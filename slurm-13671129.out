The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: yfinance in /home1/s4950836/.local/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.2.44)
Requirement already satisfied: numpy in /home1/s4950836/.local/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)
Requirement already satisfied: matplotlib in /home1/s4950836/.local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.9.0)
Requirement already satisfied: scikit-learn in /home1/s4950836/.local/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.5.2)
Requirement already satisfied: tensorflow in /home1/s4950836/.local/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.17.0)
Requirement already satisfied: pandas-ta in /home1/s4950836/.local/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.3.14b0)
Requirement already satisfied: seaborn in /home1/s4950836/.local/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.13.2)
Requirement already satisfied: pandas>=1.3.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (2.2.3)
Requirement already satisfied: requests>=2.31 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (2.32.3)
Requirement already satisfied: multitasking>=0.0.7 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (0.0.11)
Requirement already satisfied: lxml>=4.9.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (5.3.0)
Requirement already satisfied: platformdirs>=2.0.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (4.3.6)
Requirement already satisfied: pytz>=2022.5 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (2024.2)
Requirement already satisfied: frozendict>=2.3.4 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (2.4.6)
Requirement already satisfied: peewee>=3.16.2 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (3.17.7)
Requirement already satisfied: beautifulsoup4>=4.11.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (4.12.3)
Requirement already satisfied: html5lib>=1.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from yfinance->-r requirements.txt (line 1)) (1.1)
Requirement already satisfied: contourpy>=1.0.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.2.1)
Requirement already satisfied: cycler>=0.10 in /home1/s4950836/.local/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.52.4)
Requirement already satisfied: kiwisolver>=1.3.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.5)
Requirement already satisfied: packaging>=20.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (23.2)
Requirement already satisfied: pillow>=8 in /home1/s4950836/.local/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (10.3.0)
Requirement already satisfied: pyparsing>=2.3.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.1.2)
Requirement already satisfied: python-dateutil>=2.7 in /home1/s4950836/.local/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (2.9.0.post0)
Requirement already satisfied: scipy>=1.6.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.13.0)
Requirement already satisfied: joblib>=1.2.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.4.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.5.0)
Requirement already satisfied: absl-py>=1.0.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.1.0)
Requirement already satisfied: astunparse>=1.6.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)
Requirement already satisfied: flatbuffers>=24.3.25 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (24.3.25)
Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.6.0)
Requirement already satisfied: google-pasta>=0.1.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)
Requirement already satisfied: h5py>=3.10.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.11.0)
Requirement already satisfied: libclang>=13.0.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (18.1.1)
Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.4.1)
Requirement already satisfied: opt-einsum>=2.3.2 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.4.0)
Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (4.25.5)
Requirement already satisfied: setuptools in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (68.2.2)
Requirement already satisfied: six>=1.12.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.16.0)
Requirement already satisfied: termcolor>=1.1.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.4.0)
Requirement already satisfied: typing-extensions>=3.6.6 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (4.8.0)
Requirement already satisfied: wrapt>=1.11.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.16.0)
Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.66.2)
Requirement already satisfied: tensorboard<2.18,>=2.17 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.17.1)
Requirement already satisfied: keras>=3.2.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.5.0)
Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.37.1)
Requirement already satisfied: wheel<1.0,>=0.23.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.41.2)
Requirement already satisfied: soupsieve>1.2 in /home1/s4950836/.local/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 1)) (2.6)
Requirement already satisfied: webencodings in /home1/s4950836/.local/lib/python3.11/site-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 1)) (0.5.1)
Requirement already satisfied: rich in /home1/s4950836/.local/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 5)) (13.7.1)
Requirement already satisfied: namex in /home1/s4950836/.local/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 5)) (0.0.8)
Requirement already satisfied: optree in /home1/s4950836/.local/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 5)) (0.12.1)
Requirement already satisfied: tzdata>=2022.7 in /home1/s4950836/.local/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance->-r requirements.txt (line 1)) (2024.2)
Requirement already satisfied: charset-normalizer<4,>=2 in /home1/s4950836/.local/lib/python3.11/site-packages (from requests>=2.31->yfinance->-r requirements.txt (line 1)) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /home1/s4950836/.local/lib/python3.11/site-packages (from requests>=2.31->yfinance->-r requirements.txt (line 1)) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from requests>=2.31->yfinance->-r requirements.txt (line 1)) (2.2.3)
Requirement already satisfied: certifi>=2017.4.17 in /home1/s4950836/.local/lib/python3.11/site-packages (from requests>=2.31->yfinance->-r requirements.txt (line 1)) (2024.8.30)
Requirement already satisfied: markdown>=2.6.8 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 5)) (3.7)
Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 5)) (0.7.2)
Requirement already satisfied: werkzeug>=1.0.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 5)) (3.0.4)
Requirement already satisfied: MarkupSafe>=2.1.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 5)) (2.1.5)
Requirement already satisfied: markdown-it-py>=2.2.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 5)) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home1/s4950836/.local/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 5)) (2.18.0)
Requirement already satisfied: mdurl~=0.1 in /home1/s4950836/.local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 5)) (0.1.2)

[notice] A new release of pip is available: 24.0 -> 24.2
[notice] To update, run: pip install --upgrade pip
2024-11-02 00:13:26.620783: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
Retry 1:Extending the start date to 2021-03-21...
[[2.49, 1.85, -1.48, -0.66, 0.6, 3.36, 0.82, 3.69, 2.18, -4.64], [-1.12, -4.87, 3.99, 2.74, 3.31, 0.11, 4.52, 5.3, -1.72, -0.47], [5.12, 1.0, -3.76, -0.01, 0.81, -2.23, -4.99, -1.42, 0.35, -1.62], [-1.97, -0.36, 3.8, 5.45, 5.34, 1.16, -2.07, 2.69, 0.79, -3.37], [-3.23, -1.13, 2.81, 0.21, 1.08, -0.64, -2.49, -1.78, -2.74, -1.6], [-0.08, -1.86, -2.13, 1.5, -1.59, -2.67, -2.22, 0.07, 1.18, 1.28], [-3.63, -1.05, 1.33, -3.58, -1.83, 0.41, 0.47, 0.13, -2.9, -0.94], [-0.26, -0.96, -0.24, 1.89, 3.51, 1.54, -0.09, -1.77, 3.44, 3.63], [0.07, 1.19, 1.57, -0.53, 0.52, -1.44, -5.01, 4.37, 2.22, 1.47], [-2.87, 1.31, 1.71, 1.87, 0.54, -0.77, 0.95, 5.55, 5.31, -1.41], [0.55, 3.88, 1.56, 0.85, 0.91, -2.89, 1.52, -1.15, -2.24, -0.52], [-2.75, -2.65, 1.03, 4.03, -5.78, -2.05, 2.59, 4.64, 5.97, 2.38], [2.89, -6.46, -5.89, 0.0, -0.7, 0.25, -0.87, -1.02, 2.0, -0.35], [3.58, 3.33, -3.56, -2.47, 0.24, 0.95, 2.87, 2.55, -0.48, -0.24], [1.18, 5.23, 3.56, 2.09, 0.76, -2.08, 1.1, 1.32, 1.34, 3.27], [3.13, 0.76, 0.46, -2.62, -1.89, -0.56, -2.03, -0.87, -0.87, -1.24], [-1.75, -3.03, -2.03, -0.03, -1.18, -2.01, 1.3, 0.12, -1.19, -3.97], [-1.02, 0.85, 1.61, 0.26, -1.94, -0.51, -1.2, 0.37, 1.31, 3.1], [1.63, 0.09, -0.06, 1.57, 0.3, -3.61, -3.57, 0.55, -0.1, 1.1], [-2.07, -0.97, -2.04, -0.39, -1.32, -2.05, 0.34, -0.25, -1.25, 0.87], [-2.1, -2.22, -1.69, -0.06, 1.43, 0.02, 1.45, 1.7, 0.88, -3.41], [-0.83, -1.19, 0.27, 1.41, 0.34, 0.94, 0.53, -3.1, -2.4, -0.36], [1.47, -4.63, -2.55, 1.18, -0.62, -0.72, 0.72, 0.73, 0.17, -0.41], [0.6, 2.08, 0.69, -0.86, -2.01, -2.06, -0.59, -1.88, -1.52, 0.63], [-1.37, -1.18, -2.02, -0.62, -0.27, -1.59, 0.04, 0.3, 0.67, -1.68], [-1.39, -1.72, -0.62, -3.03, -0.45, 1.26, 0.06, 0.59, 1.76, 1.04], [-0.36, -2.25, -0.93, -0.83, 0.86, 1.45, -0.14, -0.85, -0.88, 0.56], [0.35, 2.3, 1.95, 6.59, 5.15, 0.41, 0.76, 0.68, 0.19, -1.05], [2.01, 0.53, -1.06, -1.38, -3.06, 1.86, 0.09, -1.8, -3.15, -3.66], [-0.69, 4.45, 5.83, 1.37, -0.99, 1.65, 2.41, -0.32, -0.02, -1.73], [2.23, -0.05, -1.15, 2.32, 2.39, 0.34, -0.43, -1.87, 0.05, -0.39], [-1.86, -0.1, -0.74, -1.08, 0.94, 0.71, 1.09, 1.4, 0.69, 1.85], [1.41, 3.59, 0.52, -1.82, -1.01, -2.29, -3.47, -0.59, -1.41, -2.59], [-2.5, -0.26, -1.23, -1.26, -1.32, -0.55, -1.17, -0.05, -0.18, 0.67], [0.48, -0.04, -1.05, 0.78, -2.06, -0.6, -0.93, -1.61, 1.21, -0.18], [0.31, 1.3, -0.14, 1.06, 0.8, 0.77, 0.73, 0.12, -0.32, 0.56], [2.02, 1.27, -2.68, -1.18, -0.56, 0.05, -0.02, 1.42, 1.4, -3.65], [-1.64, 0.02, 0.45, 1.28, 1.04, 2.69, 3.66, -0.43, -0.15, -0.88], [0.69, 0.01, 0.96, 1.97, 1.3, 0.49, 1.13, 1.02, -0.26, -1.62], [-0.53, 0.32, 0.85, 0.95, 3.4, 4.84, 2.33, 0.41, -1.11, -1.92], [-0.55, -0.37, -0.61, -1.94, -2.51, 4.0, 1.83, 0.65, 1.24, -2.02], [1.28, -0.14, 0.28, -0.23, 0.5, -0.44, 0.85, -4.21, -3.43, 2.07], [1.1, 1.68, 0.12, -0.99, -1.77, -1.29, 0.1, -2.6, 0.71, 1.74], [-2.34, 0.1, -0.46, -1.33, 0.4, -1.65, -1.84, -1.91, -0.84, -0.06], [0.53, 3.16, -0.73, -1.04, -0.2, -0.77, -0.97, -1.51, -0.81, -1.12], [1.71, -8.1, -8.62, -2.75, 0.78, -2.2, 0.19, 3.87, 3.0, 0.3], [-1.96, 2.04, -2.93, -4.39, -2.03, -3.62, -2.58, -1.07, -3.15, 2.17], [-1.57, 3.82, 5.11, 1.48, 0.19, -0.58, 3.96, 2.86, 0.04, -0.34], [1.39, 0.24, 6.56, 4.89, -1.05, -3.19, -3.12, -1.84, -2.92, -1.55], [-0.34, -0.36, -0.13, 1.28, -0.92, -1.0, -0.68, 0.74, -1.69, -0.57]]
[[2.49, 1.85, -1.48, -0.66, 0.6, 3.36, 0.82, 3.69, 2.18], [-1.12, -4.87, 3.99, 2.74, 3.31, 0.11, 4.52, 5.3, -1.72], [5.12, 1.0, -3.76, -0.01, 0.81, -2.23, -4.99, -1.42, 0.35], [-1.97, -0.36, 3.8, 5.45, 5.34, 1.16, -2.07, 2.69, 0.79], [-3.23, -1.13, 2.81, 0.21, 1.08, -0.64, -2.49, -1.78, -2.74], [-0.08, -1.86, -2.13, 1.5, -1.59, -2.67, -2.22, 0.07, 1.18], [-3.63, -1.05, 1.33, -3.58, -1.83, 0.41, 0.47, 0.13, -2.9], [-0.26, -0.96, -0.24, 1.89, 3.51, 1.54, -0.09, -1.77, 3.44], [0.07, 1.19, 1.57, -0.53, 0.52, -1.44, -5.01, 4.37, 2.22], [-2.87, 1.31, 1.71, 1.87, 0.54, -0.77, 0.95, 5.55, 5.31], [0.55, 3.88, 1.56, 0.85, 0.91, -2.89, 1.52, -1.15, -2.24], [-2.75, -2.65, 1.03, 4.03, -5.78, -2.05, 2.59, 4.64, 5.97], [2.89, -6.46, -5.89, 0.0, -0.7, 0.25, -0.87, -1.02, 2.0], [3.58, 3.33, -3.56, -2.47, 0.24, 0.95, 2.87, 2.55, -0.48], [1.18, 5.23, 3.56, 2.09, 0.76, -2.08, 1.1, 1.32, 1.34], [3.13, 0.76, 0.46, -2.62, -1.89, -0.56, -2.03, -0.87, -0.87], [-1.75, -3.03, -2.03, -0.03, -1.18, -2.01, 1.3, 0.12, -1.19], [-1.02, 0.85, 1.61, 0.26, -1.94, -0.51, -1.2, 0.37, 1.31], [1.63, 0.09, -0.06, 1.57, 0.3, -3.61, -3.57, 0.55, -0.1], [-2.07, -0.97, -2.04, -0.39, -1.32, -2.05, 0.34, -0.25, -1.25], [-2.1, -2.22, -1.69, -0.06, 1.43, 0.02, 1.45, 1.7, 0.88], [-0.83, -1.19, 0.27, 1.41, 0.34, 0.94, 0.53, -3.1, -2.4], [1.47, -4.63, -2.55, 1.18, -0.62, -0.72, 0.72, 0.73, 0.17], [0.6, 2.08, 0.69, -0.86, -2.01, -2.06, -0.59, -1.88, -1.52], [-1.37, -1.18, -2.02, -0.62, -0.27, -1.59, 0.04, 0.3, 0.67], [-1.39, -1.72, -0.62, -3.03, -0.45, 1.26, 0.06, 0.59, 1.76], [-0.36, -2.25, -0.93, -0.83, 0.86, 1.45, -0.14, -0.85, -0.88], [0.35, 2.3, 1.95, 6.59, 5.15, 0.41, 0.76, 0.68, 0.19], [2.01, 0.53, -1.06, -1.38, -3.06, 1.86, 0.09, -1.8, -3.15], [-0.69, 4.45, 5.83, 1.37, -0.99, 1.65, 2.41, -0.32, -0.02], [2.23, -0.05, -1.15, 2.32, 2.39, 0.34, -0.43, -1.87, 0.05], [-1.86, -0.1, -0.74, -1.08, 0.94, 0.71, 1.09, 1.4, 0.69], [1.41, 3.59, 0.52, -1.82, -1.01, -2.29, -3.47, -0.59, -1.41], [-2.5, -0.26, -1.23, -1.26, -1.32, -0.55, -1.17, -0.05, -0.18], [0.48, -0.04, -1.05, 0.78, -2.06, -0.6, -0.93, -1.61, 1.21], [0.31, 1.3, -0.14, 1.06, 0.8, 0.77, 0.73, 0.12, -0.32], [2.02, 1.27, -2.68, -1.18, -0.56, 0.05, -0.02, 1.42, 1.4], [-1.64, 0.02, 0.45, 1.28, 1.04, 2.69, 3.66, -0.43, -0.15], [0.69, 0.01, 0.96, 1.97, 1.3, 0.49, 1.13, 1.02, -0.26], [-0.53, 0.32, 0.85, 0.95, 3.4, 4.84, 2.33, 0.41, -1.11], [-0.55, -0.37, -0.61, -1.94, -2.51, 4.0, 1.83, 0.65, 1.24], [1.28, -0.14, 0.28, -0.23, 0.5, -0.44, 0.85, -4.21, -3.43], [1.1, 1.68, 0.12, -0.99, -1.77, -1.29, 0.1, -2.6, 0.71], [-2.34, 0.1, -0.46, -1.33, 0.4, -1.65, -1.84, -1.91, -0.84], [0.53, 3.16, -0.73, -1.04, -0.2, -0.77, -0.97, -1.51, -0.81], [1.71, -8.1, -8.62, -2.75, 0.78, -2.2, 0.19, 3.87, 3.0], [-1.96, 2.04, -2.93, -4.39, -2.03, -3.62, -2.58, -1.07, -3.15], [-1.57, 3.82, 5.11, 1.48, 0.19, -0.58, 3.96, 2.86, 0.04], [1.39, 0.24, 6.56, 4.89, -1.05, -3.19, -3.12, -1.84, -2.92], [-0.34, -0.36, -0.13, 1.28, -0.92, -1.0, -0.68, 0.74, -1.69]]
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 315ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 316ms/step
Now training the model 0/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3/5600
WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3a09b64ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4/5600
WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3a0999b560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 6/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 7/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 8/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 9/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 10/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 11/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 12/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 13/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 14/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 15/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 16/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 17/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 18/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 19/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 20/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 21/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 22/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 23/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 24/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 25/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 26/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 27/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 28/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 29/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 30/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 31/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 32/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 33/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 34/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 35/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 36/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 37/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 38/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 39/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 40/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 41/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 42/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 43/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 44/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 45/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 46/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 47/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 48/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 49/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 50/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 51/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 52/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 53/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 54/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 55/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 56/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 57/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 58/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 59/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 60/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 61/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 62/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 63/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 64/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 65/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 66/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 67/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 68/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 69/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 70/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 71/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 72/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 73/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 74/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 75/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 76/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 77/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 78/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 79/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 80/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 81/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 82/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 83/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 84/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 85/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 86/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 87/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 88/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 89/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 90/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 91/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 92/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 93/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 94/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 95/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 96/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 97/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 98/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 99/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 100/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 101/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 102/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 103/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 104/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 105/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 106/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 107/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 108/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 109/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 110/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 111/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 112/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 113/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 114/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 115/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 116/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 117/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 118/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 119/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 120/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 121/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 122/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 123/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 124/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 125/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 126/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 127/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 128/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 129/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 130/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 131/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 132/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 133/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 134/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 135/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 136/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 137/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 138/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 139/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 140/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 141/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 142/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 143/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 144/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 145/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 146/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 147/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 148/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 149/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 150/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 151/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 152/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 153/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 154/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 155/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 156/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 157/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 158/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 159/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 160/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 161/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 162/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 163/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 164/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 165/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 166/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 167/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 168/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 169/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 170/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 171/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 172/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 173/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 174/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 175/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 176/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 177/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 178/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 179/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 180/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 181/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 182/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 183/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 184/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 185/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 186/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 187/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 188/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 189/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 190/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 191/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 192/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 193/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 194/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 195/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 196/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 197/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 198/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Now training the model 199/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 200/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 201/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 202/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 203/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 204/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 205/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 206/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 207/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 208/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 209/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 210/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 211/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 212/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 213/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 214/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 215/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 216/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 217/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 218/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 219/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Now training the model 220/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 221/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 222/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 223/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 224/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 225/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 226/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 227/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 228/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 229/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 230/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 231/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 232/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 233/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 234/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 235/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 236/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 237/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 238/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 239/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 240/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 241/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 242/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 243/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 244/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 245/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 246/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 247/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 248/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 249/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 250/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 251/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 252/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 253/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 254/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 255/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 256/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 257/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 258/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 259/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 260/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 261/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 262/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 263/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 264/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 265/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 266/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 267/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 268/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 269/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 270/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 271/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 272/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 273/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 274/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 275/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 276/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 277/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 278/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 279/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 280/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 281/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 282/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 283/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 284/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 285/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 286/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 287/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 288/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 289/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 290/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 291/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 292/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 293/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 294/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 295/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 296/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 297/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 298/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 299/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 300/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 301/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 302/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 303/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 304/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 305/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 306/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 307/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 308/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 309/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 310/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 311/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 312/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 313/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 314/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 315/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 316/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 317/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 318/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 319/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 320/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 321/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 322/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 323/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 324/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 325/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 326/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 327/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 29ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 29ms/step
Now training the model 328/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 329/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 330/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 331/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 332/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 333/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 334/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 335/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 336/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 337/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 338/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 339/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 340/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 341/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 342/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 343/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 344/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 345/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 346/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 347/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 348/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 349/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 350/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 351/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 352/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 353/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 354/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 355/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 356/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 357/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 358/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 359/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 360/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 361/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 362/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 363/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 364/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 365/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 366/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 367/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 368/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 369/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 370/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 371/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 372/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 373/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 374/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 375/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 376/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 377/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 378/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 379/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 380/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 381/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 134ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 134ms/step
Now training the model 382/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 383/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 384/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 385/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 386/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 387/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 388/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 389/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 390/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 391/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 392/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 393/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 394/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 395/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 396/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 397/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 398/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 399/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 400/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 401/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 402/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 403/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 404/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 405/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 406/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 407/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 408/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 409/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 410/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 411/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 412/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 413/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 414/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 415/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 416/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 417/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 418/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 419/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 420/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 421/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 422/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 423/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 424/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 425/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 426/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 427/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 428/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 429/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 430/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 431/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 432/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 433/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 434/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 435/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 436/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 437/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 438/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 439/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 440/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 441/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 442/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 443/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 444/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 445/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 446/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 447/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 448/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 449/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 450/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 451/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 452/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 453/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 454/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 455/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 456/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 457/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 458/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 459/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 460/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 461/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 462/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 463/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 464/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 465/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 466/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 467/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 468/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 469/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 470/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 471/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 472/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 473/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 474/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 475/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 476/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 477/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 478/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 479/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 480/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 481/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 482/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 483/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 484/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 485/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 486/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 487/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 488/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 489/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 490/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 491/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 492/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 493/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 494/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 495/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 496/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 497/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 498/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 499/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 500/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 501/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 502/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 503/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 504/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 505/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 506/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 507/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 508/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 509/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 510/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 511/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 512/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 513/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 514/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 515/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 516/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 517/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 518/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 519/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 520/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 521/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 522/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 523/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 524/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 525/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 526/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 527/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 528/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 529/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 530/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 531/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 532/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 533/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 534/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 535/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 536/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 537/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 538/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 539/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 540/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 541/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 542/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 543/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 544/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 545/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 546/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 547/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 548/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 549/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 550/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 551/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 552/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 553/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 554/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 555/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 556/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 557/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 558/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 559/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 560/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 561/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 562/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 563/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 564/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 565/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 566/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 567/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 568/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 569/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 570/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 571/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 572/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 573/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 574/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 575/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 576/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 577/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 578/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 579/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 580/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 581/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 582/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 583/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 584/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 585/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 586/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 587/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 588/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 589/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 590/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 591/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 592/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 593/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 594/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 595/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 596/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 597/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 598/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 599/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 600/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 601/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 602/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 603/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 604/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 605/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 606/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 607/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 608/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 609/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 610/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 611/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 612/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 613/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 614/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 615/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 616/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 617/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 618/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 619/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 620/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 621/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 622/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 623/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 624/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 625/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 626/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 627/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 628/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 629/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 630/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 631/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 632/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 633/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 634/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 635/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 636/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 637/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 638/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 639/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 640/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 641/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 642/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 643/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 644/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 645/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 646/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 647/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 648/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 649/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 650/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 651/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 652/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 653/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 654/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 655/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 656/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 657/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 658/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 659/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 660/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 661/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 662/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 663/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 664/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 665/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 666/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 667/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 668/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 669/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 670/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 671/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 672/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 673/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 674/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 675/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 676/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 677/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 678/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 679/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 680/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 681/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 682/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 683/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 684/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 685/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 686/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 687/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 688/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 689/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 690/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 691/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 692/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 693/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 694/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 695/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 696/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 697/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 698/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 699/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 700/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 701/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 702/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 703/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 704/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 705/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 706/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 707/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 708/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 709/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 710/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 711/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 712/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 713/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 714/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 715/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 716/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 717/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 718/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 719/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 720/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 721/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 722/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 723/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 724/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 725/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 726/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 727/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 728/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 729/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 730/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 731/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 732/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 733/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 734/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 735/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 736/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 737/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 738/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 739/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 740/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 741/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 742/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 743/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 744/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 745/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 746/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 747/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 748/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 749/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 750/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 751/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 752/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 753/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 754/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 755/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 756/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 757/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 758/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 759/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 760/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 761/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 762/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 763/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 764/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 765/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 766/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 767/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 768/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 769/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 770/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 771/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 772/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 773/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 774/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 775/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 776/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 777/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 778/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 779/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 780/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 781/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 782/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 783/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 784/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 785/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 786/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 787/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 788/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 789/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 790/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 791/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 792/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 793/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 794/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 795/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 796/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 797/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 798/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 799/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 800/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 801/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 802/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 803/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 804/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 805/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 806/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 807/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 808/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 809/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 810/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 811/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 812/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 813/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 814/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 815/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 816/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 817/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 818/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 819/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 820/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 821/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 822/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 823/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 824/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 825/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 826/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 827/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 828/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 829/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 830/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 831/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 832/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 833/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 834/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 835/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 836/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 837/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 838/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 839/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 840/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 841/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 842/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 843/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 844/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 845/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 846/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 847/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 848/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 849/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 850/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 851/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 852/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 853/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 854/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 855/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 856/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 857/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 858/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 859/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 860/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 861/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 862/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 863/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 864/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 865/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 866/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 867/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 868/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 869/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 870/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 871/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 872/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 873/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 874/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 875/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 876/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 877/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 878/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 879/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 880/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 881/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 882/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 883/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 884/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 885/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 886/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 887/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 888/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 889/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 890/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 891/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 892/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 893/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 894/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 895/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 896/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 897/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 898/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 899/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 900/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 901/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 902/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 903/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 904/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 905/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 906/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 907/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 908/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 909/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 910/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 911/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 912/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 913/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 914/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 915/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 916/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 917/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 918/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 919/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 920/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 921/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 922/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 923/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 924/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 925/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 926/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 927/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 928/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 929/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 930/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 931/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 932/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 933/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 934/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 935/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 936/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 937/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 938/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 939/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 940/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 941/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 942/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 943/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 944/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 945/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 946/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 947/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 948/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 949/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 950/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 951/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 952/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 953/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 954/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 955/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 956/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 157ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 157ms/step
Now training the model 957/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 958/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 959/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 960/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 961/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 962/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 963/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 964/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 965/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 966/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 967/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 968/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 969/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 970/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 971/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 972/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 973/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 974/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 975/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 976/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 977/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 978/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 979/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 980/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 981/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 982/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 983/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 984/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 985/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 986/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 987/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 988/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 989/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 990/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 991/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 992/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 993/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 994/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 995/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 996/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 997/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 998/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 999/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1000/5600
MAE: 0.44923205232620245, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.5055112452507019, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.5063707337379456, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.5160409662723541, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.5501246765851975, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.6009200127124786, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.6209640562534331, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.6238624141216278, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.6421627748608588, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.6699385811686516, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.6891725853681565, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.6977494410276412, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.7075721465349198, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.7077806682586669, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.708240001320839, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.719034685254097, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7210422322154044, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.7225016031265258, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7398571476936341, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7472233951091766, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.7524505364894867, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.7537141907215118, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7638712931275367, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 3
MAE: 0.7642340128421783, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.7736304850578308, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.77917187666893, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.7804029048681259, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.7825557769536972, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.7922014999389648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7957228590250016, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.7963610444068908, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.7966920361518859, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.7993579388260842, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7995453178882598, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8024944529533388, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.8029407175183294, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8065524086952209, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8088162930011749, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.8145017178058623, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.8217294384241104, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.8228256285190583, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8286043152809143, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8429517626762391, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8432858943939209, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.848490445792675, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.8486416981220245, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8504347673654558, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.8533767135273663, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.8534022096395493, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.853467783331871, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8545520440340042, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.856945918560028, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.8597166538238525, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.8696977753043175, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8698150214403867, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.8706802502870559, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.8709582850337029, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8722456481158734, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.8761679697632789, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.877728431224823, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.8792613269090651, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.8801492279767992, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8805919528007508, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.8819353879094123, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8839577035903929, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8850332945585251, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8856113777160644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8859320417642593, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8940398306846618, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8967934507131577, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.896855402112007, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.8977669294774533, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9048452064394951, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9053405702114106, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9066628800630567, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.9094477133750913, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9098775107264518, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9107101503610611, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9151637361049652, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9165384531021118, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9173578476905824, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.9246643335223197, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.9257613406181335, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9307725846767425, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9320501998066902, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.9322068907618523, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.932658042192459, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.9331058443188667, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9385574072599411, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9394437425136566, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.941758621096611, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9444434449672698, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.9464023113250732, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.9474303965568541, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9486241743564605, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9490073682069777, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9529300481081009, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9585937094688415, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9594492273330687, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.9617911726832389, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.968866099834442, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9706450001001358, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9724863637089729, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9735166597366334, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9755847886800766, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.975655225276947, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9763225027024746, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9773049818277357, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.9794594392776489, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9811681048870085, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9848730582594871, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9872597247362137, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9880595417022704, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9895137530416249, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.989976371884346, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9915909414291381, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9927197054624557, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9938551109284163, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9938970268368721, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9981548563241958, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.0029092492461202, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.004199422955513, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.0048412487506866, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.008902898490429, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0118906665444374, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.012331308722496, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0127870547771454, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0133902642726897, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0146638751029968, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0172656841278076, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.020788191318512, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.021362805366516, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0218432891368867, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.024474447131157, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0258346294164657, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.025874263048172, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0265686976909638, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.0265974358320236, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0289222631454469, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.031326590538025, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0329352931976317, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0336357653737067, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.036913468003273, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.041114322900772, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.042861752510071, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0469128773212433, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0483694434165955, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0490334808826447, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0501325458884239, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.050846247434616, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0535908982753752, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0536984640359879, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0539305836558341, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0566131700277328, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0592548944056035, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0603716448545455, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.060785198688507, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.061256624817848, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0624287099838257, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.0628159493803977, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0642847294807436, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0670043904781341, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0680034726858139, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0713419616222382, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0713543117642401, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0715382680892944, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0716411457061767, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0722410993576048, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.072314890220761, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.077769433259964, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.079217530965805, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0796695057153702, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0802641607820989, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.080408705949783, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0823623094558716, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.0825453953742978, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0833412739634514, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.083363504767418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.0875321340858934, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.089275209903717, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0901152849197389, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0912890970706939, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.0937770698070526, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0942743990421295, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0980191812515259, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.102550098657608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1037141622304916, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1044815737009048, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1065229997634887, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.1066235959529878, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.107204086303711, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1097685191631317, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.1100517600774764, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1117547646164894, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1129486560821533, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1132547348737716, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.1142170131206512, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.118099238395691, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.119926503300667, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.1199304938316346, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1201983499526977, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.1215272591114043, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.130066397100687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1325382965803148, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1344717059135436, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.1366797506809234, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1381354246139526, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.1388242813944818, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.1399101078510285, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1451707661151886, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.149304316997528, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1547215626239775, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.155978034734726, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1580805070698261, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.158447265625, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1589796741008758, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1619692549705505, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.1623557872772217, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1627293915748595, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.162863756775856, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1642675642967224, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1644506767392158, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1645051602125167, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1652860090732573, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1665527880191804, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.169631724357605, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1707190768718718, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1714068803787232, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1716131925582887, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.1728973822593687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.1732904494404792, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1734163999557494, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1737823847532272, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.174130481481552, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.175797312259674, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.17603859603405, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1788064458072185, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1809096500873566, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.180922313094139, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.1812626705169678, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.185770552664995, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1891784162521362, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1898424863815307, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1947636291980743, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1959527790546418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.198767086982727, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1989935801029206, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.2003934339284896, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.2022306070327757, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2149468020200729, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2150047063827514, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2179839033484459, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2180655002593994, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.218765609025955, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2188456342220306, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.2209561395645143, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2219280109405517, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.2243560045957564, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.2253757685422897, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2259837571382524, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2270101189613343, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2284138917922973, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2326258662939071, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.232729040145874, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2329449695199728, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2348447115421295, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2349895792007444, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.235126222848892, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2359618828296661, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2393899188041686, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2395631062984467, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2442595219612123, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445047547221182, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445318520665167, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2445571527481079, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2451037096977235, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.24555746614933, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.248858909368515, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2492913488149644, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2495196838378906, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2507887959480286, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2524703726768494, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.25447074174881, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.255672797679901, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.257878007173538, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.2581990916132928, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2583328559994698, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.258658321261406, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2596591730117797, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.260091652035713, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2627122163772584, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.264324443101883, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.2649783864617348, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2657224659919737, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2675757185220717, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.2692975685596466, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2693283901214598, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.269498236835003, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2722176745533944, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.2730072708129883, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.274883782863617, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2751694118976595, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2756651029586792, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.2771128609776496, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.2776659578084946, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.2794184237718582, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.280376872420311, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2806914303302765, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2807814006805418, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2820487205982207, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2836234407424925, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.285674626737833, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2863050699234009, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.286460910797119, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.2865045615136623, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.287969485282898, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2883574829101563, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.2893567517995834, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.2896505728363992, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2940906286239624, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.295846273303032, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2983676288127899, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3047610018253326, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3057035731077193, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3059039340019225, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3061656594872475, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3067478083670139, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3097322063446044, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.310144631922245, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.311190249443054, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.3117063555717468, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3131315932273864, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3154627685546874, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3174623684883116, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3178813235759734, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.3228353456258772, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.32668805873394, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.326729215234518, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3277433071136475, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3277980056256056, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3278208632469177, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3283361272811889, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3288901090621947, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.3297507659196852, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.330053715467453, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3307581782341003, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.333287979722023, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3353062634468078, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.3358825981616973, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3362213716506957, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3372200460433958, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3385834038853646, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.339330087661743, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.34064542388916, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.3416240200996399, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3421750948429108, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.3426572501659393, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3434198067188263, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.3459816489219665, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3473761591911315, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3487317115068436, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.351424762159586, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3532036989927292, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.356932810306549, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3591956872940063, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3604056553840636, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3669246363639833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.369421910047531, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3731223106384278, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3743433923721313, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.3745349810123444, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3754923090934752, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3759255588054657, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.379000167608261, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3790293709039687, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3798093155622482, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3807407736778259, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3814833270311353, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3817279160022735, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3882122099995613, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3895928428173066, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3898489402532577, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.3905784369707106, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3920154005289078, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3940303496122362, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.3960764006376265, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3993730098605155, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3998348641991616, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4020033001899719, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4054688379764557, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.406106551170349, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4069226239994168, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4096608672142028, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4111608282327652, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4112306044101715, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4138897690773011, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4149966708049178, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.415557039141655, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.415991908311844, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.4165477008819578, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.416896034836769, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.417103001832962, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.417250825881958, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.417263792514801, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.4173992395401, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4175143394470215, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4178217158317565, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.418121071457863, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4194887631237507, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.4196272314190863, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.420102985203266, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.420616219997406, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4210114166736603, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4216918766498565, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4231562033891678, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4233985096812247, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4270993203520774, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4287651569247246, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4341230276823045, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4341457191705704, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.4346961483955383, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4367408440113068, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.4375874012708665, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.4411447689533232, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4412494378089904, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.443949596643448, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.4444691263139249, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4465025444030761, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4470076189041137, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4491006284952164, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.4504877673387526, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4513078689575196, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4522238838672639, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4530203363522887, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.457654752135277, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4611959837973116, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4612959787845612, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.4642929005622864, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4665672109127044, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.468501843690872, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.4686041954755784, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4727415370941164, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.474275733947754, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4763009814471004, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4787994503974915, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4792503386735916, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4792756605148316, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4794279308319092, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4800875812768937, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.4808689299821853, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4812486829161642, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4842892513275145, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4895776227712632, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4907044175863267, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4908448525369167, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.4947805511951446, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.495291511774063, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4956667230129241, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4964612604379652, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4964879512786866, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4979722678661347, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4994183871746063, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4995971113443374, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.499851671665907, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.500087587594986, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5012647286653518, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5045835668146608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5049042735099794, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5055404663085938, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.5059518699645995, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.5072108428925275, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.50731849527359, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5101907598972322, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5103061364889143, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.519034262061119, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.5200535521507264, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.522092010140419, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5233807862997053, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.524057889342308, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5244111554622648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5270265519618988, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5273205861449242, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5279604229927064, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5297442295253276, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.5301416087150574, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5313348803520204, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5322370147928595, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5336250097751616, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.540907790184021, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.541915274143219, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5437105374336242, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5446757645010947, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5492777690887451, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.550776258587837, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5511295483112335, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5532853341102602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.5552442226409913, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5556509986519813, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5566252875328064, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5576226354241371, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5593781995773317, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5637934196591377, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.5655289278030395, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.565563789486885, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5657193840146064, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.5673263580799102, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.567548280954361, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.5682341412305831, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5697367310523986, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.5707295604646205, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5712229553461075, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.5720596016049384, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.5734783191680908, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5749350206851958, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5771525580883026, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.579625639438629, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5796981792747975, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5804679021835326, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.5829287246465682, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.587926486134529, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5883658841848374, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5890283495783806, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.589477723836899, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5898203552365302, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5912233397960662, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5955701887607574, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.596790479183197, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5973533154129982, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.6016839895248414, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.6028615951538085, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6054216206073761, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.6056024137735367, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6068544074892999, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.6088911123275758, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.608901499390602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.6132668242454529, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6145376892089842, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.6149865255355835, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.617002248764038, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6183684871196746, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6190730199813843, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6254666239619255, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6258640397191049, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.6261632130146026, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.6262701154351233, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6269377813339232, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.6271870419979095, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.6296569752693177, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6303403396606444, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6314718604683875, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.636107897758484, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6364457309246063, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.637423395037651, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.6385496586561203, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.640715942144394, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6417351350784302, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.64206120967865, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.6422480301856992, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.6452662916183471, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6464651541709898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6482768373489378, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6488916521072388, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.649846633076668, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.6518700302839278, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.655961772918701, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.6563528583049774, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.65910815179348, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.6641271338462829, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6652281806468963, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.667265977025032, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6682733998298644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6703035757541655, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6783748769462108, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.683435659408569, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.688024725317955, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6880490038394929, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6882670879364015, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.6893699929714203, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6908744305968284, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6913443308323621, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6919383273124695, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.6946387724876402, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6950820374488829, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.6968272387981416, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.6989871129989624, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.7030796751976012, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.7055030322074891, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.709457209765911, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7101020709276198, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.710202185988426, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7112806544303893, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.7120026067495346, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7122117028236388, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.7126088634729384, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7126224145889282, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7130378901958465, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7134972870349885, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7135540217757224, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.7136183590888976, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7139797315597534, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.7154318228363992, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7156692714691162, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.7156890586614608, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7179230451583862, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7180974708795547, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.7190667424201966, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7219003841876983, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.722057311296463, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7230394825935362, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7239278957247735, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7250207290649413, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7252617985457182, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.7302283601760862, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7303747057914733, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7314121589660645, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.732295435667038, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7325358912944793, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.7339372055530546, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.7343085520565509, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.735089676141739, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.7356451585143806, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.7392203407287596, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.7400204854011534, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7407579469680787, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7430600957870481, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7459279820919036, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7479827032089232, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.749409262895584, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.7504271820783615, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.7512264298200606, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7515728995800017, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7520624340772628, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7529126749038695, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7537784278392792, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7539441004991532, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7549213156700134, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7582494781017304, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7594976902008057, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7640695543289184, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.7649804100990294, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.7658147633075714, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7662122145891188, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7684044466018676, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7684059948921202, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.76896444606781, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.7696022171974182, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.7704019293785094, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.7772946999073027, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7810661047697067, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7845523595809936, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7878951699733734, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.7881029949188236, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7901215612888337, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7934389099478723, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.7952616260051726, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7978993713855744, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7995828227996824, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8036522538661957, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8052691490650177, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8058169708251952, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8060016632080078, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.808211790204048, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8106041059494018, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8184639797210693, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8194591376781464, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8202139214277266, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8229052529335021, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.8235276312828064, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.825089852809906, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.8284483242034912, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.8287240147590638, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8347806572914123, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.8376560673713684, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.8395919964313507, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.8397361130714416, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.8406830847859381, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.8408745527267456, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8418196067810058, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8455752835273742, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.847792100906372, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.848219861268997, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8482250349521636, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.8550118267536164, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8550261214971542, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.856734118670225, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.860503324985504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8659023777246475, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.8671984914541244, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8677148163318633, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.8682186007499695, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.8694670648574827, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8730671093463898, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8790963859558105, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8791436882019041, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.879826320707798, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.8799741716384886, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8811773941516876, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8823429703712464, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.8838593558073042, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8841468945741653, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.8844422221183776, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.8844440221786498, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8856610432863234, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.887393186300993, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8878778967857361, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.888327965259552, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.893958365917206, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.8963519916534426, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.8971855373382567, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8974021569490431, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8984763860702514, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.8993401646614074, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9000274062156677, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.9006402597427368, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9028469221591948, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9034287571907043, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.903832612991333, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9049101696014403, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9051041648387907, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.9075096354484558, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.908993689775467, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.9104237303733824, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.9113574192523957, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.912921197772026, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9154980707168576, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.915706233739853, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.9180502713322638, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.9250909745693208, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9253533780574799, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.9268941955566405, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.9269641075134278, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9300405592918395, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.9322919920682906, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.932523000240326, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9329437346458433, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.937361756324768, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.938294498682022, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.938849555015564, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.94138206410408, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.943249243557453, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9469791264533995, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9517008786201473, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9523427203893662, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.9538272678852082, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9566843718886375, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.9596466200351714, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9631543610841036, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.966683383464813, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.96797962641716, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9701451659202576, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9745340392589568, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.974722777366638, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.975356815934181, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9786889151334761, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.9875781551599503, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9876585111618041, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.9884053320884703, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9922114973068237, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.9955444917678833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.9956910174191003, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.995696872472763, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.9960896492004394, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.000362291991711, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.007160742580891, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.0128101289868354, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.0149026572704316, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.017586702108383, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.018459497451782, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0266250342130663, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.0272196531295776, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.03167760848999, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.0345093579292297, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.0405101127922536, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.0412771478891374, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.0435629086494442, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.044292601466179, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.0476628035902977, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.048649752318859, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.048884205579758, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0516196534633635, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.051832914352417, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.052972470283508, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.0537389397621153, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.054859972000122, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.0574438900351524, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.0579430595040322, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.0591199562549596, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.0594616458415986, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0620893602371213, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.063803866863251, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0648088455200195, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.070836775749922, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.075014959335327, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.075873627513647, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.077954441308975, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.0814577147960662, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.087084526181221, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.088319371700287, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.0894282147884367, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.0902798332870005, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.0909157947301864, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.0912524461746216, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.0936098918914796, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.094252688169479, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.095119853496551, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.1071963535547256, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.113142045021057, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.113944552898407, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1142090814113614, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.11633536529541, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.1179665670394896, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.1224231884479523, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.128646969795227, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.129011590838432, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1299195842742917, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.132686434745789, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.139706157207489, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.1420151562690735, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.1452305309474466, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1468250691890716, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.1494251461029052, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.149927827835083, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.1511641428470614, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.1531429812908174, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.1553255156874656, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.1580598936080935, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.158605764865875, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1591765675544736, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1617755131721497, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.165790997505188, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1660262048244476, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1661195502281188, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.1678628311157224, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.169298859000206, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.173025022506714, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.1731034190654754, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1736091212034223, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1742076174020766, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.1792540296912195, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.180105555534363, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.1819722623825073, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.1823269591331482, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.1845811114311218, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.1881432042121887, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.191343186855316, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.1985860452651975, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.1995634467005734, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.2004692912101746, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.2141740725040435, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.214598279505968, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.2148191576004024, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.2233117491602896, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.230036625444889, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.2344828338027, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2391082451343536, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.2494699362516406, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.2513430134058, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.2620479092597963, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.262953279972076, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.2630436973571775, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.2641238676309583, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.2698918521404265, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.2730577841997146, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.273338125705719, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.2782123403549193, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.2837203428745267, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.2841161929666995, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.2885433718562127, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.2902920633554458, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.293800139427185, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.2940399603843686, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.3011642665863037, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3044723675251007, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.306535981655121, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.307020859479904, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.308794270515442, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.308952045440674, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.3119770706295966, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.3135028915405274, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.317508618593216, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.318241516113281, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.3199576113224034, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.320935190081596, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.324331745624542, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.324379640996456, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.3245733234882353, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.32524663066864, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3304125086069107, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.332355314552784, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.3348226294517516, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.3440734834671018, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.365408286511898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.3685140312314035, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.3705247566699983, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.3782636300325395, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.380768096446991, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.3813441932201385, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.382840000152588, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3901876912117004, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.392253859400749, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.401200239419937, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.4102375656962396, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.410561458826065, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.412057755947113, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.412959004998207, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.413552816271782, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.418061542510986, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.4186100766658782, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.42441800570488, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.4303963069915766, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.43413844871521, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.440752312541008, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.4441592321395875, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.4442741751670836, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.4568203092217447, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.466722925066948, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.4671855211257934, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.481179675579071, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.488544668316841, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4916726559996603, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.4921403542757035, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.501889357402921, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.5022410616874695, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.514095245361328, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.519612734079361, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.5208762288093567, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.534331890940666, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.535784955382347, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.5379346877336504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.5436976120471955, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5454398469924926, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.5506374225616453, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.5631247535943986, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.5654521927833556, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.56702621281147, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.571935909986496, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.575710658788681, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.5768654661178587, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.578273500561714, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.588696889638901, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.590064583778381, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5954928741455077, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.601329207420349, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.601901505947113, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.602644822359085, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.6147365542054173, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6267674342393876, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.628404844239354, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.629312935590744, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.631418771961704, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.6398198561668393, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.664280910849571, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.6680451110601426, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.6702974177226424, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6855965719223023, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.7139180302619934, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.722136028289795, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.723188541889191, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.724814936637878, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.735076573848725, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.739984595775604, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.761810897350311, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.7712779359817503, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.774302265167236, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.788458643913269, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.7929939703941344, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.801421770572662, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.811801800251007, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.8260716676712034, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.8320538507699964, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.854437692642212, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.888055741786957, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.8924584493637084, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.8952078745365144, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.89608642911911, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.9176550731658937, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.9365611748695373, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.9565970771610735, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.984579122066498, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.987040515422821, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 3.0039432943463327, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 3.0065708861351013, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 3.0183619604110716, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 3.018407331466675, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 3.0264869556427003, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 3.035234998345375, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 3.049882178068161, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 3.0728003606796266, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 1
MAE: 3.0774910867214205, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 3.090915502667427, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 3.1046783730983734, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 1
MAE: 3.1315883890390395, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 3.1394094079732895, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 5
MAE: 3.1818889126777647, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.1884463267326355, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.19628550863266, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.240051233768463, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.2574724512100217, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 1
MAE: 3.2774167344570158, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 4
MAE: 3.4833023028373717, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 3.621103637099266, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 5
Results saved successfully in dir `results/test2/NN_results_1000_lessData.pkl.pkl`.
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1001/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1002/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1003/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1004/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1005/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1006/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1007/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1008/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1009/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1010/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1011/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1012/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1013/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1014/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1015/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1016/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1017/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1018/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1019/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1020/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1021/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1022/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1023/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1024/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1025/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1026/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1027/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1028/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1029/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1030/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1031/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1032/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 1033/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Now training the model 1034/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 1035/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 1036/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1037/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1038/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1039/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1040/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1041/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1042/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1043/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1044/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1045/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1046/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Now training the model 1047/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1048/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1049/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1050/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1051/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 1052/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1053/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1054/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1055/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1056/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1057/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1058/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1059/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 1060/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 1061/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1062/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1063/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1064/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1065/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1066/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1067/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1068/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1069/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 1070/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1071/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1072/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1073/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 1074/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1075/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1076/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 1077/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1078/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1079/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1080/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1081/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1082/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1083/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1084/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1085/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1086/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1087/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1088/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1089/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1090/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1091/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1092/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1093/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1094/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1095/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1096/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1097/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1098/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1099/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1100/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1101/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1102/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1103/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1104/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1105/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1106/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1107/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1108/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 1109/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1110/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1111/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1112/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1113/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1114/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1115/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1116/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1117/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1118/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1119/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1120/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1121/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1122/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1123/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1124/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1125/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1126/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1127/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 1128/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1129/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1130/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1131/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1132/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1133/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1134/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1135/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1136/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1137/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1138/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1139/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1140/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1141/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1142/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1143/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1144/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1145/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1146/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1147/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1148/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1149/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1150/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1151/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1152/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1153/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1154/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1155/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1156/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1157/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1158/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1159/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1160/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1161/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1162/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1163/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1164/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1165/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1166/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1167/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1168/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1169/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1170/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1171/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1172/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1173/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1174/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1175/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1176/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1177/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1178/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1179/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1180/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1181/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1182/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1183/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1184/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1185/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1186/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1187/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1188/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1189/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1190/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 1191/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 1192/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 1193/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 1194/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1195/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 1196/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1197/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1198/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1199/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 1200/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 1201/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1202/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1203/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1204/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 1205/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1206/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1207/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1208/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1209/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1210/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1211/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1212/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1213/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1214/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1215/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1216/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 1217/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1218/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1219/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1220/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1221/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1222/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1223/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1224/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1225/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 1226/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 1227/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1228/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1229/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1230/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1231/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 1232/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1233/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1234/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1235/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1236/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1237/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1238/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1239/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1240/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1241/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1242/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1243/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1244/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1245/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1246/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1247/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1248/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1249/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1250/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1251/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1252/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1253/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1254/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1255/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1256/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1257/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1258/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1259/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1260/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1261/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1262/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1263/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1264/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1265/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1266/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1267/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1268/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1269/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1270/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1271/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1272/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1273/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1274/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1275/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1276/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1277/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1278/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1279/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1280/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1281/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1282/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1283/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1284/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1285/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1286/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1287/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1288/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1289/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1290/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1291/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1292/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1293/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1294/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1295/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1296/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1297/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1298/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1299/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1300/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1301/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1302/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1303/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1304/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1305/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1306/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1307/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1308/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1309/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1310/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1311/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1312/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1313/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1314/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1315/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1316/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1317/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1318/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1319/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 1320/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1321/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1322/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1323/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1324/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1325/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1326/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1327/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1328/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1329/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1330/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1331/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1332/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1333/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1334/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1335/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1336/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1337/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1338/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1339/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1340/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1341/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1342/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1343/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1344/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1345/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1346/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1347/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1348/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1349/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1350/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1351/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1352/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1353/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1354/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1355/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1356/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1357/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1358/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1359/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1360/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1361/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1362/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1363/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1364/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1365/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1366/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1367/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1368/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1369/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1370/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1371/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1372/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1373/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1374/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1375/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1376/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1377/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1378/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1379/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1380/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1381/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1382/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1383/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1384/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1385/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1386/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1387/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1388/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1389/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1390/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1391/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1392/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1393/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1394/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1395/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1396/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1397/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1398/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1399/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1400/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1401/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1402/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1403/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1404/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1405/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1406/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1407/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1408/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1409/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1410/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1411/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1412/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1413/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1414/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 1415/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1416/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1417/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1418/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1419/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1420/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1421/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1422/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1423/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1424/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1425/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1426/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1427/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1428/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1429/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1430/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1431/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1432/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1433/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1434/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1435/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1436/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1437/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1438/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1439/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1440/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1441/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1442/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1443/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1444/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1445/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1446/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1447/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1448/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1449/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1450/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1451/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1452/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 81ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 82ms/step
Now training the model 1453/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 83ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 83ms/step
Now training the model 1454/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step
Now training the model 1455/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 1456/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 1457/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1458/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1459/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1460/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step
Now training the model 1461/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1462/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1463/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1464/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1465/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1466/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1467/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1468/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1469/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1470/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1471/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 82ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 82ms/step
Now training the model 1472/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1473/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1474/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1475/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1476/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1477/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1478/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1479/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1480/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1481/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1482/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1483/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1484/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1485/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1486/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1487/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1488/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1489/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1490/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1491/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1492/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1493/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1494/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1495/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1496/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1497/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1498/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1499/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1500/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1501/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 214ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 214ms/step
Now training the model 1502/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1503/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1504/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1505/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1506/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1507/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1508/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1509/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1510/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1511/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1512/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1513/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1514/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1515/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1516/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1517/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1518/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1519/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1520/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1521/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1522/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1523/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1524/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1525/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1526/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1527/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1528/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1529/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1530/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1531/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1532/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1533/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1534/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1535/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1536/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1537/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1538/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1539/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1540/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1541/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1542/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1543/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1544/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1545/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1546/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1547/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1548/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1549/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1550/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1551/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1552/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1553/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1554/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1555/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1556/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1557/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1558/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1559/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1560/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1561/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1562/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1563/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1564/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1565/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1566/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1567/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1568/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1569/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1570/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1571/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1572/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1573/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1574/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1575/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1576/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1577/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1578/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1579/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1580/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1581/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1582/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1583/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1584/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1585/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1586/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1587/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1588/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1589/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1590/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1591/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1592/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1593/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1594/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1595/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1596/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1597/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1598/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1599/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1600/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1601/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1602/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1603/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1604/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1605/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1606/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1607/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1608/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1609/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1610/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1611/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1612/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1613/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1614/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1615/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1616/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1617/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1618/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1619/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1620/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1621/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1622/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1623/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1624/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1625/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1626/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1627/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1628/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1629/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1630/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1631/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1632/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1633/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1634/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1635/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1636/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1637/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1638/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1639/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1640/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1641/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1642/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1643/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1644/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1645/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1646/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1647/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1648/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1649/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1650/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1651/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1652/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1653/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1654/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1655/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1656/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1657/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1658/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1659/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1660/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1661/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1662/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1663/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1664/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1665/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1666/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1667/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 85ms/step
Now training the model 1668/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step
Now training the model 1669/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 76ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 76ms/step
Now training the model 1670/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1671/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 1672/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step
Now training the model 1673/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1674/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1675/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 1676/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1677/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 1678/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1679/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1680/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1681/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 330ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 331ms/step
Now training the model 1682/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1683/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1684/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1685/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1686/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1687/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1688/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1689/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1690/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 1691/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1692/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1693/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1694/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 1695/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1696/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1697/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 96ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 97ms/step
Now training the model 1698/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 1699/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1700/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1701/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1702/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 1703/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1704/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1705/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1706/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1707/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1708/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1709/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1710/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1711/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1712/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1713/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1714/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1715/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1716/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1717/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1718/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1719/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1720/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1721/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1722/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1723/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1724/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1725/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1726/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1727/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1728/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1729/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1730/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1731/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1732/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1733/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1734/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1735/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1736/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1737/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1738/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1739/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1740/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1741/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1742/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1743/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1744/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1745/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1746/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1747/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1748/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1749/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1750/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1751/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1752/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1753/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1754/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1755/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1756/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1757/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1758/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1759/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1760/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1761/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1762/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1763/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1764/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1765/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1766/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1767/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1768/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1769/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1770/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1771/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1772/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1773/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1774/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1775/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1776/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1777/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1778/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1779/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1780/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1781/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1782/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1783/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1784/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1785/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1786/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1787/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1788/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1789/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1790/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1791/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1792/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1793/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1794/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1795/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1796/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1797/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1798/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1799/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1800/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1801/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1802/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1803/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1804/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1805/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1806/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1807/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1808/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1809/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1810/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1811/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1812/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1813/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1814/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1815/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1816/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1817/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1818/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1819/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1820/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1821/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1822/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1823/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1824/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1825/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1826/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1827/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1828/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1829/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1830/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1831/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1832/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1833/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1834/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1835/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1836/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1837/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1838/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1839/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1840/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1841/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1842/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1843/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1844/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1845/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1846/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1847/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1848/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1849/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1850/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1851/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1852/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1853/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1854/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1855/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1856/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1857/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1858/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1859/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 1860/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1861/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1862/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1863/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1864/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1865/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1866/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1867/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1868/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1869/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 1870/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1871/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1872/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1873/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 1874/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1875/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1876/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 1877/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1878/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1879/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1880/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1881/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1882/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1883/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1884/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1885/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1886/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1887/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1888/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1889/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1890/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1891/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1892/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1893/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1894/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1895/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1896/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1897/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1898/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1899/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1900/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1901/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1902/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1903/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1904/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1905/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1906/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1907/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1908/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1909/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 1910/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1911/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1912/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1913/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1914/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1915/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1916/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1917/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1918/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 1919/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1920/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1921/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1922/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1923/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1924/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1925/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1926/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1927/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1928/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1929/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1930/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1931/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1932/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1933/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1934/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1935/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 1936/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1937/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 102ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 103ms/step
Now training the model 1938/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step
Now training the model 1939/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1940/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1941/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1942/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step
Now training the model 1943/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1944/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1945/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1946/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1947/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1948/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 1949/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1950/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step
Now training the model 1951/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1952/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1953/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1954/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 1955/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1956/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 1957/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1958/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1959/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1960/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1961/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1962/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 1963/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1964/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1965/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1966/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1967/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1968/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1969/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1970/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 1971/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1972/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1973/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1974/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1975/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1976/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1977/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 1978/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 1979/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 1980/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 1981/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 1982/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 1983/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1984/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1985/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1986/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 1987/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1988/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1989/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1990/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 1991/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 1992/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 1993/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1994/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 1995/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 1996/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 1997/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 1998/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 1999/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2000/5600
MAE: 0.44923205232620245, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.4543892282247543, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.5055112452507019, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.5063707337379456, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.5160409662723541, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.5501246765851975, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.5708359527587891, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.5898485127687454, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.598156087398529, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.6009200127124786, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.6209640562534331, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.6238624141216278, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.6300478296279907, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.6345163732767104, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.6421627748608588, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.6444715872406959, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6489730063676833, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.6589588187932969, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.6656275681257248, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.6665548310279845, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.6699385811686516, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.6891725853681565, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.6892478972673415, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6971244856715202, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.6977494410276412, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.6979007499217986, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7019101973474025, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.7050580998063087, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7075721465349198, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.7077806682586669, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.708240001320839, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.719034685254097, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7210422322154044, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.7225016031265258, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7270399197936057, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7275242509320378, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7302863355576992, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.7349561529159545, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.7350464780330659, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.7355337245389818, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.7398571476936341, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7407054695487022, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.7472233951091766, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.748293634802103, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.7521494121551513, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.7522475079298018, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.7524505364894867, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.7537141907215118, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7539760146141051, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.756956045627594, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.7572228129208087, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.7584530577659607, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.7616818272173405, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7638712931275367, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 3
MAE: 0.7642340128421783, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.766611597418785, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.7721868157386779, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.7736304850578308, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.7754869047403334, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.77917187666893, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.7804029048681259, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.781268697977066, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7825557769536972, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.7839247748851774, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.7843046984672546, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.7852131143212318, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.7864446636140345, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.7922014999389648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7931723882555961, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7957228590250016, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.7963610444068908, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.7966920361518859, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.7968507007360457, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.7979138526916503, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7989478409290313, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.7993579388260842, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7995453178882598, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8007047452032566, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8024944529533388, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.8029407175183294, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8065524086952209, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8088162930011749, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.8100414131879805, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.8145017178058623, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.815883231639862, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.818424189388752, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.8203614697456361, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.8217294384241104, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.821796715259552, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8225435081720353, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8225992131233216, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8228256285190583, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8272567216157913, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8286043152809143, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.829092726111412, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.8309720594286919, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8311921567916869, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8319679604768752, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8342636034488677, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.8355040255784989, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.8355076717063785, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.8355222228765488, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8407961115837097, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.8429517626762391, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8432858943939209, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.845367192029953, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.8477217183113097, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.847765215218067, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.848490445792675, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.8486416981220245, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8504347673654558, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.8504518065452575, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.8521032073199748, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8527810308933258, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.8533767135273663, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.8534022096395493, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.853467783331871, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8545520440340042, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.8548299183249473, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.856945918560028, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.8580345873832702, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.8585323095321655, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.8589471125900744, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.8597166538238525, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.8612274858951569, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.8634447321891784, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8665681175142528, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8690516250133513, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8696977753043175, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8698150214403867, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.8700460231527686, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.870321896791458, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8706802502870559, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.8709582850337029, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8715643212795259, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8722456481158734, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.8723084300756454, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.8761679697632789, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.877728431224823, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.8789030776023864, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.8792613269090651, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.879950918674469, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8801492279767992, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8805919528007508, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.8806484047174454, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.8819353879094123, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8827753797769546, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8834430396556854, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8839577035903929, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8850332945585251, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8851434960216285, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8856113777160644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8859320417642593, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.891055073261261, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8913829044103622, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.8922944918870925, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.8924088195562362, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.8927029927372931, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8936026234626769, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8940398306846618, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8943172857165337, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.895813842177391, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8967934507131577, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.896855402112007, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.8971059186384082, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.8976442650556564, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8977669294774533, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8977671282291411, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.8979695290327072, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.898093959748745, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8989679548740387, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8993723618984223, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.8999445319175721, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.9011436626911162, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.9011730879545212, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9017507553100585, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9048452064394951, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9053405702114106, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9063540596961974, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9066628800630567, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.9081665650606154, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9094477133750913, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9098775107264518, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.90991151034832, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9107101503610611, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9139630962610245, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9151637361049652, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9161894142627716, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.9165384531021118, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9173578476905824, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.9177226185798645, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9182149291038513, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.9189472422599791, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.9202301412820816, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9206541166305542, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9246643335223197, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.9247426838278769, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9255966365337371, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9257613406181335, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9301387057304382, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9307725846767425, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9315259994268417, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9315887600183487, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9320501998066902, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.9322068907618523, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.9325052313804626, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.932658042192459, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.9331058443188667, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9340429635047911, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.934073592722416, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9344231162071228, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9377435848712921, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9385574072599411, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9394437425136566, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.9394940141439438, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9399453848600388, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.9409988552331925, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9410286727547647, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.941758621096611, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9419584976434706, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9421860694885253, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.9424801561236382, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.9429124925136566, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9444434449672698, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.944455280214548, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.9445515528917312, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.94577573543787, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9464023113250732, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.9474287229776384, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9474303965568541, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9483466252684594, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9486241743564605, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9488877713680267, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9490073682069777, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9495644915103914, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.9500214550495147, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.95034086561203, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9505964908599853, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9511664390563965, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9529300481081009, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9544366257190703, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9585937094688415, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9594492273330687, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.960048359632492, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9617911726832389, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.962413466334343, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.9641792745590209, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.9645057778656483, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9650960729122161, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.9651005196571351, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.9655772018432618, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.968866099834442, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9690815970897674, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.9691726677119732, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9695619601607323, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.9701418697834014, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.9706450001001358, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9713159010410308, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9724863637089729, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9735166597366334, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9755847886800766, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.975655225276947, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9763225027024746, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9764381438493729, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9772419661283493, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9773049818277357, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.9783877407312392, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9794594392776489, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9804305956363677, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.9811681048870085, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9815390795469284, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9816179441213606, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.9839325070977211, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9843457684516906, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9844231263399124, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9848730582594871, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9860930428504944, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.9862384550869464, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9868780481815339, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9869161476045847, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9872597247362137, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9876141175627708, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9880595417022704, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9884670023918151, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9887511775493621, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9895137530416249, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9899633886218069, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.989976371884346, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9915909414291381, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9927197054624557, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9934003980159758, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9938551109284163, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9938970268368721, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9974022626876831, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.9977785244584083, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.9981548563241958, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.998576426565647, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9989156053066253, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 0.9996528358459471, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0000552892684937, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0012471899986266, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.0012910754084587, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0028833688497543, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.0029092492461202, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0032648146152496, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0035855770111084, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.004199422955513, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.0048412487506866, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0070194438695907, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.0073151216506957, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.007539366930723, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.008902898490429, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0096306488513946, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0097092896699906, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.0113800749778747, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.0118906665444374, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.012331308722496, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0124546246528623, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.0126621712595223, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0127870547771454, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0133326277732848, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0133902642726897, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0146638751029968, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0158367025852204, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.0161958366632462, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0165661410093307, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.0172656841278076, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.017580284178257, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0193104926347734, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0202080655694008, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0206860706806182, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.020788191318512, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.0208191859722138, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.021362805366516, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0218432891368867, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.024474447131157, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0258346294164657, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.025874263048172, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0264765083789826, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0265686976909638, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.0265974358320236, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0266997136175633, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0278421477079391, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0282114908695221, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0289222631454469, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0289236233234405, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.029970814704895, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.031326590538025, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0318925619125365, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.0329352931976317, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0336357653737067, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0347794995307922, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0350257717072964, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0351076081991195, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0354762330651284, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.036913468003273, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0378706413507461, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0382787200808525, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0387021378278731, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0392061249017714, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.0393334809541703, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0404546320438386, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.041114322900772, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0419397552013396, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0420043069720268, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0427082359790802, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.042861752510071, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0435899123549461, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0439001698493957, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0440221458673478, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0442552716732023, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.044936180114746, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0469128773212433, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0472084954977035, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0483686850070952, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0483694434165955, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0490334808826447, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0501325458884239, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.0502329289913177, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0508269877433776, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.050846247434616, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0513658702373505, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0516811640262602, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.052442467689514, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0535908982753752, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0536984640359879, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0539305836558341, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0540950894355774, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0549490993022919, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0566131700277328, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0586347043514253, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0589376435279845, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0592548944056035, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0593107018470764, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0593721661567688, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0603716448545455, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.060785198688507, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.061256624817848, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0618835583925246, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.0619545805454256, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0624287099838257, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.0628159493803977, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0642847294807436, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0653473467826842, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0666196205317973, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0668340311050415, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0670043904781341, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0680034726858139, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0681829083561898, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0686921194791794, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0698782638311386, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.070581117272377, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0706403541564942, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0706441328525542, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0707555108368396, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.0710142259597777, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0713419616222382, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0713543117642401, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0715382680892944, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0716411457061767, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0717600125074387, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0722410993576048, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.072314890220761, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0732078731060029, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0751376688480376, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.0756921679973601, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.076735294610262, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0774131492376327, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.077769433259964, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0778125740587712, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.079217530965805, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0796695057153702, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0802641607820989, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.080408705949783, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0823623094558716, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.0825453953742978, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0833412739634514, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.083363504767418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.0846343660652635, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.084816481590271, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.0875321340858934, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.088230104804039, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.089275209903717, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0895144448280334, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0897042379379271, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0899222109317779, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0901152849197389, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.091097836256027, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0912890970706939, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.0924107954502105, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.092526517868042, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.0937770698070526, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0939628844261169, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.0941764459013938, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.0942743990421295, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0961927339434623, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0980191812515259, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.0987761557102202, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0994979084134102, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1010433673858642, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.1010906457901002, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1012975022792815, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1016623467803002, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.102550098657608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1033662649989129, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.103560108564794, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1037141622304916, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1044815737009048, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1052216048538686, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.105893760919571, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1064059302806855, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1065229997634887, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.1066235959529878, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.106881468296051, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.107204086303711, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1097685191631317, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.1100517600774764, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1117547646164894, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1118240520954132, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1119961798191071, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1121876972913742, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1122084472179412, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.1126086980700491, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1129486560821533, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1132547348737716, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.1142170131206512, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.114990519285202, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1166182503700255, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1168236628770827, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1170781210660934, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.118099238395691, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.1195269674062729, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.1196605435609819, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.119926503300667, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.1199304938316346, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1201983499526977, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.1202941477298736, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1210597709417343, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1215272591114043, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1229263305664063, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.1242185267806053, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1246203848421572, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.1251030206680297, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1253704309463501, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1275532352924347, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1283783781528474, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.12932218170166, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1293941140174866, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1294322653859854, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1295561168193817, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.130066397100687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1321519852280617, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.132416479587555, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1325382965803148, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.132710320800543, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1342642740011215, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1344717059135436, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.1350252070128917, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1365522240400314, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1366797506809234, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.13671632707119, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.13683682847023, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1370276898145675, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1381354246139526, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.1388242813944818, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.139181356191635, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1392349660396577, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1399101078510285, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1404609561562538, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1405060338974, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1424760193824768, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.1427434656620026, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1438857972621919, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.14406378865242, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1440683946609496, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1451707661151886, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1453259915709495, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.1462877541780472, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.147533522605896, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1477673414945602, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1478081093430519, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.148746195793152, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1492148265838622, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.149304316997528, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1499967626295984, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1504302397370338, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1529740154743195, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1547215626239775, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.155978034734726, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.156422911643982, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1575050727128982, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.1580805070698261, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.158447265625, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1589796741008758, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.159177005648613, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1593240574598311, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1593245733380317, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1599270601272582, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.161376729786396, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1619692549705505, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.1623557872772217, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1627293915748595, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.162863756775856, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1638499915599823, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1642675642967224, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1644506767392158, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1645051602125167, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1652860090732573, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1660752207636833, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.166352427005768, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1665527880191804, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1670567111968992, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1680036354064942, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.169631724357605, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1698786590099335, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1707190768718718, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1708724796772003, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1709176969379187, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1711886260509492, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1714068803787232, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1715517343878745, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1716131925582887, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.171757330060005, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.172731126099825, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1728973822593687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.1732904494404792, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1734163999557494, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1734553784132005, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1737823847532272, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.17412093436718, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.174130481481552, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1747539508342744, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.175797312259674, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.17603859603405, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1763556361198426, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1763800532817839, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1775286853313447, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1788064458072185, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1788590536117554, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1795523599386215, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1799266550540923, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1806045177578928, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.180729979634285, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1809096500873566, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.180922313094139, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.1812626705169678, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1822544205188752, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.182465680003166, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.185770552664995, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1870422676801682, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1885135564804077, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.1891784162521362, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1898424863815307, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1905379891395569, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1914721310138703, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.191513533949852, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1921170905828475, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.194228090405464, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1947636291980743, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1949568316936492, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.1957175029441713, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1959527790546418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.198767086982727, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1989935801029206, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1992623761892318, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2003934339284896, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.2006638564169407, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2006974831819535, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2020080180168151, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2022306070327757, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.203589000105858, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2036739408969879, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2037106618285178, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.204601080775261, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2083155289292336, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.208918525338173, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.2095628324747085, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2113046199083328, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.2121646761894227, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.213075375556946, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2134685341864824, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.2141593639850616, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.2149228692650795, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2149468020200729, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2150047063827514, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2155862197875975, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2164634570479393, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2179839033484459, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2180655002593994, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.2182347044348716, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.218765609025955, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2188456342220306, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.219880692720413, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2199360654354094, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.220035719871521, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2209561395645143, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2219280109405517, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.2228133187294006, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2234574933052063, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.2243560045957564, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.225172500371933, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2251747727394104, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.2253757685422897, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2259368613362311, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2259837571382524, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2270101189613343, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2277037177085877, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2277079105973243, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2284138917922973, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2284859031438828, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.2297819708585738, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2303008351325988, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.231753465592861, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2326258662939071, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.232729040145874, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2327508989572524, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2328656063079833, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2329449695199728, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2343170046806335, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2348447115421295, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2349895792007444, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.235126222848892, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2359618828296661, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2366228699684143, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2372017860412599, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.2374689251780508, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2375131607055665, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.2376206934452056, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.2393899188041686, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2395631062984467, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2406694177389146, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2414695698022844, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2421698033809663, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2431426808834076, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.243456225156784, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2442595219612123, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445047547221182, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445318520665167, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2445571527481079, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2451037096977235, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.24555746614933, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.245790148139, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2461296141147613, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2464210275411607, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.24697012758255, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.247449083685875, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.248412902712822, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.248858909368515, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2492913488149644, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2495196838378906, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2500996903181076, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2507887959480286, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2524703726768494, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.25447074174881, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2545394882559777, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2553999902606008, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.255672797679901, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.2559172365665436, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2568185716867446, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.2572679624557495, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.257878007173538, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.2581990916132928, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2583328559994698, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.258658321261406, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2588403031826019, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2594862492084502, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2596591730117797, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.260091652035713, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2610995729118586, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2618624180555345, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2627122163772584, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.264324443101883, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.2644008711576462, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2649783864617348, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.265193262696266, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.265494620859623, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2656156569719315, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2657224659919737, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2674663960933685, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2675757185220717, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.2684665739536285, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2692975685596466, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2693283901214598, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.269498236835003, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2702135741710663, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2706028597354888, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2721146658658982, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2722176745533944, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.2730072708129883, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2735145252794027, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.273655313551426, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2745149836540222, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.2748253226280213, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.274883782863617, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2751694118976595, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2755898342132568, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.2756651029586792, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.276469317138195, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2764834616184235, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.276766179561615, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.2771128609776496, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.2776659578084946, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.2794184237718582, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2802399591207503, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.280376872420311, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2806914303302765, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2807814006805418, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2820487205982207, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2824026124477386, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.2824575755596161, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2833797991275788, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.283564223408699, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.2836234407424925, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2850175187587738, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.2850350186824797, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2852699309587479, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.285674626737833, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2863050699234009, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.286460910797119, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.2865045615136623, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.287969485282898, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.288068825006485, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.2883574829101563, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.2889757871627807, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2893567517995834, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.2893610820770263, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2896505728363992, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.292645646929741, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2938129652142525, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2940906286239624, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.295846273303032, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2961256757974624, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2966798727512359, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2968990956544875, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.2980957542657852, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2983018473386765, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.2983676288127899, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2986110941171645, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.300602905511856, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3014185265302658, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.301810483932495, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3023189607858658, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.3044717342853545, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3047610018253326, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3049516544342041, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3057035731077193, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3059039340019225, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3061656594872475, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.306288183093071, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3067478083670139, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.307906848192215, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.308551162481308, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3097322063446044, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.310144631922245, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.310320417881012, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.311190249443054, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.3117063555717468, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3117224589586258, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3118670601844786, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.3129359312355517, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3131315932273864, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3148029550909996, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.314983524441719, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.3154627685546874, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.315994225502014, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.3160212501883506, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.3163570433855056, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.3174623684883116, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3178813235759734, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.318626489162445, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3193671987056732, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3196965992450713, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.3201689782738686, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.320310755252838, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3228353456258772, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3233416841030121, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3245241001844406, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.3249909937381745, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.32668805873394, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.326729215234518, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3276256430149078, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3277433071136475, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3277980056256056, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3278208632469177, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3283361272811889, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.328814271092415, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3288901090621947, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.3297507659196852, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.329865675032139, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.330053715467453, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3306114077568054, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3307581782341003, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.3329135417938232, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.333287979722023, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3353062634468078, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.3356382161378861, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.3358825981616973, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3362213716506957, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3372200460433958, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3379688190221786, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3385834038853646, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.339330087661743, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.339451030254364, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.34064542388916, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.3414656937122345, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3416240200996399, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3419297322630883, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3421750948429108, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.3426572501659393, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3429890334606172, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3434198067188263, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.3457993969917297, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3459816489219665, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3463023979663848, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.347072219848633, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3473331645727158, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3473761591911315, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3474469230175017, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.347991520166397, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.3480030301809311, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3487317115068436, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3493617281913757, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3503839701414109, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3509874577820302, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.351419883966446, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.351424762159586, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3517092064619063, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3526166605949403, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3532036989927292, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.353647212743759, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3544619619846343, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.356932810306549, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3582237632274627, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3583797693252564, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3587980136871338, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.3591956872940063, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3604056553840636, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3605182573795318, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3608753430843354, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.360919356405735, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.36185402572155, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.3618554845452309, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3634249181747435, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3647809019908308, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3662926003932951, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3669246363639833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3669361785054206, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3687674403190613, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.369115690946579, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.3691217392683028, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.369421910047531, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3701489572525023, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.3702292048037052, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3712328106164933, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3716639697551727, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3731223106384278, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3742104530334474, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3743433923721313, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.374400000333786, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3745349810123444, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3754923090934752, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3759255588054657, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.377598753631115, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3777845860123634, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.379000167608261, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3790293709039687, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3798093155622482, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.380611956551671, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.3807407736778259, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3814833270311353, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3817279160022735, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3824641168117524, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3830936313271522, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3837285697460175, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3843189630508423, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3848715335726738, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.3853567422032356, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.38557870388031, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3882122099995613, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3890215158462524, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3895928428173066, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3898489402532577, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.3899388880729675, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3905784369707106, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3914799213409423, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3919424176216126, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3920154005289078, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3922474757432937, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.392300127506256, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3928238101303578, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3940250068902968, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3940303496122362, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.3940454349517821, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3941033065319062, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.3943568453788757, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3960764006376265, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.397471097111702, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.398580132484436, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3993730098605155, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3998017713427544, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3998348641991616, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4009284124374388, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.401613317489624, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4020033001899719, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4027880776524544, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4036362636089326, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4054688379764557, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.406106551170349, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4069226239994168, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4074744403362274, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4082462356090546, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4082952439785004, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4096608672142028, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4111608282327652, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4112306044101715, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4112409591674804, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4138897690773011, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4149966708049178, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4150501847267152, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.415557039141655, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.415991908311844, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.4165477008819578, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4168289752006529, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.416896034836769, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.417103001832962, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.417250825881958, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.417263792514801, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.4173446297645569, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4173992395401, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4175143394470215, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4177747431993484, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4178217158317565, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.418121071457863, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4194887631237507, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.4196272314190863, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4200205281972884, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.420102985203266, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.420616219997406, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4210114166736603, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4216918766498565, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4223053634166718, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.4227982044816017, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.4231562033891678, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4233985096812247, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.424767118692398, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4264571014642715, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4270993203520774, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4273701775074006, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4287651569247246, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.430337804555893, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.4304524869918822, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4315102088451386, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.431624525785446, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.4326510564088821, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4335243642926216, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.4341230276823045, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4341457191705704, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.4346961483955383, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4367408440113068, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.437243476629257, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4375874012708665, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.4377964706039055, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4384397537708282, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4384685591459274, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4393303513526916, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.4411447689533232, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4412494378089904, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.4426380264759064, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.443949596643448, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.4444691263139249, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.445134162902832, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.445313729405403, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4463425070047378, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4465025444030761, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4470076189041137, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.448527179777622, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.4491006284952164, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.449397428393364, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4501372691243888, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4504877673387526, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4511441321372984, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4513078689575196, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4522238838672639, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4530203363522887, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.4546473712921142, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4548569121062755, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.4566139028072356, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.456911626458168, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.457654752135277, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.458910585194826, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4591062173247338, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4601812422275544, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4608954668045044, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4611959837973116, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4612959787845612, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.462384913921356, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.4642929005622864, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4665672109127044, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4671219396591186, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4683350431919098, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.468501843690872, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.4686041954755784, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4701347068548203, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4710909113883972, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4725461230278014, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.4727415370941164, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4728660807609557, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4734120745658874, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.474275733947754, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4753249781131743, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.4760962934494017, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4763009814471004, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4787994503974915, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4792503386735916, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4792756605148316, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4794279308319092, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4799288318157195, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4800875812768937, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.4802428305745123, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4808689299821853, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4812486829161642, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4813525319099425, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.482943373978138, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.4842892513275145, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4845762537717817, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4869631366729734, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.488746618539095, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4895776227712632, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4895888016223906, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4900921599864958, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4907044175863267, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4908448525369167, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.49088915219903, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4929342374801635, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.4937691271305085, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.494155466556549, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4947805511951446, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4948421076536178, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.495291511774063, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4956667230129241, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4957764327526093, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4959711283445358, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4964612604379652, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4964879512786866, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4971350864171982, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4979722678661347, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4980430529117583, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4989364476203917, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4991245688796042, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.4994183871746063, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4995971113443374, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.4997069239616394, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.499851671665907, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4999164092540742, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.500087587594986, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.500456394314766, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5011395947933195, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5012647286653518, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5016118527054787, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.5036670804023742, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5045835668146608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5049042735099794, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5050567955970764, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5051952838897704, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5055404663085938, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.5057408676147461, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.5059518699645995, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.5072108428925275, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.50731849527359, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5075225130319594, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.5076407644748688, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.509845276236534, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5100231561660766, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5101907598972322, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5103061364889143, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.5113538340330124, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5129951238632202, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5145435886383054, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5155210123062133, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.5164628878831863, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5170335814952849, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.517641043663025, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.519034262061119, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.5200535521507264, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.5201763973236084, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.520719330072403, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5208396956920622, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.522092010140419, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5223910586833953, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5231809512376784, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5233807862997053, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5236464619636536, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.524057889342308, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5242240205407143, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.5244111554622648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5246812748908998, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.5270265519618988, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5273205861449242, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5279604229927064, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5281553239822387, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5291513056159018, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5297442295253276, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.5301416087150574, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5313348803520204, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5322370147928595, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5324755446910856, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.53347171998024, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.5336250097751616, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5342887969017027, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5359099846929312, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.5370842606425286, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.537454183578491, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.5386232321262359, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.5391005964279174, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5406735167503356, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.540907790184021, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.541915274143219, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5431840152740477, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5437105374336242, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.544145956993103, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5442402992248536, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5446757645010947, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5456209421157836, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5460962698459624, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5477801249027252, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.549153311729431, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5492777690887451, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.5493997485041617, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.5495794266462326, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5497839406728744, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.550776258587837, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5511295483112335, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5512107179164887, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.5523703013658523, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5530784014463426, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5532853341102602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.5550355405807494, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.5552442226409913, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5555772542953492, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5556509986519813, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5564892768859864, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5566252875328064, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5576226354241371, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.558823463320732, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.5592271324843168, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5593781995773317, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5623150997459887, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.5631063163280488, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5637934196591377, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.5655289278030395, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.565563789486885, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5657193840146064, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.5673263580799102, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.567548280954361, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.5682341412305831, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5687083512544633, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5697367310523986, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.5707295604646205, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5712229553461075, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.5720596016049384, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.5734783191680908, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.574022530078888, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.574155135512352, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.5741650045514106, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.5742400567177683, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5749350206851958, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5771525580883026, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.577446422100067, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.579625639438629, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5796981792747975, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5804679021835326, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.5807987065315245, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5816649533808231, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.581820364356041, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.5829287246465682, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.584499255180359, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5863343358635902, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5872633740901947, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.587926486134529, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5883457335829736, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5883658841848374, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5888893518447875, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.5890283495783806, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.589477723836899, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5898203552365302, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5912233397960662, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5920956704616547, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.594790741920471, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5955701887607574, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.5957105785608292, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5961232051849366, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.5961959153413772, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.5964675101637842, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.596790479183197, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5973533154129982, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5979499683380127, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.601586233139038, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6016839895248414, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.6028615951538085, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6049754738807678, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.6050685750246045, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6052088755369187, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6054216206073761, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.6056024137735367, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6068544074892999, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.6088911123275758, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.608901499390602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.609053906917572, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.612512287557125, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.6132668242454529, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.613269971370697, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6134663076400755, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.613594752550125, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6138822841644287, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6142002556324004, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6145376892089842, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.6149865255355835, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.6161996845006943, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.617002248764038, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6180418342351914, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.6180767915248873, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.6183684871196746, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6190730199813843, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6220894753932953, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6251214444637299, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.625308014512062, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6254666239619255, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6258640397191049, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.625891238451004, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.6261632130146026, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.6262701154351233, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6269377813339232, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.6271870419979095, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.6296569752693177, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6303403396606444, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6305015790462494, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6314718604683875, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6351746678352357, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.63598140335083, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.636107897758484, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6364457309246063, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.636586892604828, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.637423395037651, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.6378771352767945, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.638349692583084, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6385496586561203, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.6388198778629302, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.640715942144394, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6417351350784302, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.64206120967865, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.6422480301856992, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.6438249543309211, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.6442171589136123, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6450113848447798, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6452662916183471, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6464651541709898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6472749561071396, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6479135484695433, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.6482768373489378, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6488916521072388, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.649846633076668, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.6500540823340415, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6501185879707336, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.6518700302839278, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.6521053105592727, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.653188872396946, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6535077021121978, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6549458341598509, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.6553491071462632, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.655961772918701, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.6563528583049774, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.65910815179348, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.6596220955848693, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.6612754479050635, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6638370203971864, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.6641271338462829, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6641634151935576, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.6643911854028701, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.6646652817726135, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6652281806468963, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6665068343877791, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.666830281972885, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.667265977025032, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.667952594280243, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.6682733998298644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.668950484752655, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.6699607685804367, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6703035757541655, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6704502121210099, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6715821504592896, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6718625054359435, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6783748769462108, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.6789251744747162, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.6799230308532713, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.683435659408569, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6850620613098144, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.686312511563301, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.688024725317955, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6880490038394929, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6882670879364015, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.688455948293209, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.6892227978706358, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6893699929714203, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6908744305968284, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6909005150794982, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.6913443308323621, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6919383273124695, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.6946387724876402, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6950820374488829, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.6956776916980743, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6965408549308776, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6968272387981416, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.6989871129989624, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.6999855488538742, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7018252894878387, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7022667751312255, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.7030796751976012, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.703391656398773, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7055030322074891, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7068614826202393, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.709457209765911, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7100847721099854, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7101020709276198, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.710202185988426, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7112806544303893, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.7120026067495346, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7122117028236388, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.7126088634729384, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7126224145889282, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7130378901958465, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7133623480796814, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.7134972870349885, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7135540217757224, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.7136183590888976, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7139797315597534, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.7141844660043717, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.7154318228363992, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7156692714691162, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.7156890586614608, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.716011992841959, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.716227039694786, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.7176924601793289, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.7179230451583862, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7180974708795547, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.7187690216898919, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7190667424201966, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7209585849046707, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7218889718055723, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.7219003841876983, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.722057311296463, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7230394825935362, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7239278957247735, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.724538342654705, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7250207290649413, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7252617985457182, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.7302283601760862, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7303747057914733, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7314121589660645, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.7319075167179108, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.732295435667038, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7325358912944793, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.7339372055530546, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.7343085520565509, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.735089676141739, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.735130075365305, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.7356451585143806, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.7388700738549232, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.7392203407287596, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.7397438303232193, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.7400204854011534, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7401804089546205, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7407579469680787, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.741139496922493, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.742418247461319, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.7430600957870481, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7459279820919036, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7463804125785827, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.746958520323038, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7479827032089232, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7484186097979546, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.749409262895584, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.7504271820783615, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.7512264298200606, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7515728995800017, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7518246591091156, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.7520624340772628, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7529126749038695, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7535233736038207, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7537784278392792, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7539441004991532, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7549011439681053, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7549213156700134, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7571703345775602, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.7582494781017304, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7583915249109268, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.7594976902008057, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7640695543289184, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.7645261989831922, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7649804100990294, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.7658147633075714, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7662122145891188, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7684044466018676, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7684059948921202, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.76896444606781, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.7696022171974182, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.7696832486093044, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7704019293785094, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.7754646204411983, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.776850337266922, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7772946999073027, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7780107603073119, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.7803962023258209, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7810661047697067, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7826528208255765, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7828125361204148, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7845523595809936, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7855927095413207, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.7878951699733734, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.7881029949188236, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7883336112499237, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.7886042892932892, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.7896199986934662, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7898313686251641, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7901215612888337, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7933157370090484, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.7934389099478723, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.7950314640998841, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7952616260051726, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7978993713855744, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7979341865181921, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7995828227996824, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8003283069133758, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.8008347842693329, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.8036522538661957, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8052691490650177, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.805625283718109, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8058169708251952, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8060016632080078, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.808211790204048, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8103778049945831, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.8106041059494018, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8157711625695228, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.8184639797210693, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8185790256261825, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8194591376781464, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8202139214277266, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8229052529335021, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.8235276312828064, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.82455791836977, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.825089852809906, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.8284483242034912, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.8287240147590638, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8326948791742326, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8328437447547912, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.8328442410230636, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8347806572914123, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.835990902841091, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8376560673713684, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.8395919964313507, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.8397361130714416, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.8406830847859381, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.840829442501068, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.8408745527267456, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8418196067810058, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8430962954312562, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.843495047211647, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.844065702021122, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.8443952932953835, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8455752835273742, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.847792100906372, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.8481660813093186, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.848219861268997, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8482250349521636, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.8491930175423623, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8547063797712326, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8550118267536164, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8550261214971542, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.8555288121700286, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.856734118670225, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.860503324985504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8607090876102448, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8613657430410384, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.8617945508956908, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8659023777246475, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.86623490190506, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.8668766990900039, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8671984914541244, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8677148163318633, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.8682186007499695, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.868643239200115, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.8694670648574827, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8715872623622416, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.8730671093463898, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8736142352819443, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8749783651828764, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8759938330650328, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.8770955029726024, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.8790963859558105, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8791436882019041, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.879826320707798, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.8799741716384886, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8811773941516876, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8823429703712464, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.8838593558073042, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8841468945741653, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.8844422221183776, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.8844440221786498, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8856610432863234, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.887393186300993, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8878778967857361, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.8882436275482177, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.888327965259552, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.8921154890060425, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.893958365917206, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.8963519916534426, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.8971855373382567, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8974021569490431, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8984763860702514, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.8993401646614074, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9000274062156677, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.9006402597427368, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9028469221591948, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9032050118446349, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9034287571907043, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.903832612991333, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9049101696014403, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9051041648387907, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.9059335265159607, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.9063168935477735, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9075096354484558, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.908993689775467, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.9093120262622834, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.90933727478981, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9104237303733824, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.9105084453374146, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.9113574192523957, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.912921197772026, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9149996566772465, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9154980707168576, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.915706233739853, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.9159319460392, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.9169115905761713, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.9172073125839233, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9172749161720275, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9180502713322638, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.9191463600695133, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9250909745693208, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9253533780574799, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.9264496564865112, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.9268941955566405, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.9269641075134278, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9289744840860366, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.9300405592918395, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.9322919920682906, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.932523000240326, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9329437346458433, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9349317388534548, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9366389416754246, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.937361756324768, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.938294498682022, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.938849555015564, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9409704045057297, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.94138206410408, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9421065837740898, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.943249243557453, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9463834375739097, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.9469791264533995, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9517008786201473, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9523427203893662, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.9538272678852082, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9566843718886375, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.9572237179279326, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.9573579061031339, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.9586571335792542, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.9596466200351714, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9624540791511536, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9631543610841036, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.9665032938122748, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.966683383464813, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.96797962641716, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9700331091880798, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.9701451659202576, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9730967149734497, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.9736441643238067, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.9745340392589568, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.974722777366638, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.975356815934181, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9786889151334761, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.9798052716255186, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.984850284576416, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.9875781551599503, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9876585111618041, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.9884053320884703, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9917332785129545, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9922114973068237, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.9955444917678833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.9956910174191003, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.995696872472763, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.9960896492004394, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.998582165375352, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.000362291991711, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.001096342563629, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.007160742580891, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.0084685068130494, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.0128101289868354, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.0149026572704316, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.0171797440052033, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.017586702108383, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.018459497451782, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0184739112854, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.0250530049800872, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.0266250342130663, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.0272196531295776, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.03167760848999, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.0345093579292297, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.037584570109844, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0375961080789566, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.0405101127922536, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.0412771478891374, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.042128403544426, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.0435629086494442, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.044292601466179, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.044934856891632, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.046544522047043, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.0476628035902977, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.048649752318859, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.048884205579758, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0499174699783325, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0516196534633635, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.051832914352417, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.052586218774319, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.052972470283508, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.0537389397621153, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.054859972000122, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.0574438900351524, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.0579430595040322, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.0591199562549596, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.0594616458415986, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0620893602371213, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.062719964981079, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.063803866863251, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.064622406721115, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.0648088455200195, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.0676073328256606, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.0677975997924802, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.070836775749922, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.071325051784515, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.073542498111725, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.075014959335327, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.075873627513647, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.077954441308975, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.078225139141083, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.0814577147960662, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.086098995804787, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.087084526181221, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.088319371700287, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.0894282147884367, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.089542101383209, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.0899966076612477, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.0902798332870005, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.0909157947301864, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.0912524461746216, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.0923535064458845, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.0936098918914796, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.094252688169479, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.0948588104248045, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.095119853496551, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.104536937236786, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.1071963535547256, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.10782697057724, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.113142045021057, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.113944552898407, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1142090814113614, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.1147344068288803, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.11633536529541, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.1179665670394896, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.1224231884479523, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.1248700964450835, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.128646969795227, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.129011590838432, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1299195842742917, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.1311943118572234, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.132686434745789, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.1350850269794464, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.138095583438873, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.139706157207489, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.1420151562690735, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.1452305309474466, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1454857543706893, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1468250691890716, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.1494251461029052, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.1497225151062014, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.149927827835083, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.1511641428470614, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.1531429812908174, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.1553255156874656, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.1580598936080935, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.158605764865875, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1591765675544736, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1595361099243164, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.1617755131721497, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.1620195138454434, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1629947276115415, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.165790997505188, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1660262048244476, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1661195502281188, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.1678628311157224, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.169298859000206, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.173025022506714, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.1731034190654754, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1736091212034223, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1742076174020766, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.1752003893852234, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.1792540296912195, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.180105555534363, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.180269846320152, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.1819722623825073, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.1823269591331482, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.1845811114311218, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.185506668686867, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1863368556499485, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.1881432042121887, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.190774138331413, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.191343186855316, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.1957105457782746, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.1980114564895628, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1985860452651975, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.1995634467005734, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.2004692912101746, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.207610981225968, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.2130393773317336, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.2133362382650374, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.2141740725040435, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.2143728256225588, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.214481160402298, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.214598279505968, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.2148191576004024, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.2191628173589706, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.222566197872162, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.2233117491602896, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.223574324011803, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.2276251718997955, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.230036625444889, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.231529727935791, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.2344828338027, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2354313850402834, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.2391082451343536, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.2394701898097993, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.2494699362516406, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.2513430134058, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.25994597530365, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.2620479092597963, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.262953279972076, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.2630436973571775, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.2641238676309583, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.2698918521404265, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.2724695103168484, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.2730577841997146, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.273338125705719, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.2782123403549193, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.282795798778534, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.2837203428745267, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.2841161929666995, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.2864682302474977, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.2885433718562127, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.2902920633554458, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.2917884871959684, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.293800139427185, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.2940399603843686, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.298683853626251, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3011642665863037, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.301778863430023, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.3044723675251007, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.306535981655121, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.3067020059227943, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.307020859479904, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.308794270515442, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.308952045440674, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.3119770706295966, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.3135028915405274, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.315435642004013, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.317508618593216, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.318241516113281, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.3199576113224034, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.320935190081596, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.324331745624542, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.324379640996456, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.3245733234882353, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.32524663066864, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3285417170524596, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.3304125086069107, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.332355314552784, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.3335624427795407, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.3348226294517516, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.3378108143806458, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.3387243807315827, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.3440734834671018, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.348347647666931, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.354297457695007, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.365408286511898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.3685140312314035, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.3705247566699983, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.3762458102703095, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.3782636300325395, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.380768096446991, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.3813441932201385, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.382840000152588, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3830521211624145, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3893957302570343, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.3901876912117004, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.392253859400749, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.401200239419937, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.4102375656962396, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.410561458826065, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.412057755947113, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.412959004998207, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.413552816271782, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.418061542510986, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.4186100766658782, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.4239822015166284, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.42441800570488, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.4303963069915766, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.43413844871521, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.440752312541008, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.4441592321395875, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.4442741751670836, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.452475400328636, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.4568203092217447, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.45941830432415, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.4635427419692277, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.466722925066948, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.4671855211257934, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.4684245321750637, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.4746531563997265, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.480398269057274, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.481179675579071, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.488544668316841, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4916726559996603, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.4919800058603285, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4921403542757035, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.4977822482585905, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.501889357402921, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.5022410616874695, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.514095245361328, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.5182691488265987, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.519612734079361, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.5208762288093567, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.534331890940666, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.535784955382347, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.5379346877336504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.5436976120471955, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5454398469924926, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.54894557762146, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.5506374225616453, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.558982105731964, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.5631247535943986, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.5654521927833556, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.56702621281147, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.571935909986496, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.575710658788681, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.5760038599967956, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.5768654661178587, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.578273500561714, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.588696889638901, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.5891943722963333, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.590064583778381, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5954928741455077, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.59977793264389, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.601329207420349, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.601901505947113, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.602644822359085, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.6147365542054173, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6267674342393876, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.628404844239354, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.629312935590744, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.631418771961704, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.6398198561668393, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.664280910849571, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.6680451110601426, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.6702974177226424, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6855965719223023, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.688511425256729, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.701877100944519, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.7139180302619934, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.7152185292243955, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.722136028289795, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.723188541889191, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.724814936637878, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.735076573848725, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.7379768388271333, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.739984595775604, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.749227763772011, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.757665436029434, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.761810897350311, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.7712779359817503, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.774302265167236, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.788458643913269, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.7929939703941344, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.801421770572662, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.811801800251007, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.8260716676712034, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.8320538507699964, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.833484319031238, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.854437692642212, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.8773375306129454, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.888055741786957, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.8924584493637084, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.8952078745365144, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.89608642911911, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.896396240711212, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.8971294522285462, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.9176550731658937, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.929804211854935, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.9365611748695373, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.9565970771610735, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.984579122066498, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.987040515422821, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 3.0039432943463327, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 3.0065708861351013, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 3.0183619604110716, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 3.018407331466675, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 3.0264869556427003, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 3.035234998345375, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 3.049882178068161, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 3.0728003606796266, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 1
MAE: 3.0774910867214205, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 3.090915502667427, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 3.1046783730983734, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 1
MAE: 3.1190274552106856, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 3.1285714404582974, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 3.1315883890390395, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 3.1362825334072113, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 3.1394094079732895, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 5
MAE: 3.1818889126777647, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.1884463267326355, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.19628550863266, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.240051233768463, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.2574724512100217, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 1
MAE: 3.2774167344570158, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 4
MAE: 3.4833023028373717, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 3.621103637099266, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 5
Results saved successfully in dir `results/test2/NN_results_2000_lessData.pkl.pkl`.
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2001/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2002/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 2003/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2004/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2005/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2006/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2007/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2008/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2009/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2010/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 2011/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2012/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2013/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2014/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2015/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2016/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2017/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2018/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2019/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2020/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2021/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2022/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 2023/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2024/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2025/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2026/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2027/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2028/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2029/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2030/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2031/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2032/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2033/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2034/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2035/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2036/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2037/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2038/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2039/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2040/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2041/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2042/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2043/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 86ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 86ms/step
Now training the model 2044/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2045/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2046/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step
Now training the model 2047/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2048/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2049/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2050/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2051/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2052/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2053/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2054/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2055/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2056/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2057/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2058/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2059/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2060/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2061/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2062/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2063/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2064/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2065/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2066/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2067/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2068/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2069/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2070/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2071/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2072/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2073/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2074/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2075/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2076/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2077/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2078/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2079/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2080/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2081/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2082/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2083/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2084/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2085/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2086/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2087/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2088/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2089/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2090/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2091/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2092/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2093/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2094/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2095/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2096/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2097/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2098/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2099/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2100/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2101/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2102/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2103/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2104/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2105/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2106/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2107/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2108/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2109/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2110/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2111/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2112/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2113/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2114/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2115/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2116/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2117/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2118/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2119/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2120/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2121/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2122/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2123/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2124/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2125/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2126/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2127/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2128/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2129/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2130/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2131/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2132/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2133/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2134/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2135/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2136/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2137/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2138/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2139/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2140/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2141/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2142/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2143/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2144/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2145/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2146/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2147/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2148/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2149/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2150/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2151/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2152/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2153/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 2154/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2155/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2156/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2157/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2158/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2159/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2160/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2161/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2162/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2163/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2164/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2165/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2166/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2167/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2168/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2169/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2170/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2171/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2172/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2173/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2174/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2175/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2176/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2177/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2178/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2179/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2180/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2181/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2182/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2183/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2184/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2185/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2186/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2187/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2188/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2189/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2190/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2191/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2192/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2193/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2194/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2195/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2196/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2197/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2198/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2199/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2200/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2201/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2202/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2203/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2204/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2205/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2206/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2207/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2208/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2209/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 2210/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step
Now training the model 2211/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 2212/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 2213/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 2214/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2215/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 2216/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2217/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2218/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 107ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 107ms/step
Now training the model 2219/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2220/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2221/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2222/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2223/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2224/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2225/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2226/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 2227/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2228/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2229/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2230/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 2231/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step
Now training the model 2232/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2233/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2234/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 2235/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2236/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2237/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2238/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 2239/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2240/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2241/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2242/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2243/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2244/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2245/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2246/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2247/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2248/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2249/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2250/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2251/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2252/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2253/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2254/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 2255/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2256/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2257/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2258/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 2259/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2260/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2261/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2262/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 2263/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2264/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2265/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 2266/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2267/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2268/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2269/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2270/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2271/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2272/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2273/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2274/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2275/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 82ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 82ms/step
Now training the model 2276/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2277/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2278/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2279/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2280/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2281/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2282/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2283/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2284/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2285/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2286/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2287/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2288/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2289/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2290/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2291/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2292/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2293/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2294/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2295/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2296/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2297/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2298/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2299/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2300/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2301/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2302/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2303/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 2304/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2305/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2306/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2307/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2308/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2309/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2310/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2311/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2312/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2313/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2314/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2315/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2316/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2317/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2318/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2319/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2320/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2321/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2322/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2323/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2324/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2325/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2326/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2327/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2328/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2329/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2330/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2331/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2332/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2333/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2334/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2335/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2336/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2337/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2338/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2339/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2340/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2341/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2342/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2343/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2344/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2345/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2346/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2347/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2348/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2349/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2350/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2351/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2352/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2353/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2354/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2355/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2356/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2357/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2358/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2359/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2360/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2361/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2362/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2363/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2364/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2365/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2366/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2367/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2368/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2369/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2370/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2371/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2372/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2373/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2374/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2375/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2376/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2377/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2378/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2379/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2380/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2381/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2382/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2383/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2384/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2385/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2386/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2387/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2388/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2389/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2390/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2391/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2392/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2393/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2394/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2395/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2396/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2397/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2398/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2399/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2400/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2401/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2402/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2403/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2404/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2405/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2406/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2407/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2408/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2409/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2410/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2411/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2412/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2413/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2414/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2415/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2416/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2417/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2418/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2419/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2420/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2421/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2422/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2423/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2424/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2425/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2426/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2427/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2428/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2429/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2430/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 255ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 255ms/step
Now training the model 2431/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2432/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2433/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2434/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2435/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2436/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2437/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2438/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2439/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2440/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2441/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2442/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2443/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2444/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2445/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2446/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2447/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2448/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2449/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2450/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2451/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2452/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2453/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2454/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2455/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2456/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2457/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2458/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2459/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2460/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2461/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2462/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2463/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2464/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2465/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2466/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2467/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2468/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2469/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2470/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2471/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2472/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2473/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2474/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2475/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2476/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2477/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2478/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2479/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2480/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2481/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2482/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2483/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2484/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2485/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2486/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2487/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2488/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2489/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2490/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2491/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2492/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2493/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2494/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2495/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2496/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2497/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2498/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2499/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2500/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2501/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2502/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2503/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2504/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2505/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2506/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2507/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2508/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2509/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2510/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2511/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2512/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2513/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2514/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 415ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 415ms/step
Now training the model 2515/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2516/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2517/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2518/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2519/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2520/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2521/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2522/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2523/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2524/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2525/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2526/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2527/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2528/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2529/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2530/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2531/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2532/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2533/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2534/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2535/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2536/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2537/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2538/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2539/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2540/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2541/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2542/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2543/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 2544/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2545/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2546/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2547/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step
Now training the model 2548/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step
Now training the model 2549/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step
Now training the model 2550/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 2551/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2552/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 2553/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2554/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2555/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2556/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2557/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2558/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2559/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2560/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2561/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2562/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2563/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2564/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2565/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 108ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 108ms/step
Now training the model 2566/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2567/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2568/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2569/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2570/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2571/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2572/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2573/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2574/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2575/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2576/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2577/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2578/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2579/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2580/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 336ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 336ms/step
Now training the model 2581/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2582/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2583/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2584/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2585/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2586/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2587/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2588/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2589/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2590/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2591/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2592/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2593/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 102ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 102ms/step
Now training the model 2594/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2595/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2596/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2597/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2598/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2599/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2600/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2601/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2602/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2603/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2604/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2605/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2606/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2607/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2608/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2609/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2610/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2611/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2612/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2613/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2614/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 2615/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2616/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2617/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2618/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2619/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2620/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2621/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step
Now training the model 2622/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2623/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2624/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2625/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2626/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2627/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2628/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2629/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2630/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2631/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2632/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2633/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2634/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2635/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2636/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2637/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2638/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2639/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2640/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2641/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2642/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2643/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2644/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2645/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2646/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2647/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2648/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2649/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2650/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 2651/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2652/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2653/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2654/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2655/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2656/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2657/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2658/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2659/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2660/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2661/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Now training the model 2662/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2663/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 35ms/step
Now training the model 2664/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2665/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2666/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2667/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 2668/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 2669/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Now training the model 2670/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2671/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2672/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2673/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2674/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2675/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2676/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2677/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2678/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2679/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2680/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2681/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2682/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 2683/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2684/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2685/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2686/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2687/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2688/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2689/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2690/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2691/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2692/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2693/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2694/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2695/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2696/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2697/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2698/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2699/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2700/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2701/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2702/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2703/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2704/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2705/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2706/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2707/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2708/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2709/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2710/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2711/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2712/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2713/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2714/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2715/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2716/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2717/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 2718/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 2719/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2720/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2721/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2722/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2723/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2724/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2725/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2726/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2727/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2728/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2729/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2730/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2731/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2732/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2733/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2734/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2735/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2736/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2737/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2738/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2739/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2740/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2741/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2742/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2743/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2744/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2745/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2746/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2747/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2748/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2749/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2750/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2751/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2752/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2753/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2754/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2755/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2756/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2757/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2758/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2759/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2760/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2761/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2762/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2763/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2764/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2765/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2766/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2767/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2768/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2769/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2770/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2771/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2772/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2773/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2774/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2775/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2776/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2777/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2778/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2779/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2780/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2781/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2782/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2783/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2784/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2785/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2786/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2787/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2788/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2789/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2790/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2791/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2792/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2793/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2794/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2795/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2796/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2797/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2798/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2799/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2800/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2801/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2802/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2803/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2804/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2805/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2806/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2807/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2808/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2809/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2810/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2811/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2812/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2813/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2814/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2815/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2816/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2817/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2818/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2819/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2820/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2821/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2822/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2823/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2824/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2825/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2826/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2827/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2828/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2829/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2830/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2831/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2832/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2833/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2834/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2835/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2836/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2837/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2838/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2839/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2840/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2841/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2842/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2843/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2844/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2845/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2846/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2847/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2848/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2849/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2850/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2851/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2852/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2853/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2854/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2855/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2856/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2857/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2858/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2859/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2860/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2861/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2862/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2863/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2864/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2865/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2866/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2867/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2868/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2869/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2870/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2871/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2872/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2873/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2874/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2875/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2876/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2877/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2878/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2879/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2880/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2881/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2882/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2883/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 2884/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2885/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2886/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2887/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2888/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2889/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2890/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2891/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2892/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2893/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2894/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2895/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2896/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2897/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2898/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2899/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2900/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2901/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2902/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2903/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2904/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2905/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2906/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2907/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2908/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2909/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2910/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2911/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2912/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2913/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2914/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2915/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2916/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2917/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2918/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2919/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2920/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2921/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2922/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2923/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2924/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2925/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2926/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2927/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2928/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2929/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2930/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2931/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 2932/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2933/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2934/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 2935/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 2936/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2937/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2938/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2939/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 2940/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2941/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step
Now training the model 2942/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step
Now training the model 2943/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step
Now training the model 2944/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 75ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 75ms/step
Now training the model 2945/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2946/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 2947/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 2948/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 2949/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2950/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 2951/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2952/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2953/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2954/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2955/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2956/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2957/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2958/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2959/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2960/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2961/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2962/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2963/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2964/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2965/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 2966/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2967/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2968/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2969/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 2970/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2971/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2972/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 2973/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 2974/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2975/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2976/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 2977/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2978/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2979/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 2980/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2981/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2982/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2983/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 2984/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2985/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step
Now training the model 2986/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2987/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 2988/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 2989/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 2990/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 2991/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 2992/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 2993/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 2994/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2995/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 2996/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 2997/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 2998/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 2999/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3000/5600
MAE: 0.38881727933883664, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.4487369272708893, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.44923205232620245, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.4543892282247543, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.5055112452507019, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.5063707337379456, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.5160409662723541, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.5501246765851975, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.5529182021617889, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.5551680672168732, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.5708359527587891, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.5819763049483299, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.5827870640754699, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.5863663447201252, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.5872042841911317, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.5898485127687454, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.5913026275038719, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.598156087398529, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.6009200127124786, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.6039543664455412, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.6051378774642944, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.6126239690780639, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.613431718379259, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.6209640562534331, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.6238624141216278, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.6300478296279907, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.6327485294342041, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.6345163732767104, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.6421627748608588, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.6444715872406959, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6476881194114685, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 0.6484179026484489, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.6489730063676833, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.6589588187932969, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.6656275681257248, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.6665548310279845, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.6699385811686516, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.6731036055088043, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.6741763727664947, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.6791027084589003, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.6847699747085569, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.6891725853681565, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.6892478972673415, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6904150829315185, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.6905417340993881, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.6928469658493994, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.6934066742658614, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.6971244856715202, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.6977494410276412, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.6979007499217986, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.700491947054863, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.7019101973474025, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.7050580998063087, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7075721465349198, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.7077806682586669, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.708240001320839, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.7093756214380262, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.715821725487709, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.719034685254097, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7210422322154044, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.7225016031265258, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7270399197936057, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7275242509320378, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7302863355576992, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.7314684736728668, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.7349561529159545, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.7350464780330659, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.7355337245389818, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.7379527900218963, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.7398571476936341, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7407054695487022, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.7440746413469316, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7457273457050323, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.7472233951091766, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.748293634802103, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.7521494121551513, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.7522475079298018, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.7524505364894867, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.7537141907215118, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7539760146141051, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.756956045627594, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.7572228129208087, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.7584530577659607, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.7616818272173405, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7638712931275367, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 3
MAE: 0.7642340128421783, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.766611597418785, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.7674060136079788, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.7679757560789585, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.7707334638237952, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.7721868157386779, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.7736304850578308, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.7745808262825012, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.7749056569933892, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.7754869047403334, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.7768042478561401, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7789265978336334, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.77917187666893, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.780275191783905, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.7804029048681259, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.781268697977066, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7818216059207915, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.7825557769536972, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.7839247748851774, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.7843046984672546, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.7852131143212318, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.7864446636140345, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.7922014999389648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7931078165769576, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.7931723882555961, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7940007553100584, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.7957228590250016, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.7963610444068908, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.7966920361518859, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.7968507007360457, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.7979138526916503, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7989478409290313, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.799071231842041, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.7993579388260842, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7995453178882598, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8007047452032566, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8024944529533388, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.8029407175183294, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8065524086952209, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8072243332862854, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8083462480306626, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8088162930011749, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.8100414131879805, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.8103890091776847, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.8145017178058623, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.8156524032354355, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.815883231639862, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8162349867820741, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.818424189388752, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.8203614697456361, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.8209879121780397, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.8217294384241104, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.821796715259552, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8225435081720353, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8225992131233216, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8226669018268584, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 0.8228256285190583, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8239878654479981, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.8252090245485306, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8264583021402359, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.8272567216157913, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8286043152809143, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.829092726111412, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.8294511542320251, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8298073694705963, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8309720594286919, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8311921567916869, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8318441540598869, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8319679604768752, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8342636034488677, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.8355040255784989, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.8355076717063785, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.8355222228765488, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8389996933937074, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8403890595436095, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.8407961115837097, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.8429517626762391, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8432644817829132, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.8432858943939209, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.844295244693756, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.845367192029953, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.8469060148894787, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8477217183113097, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.847765215218067, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.848490445792675, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.8486416981220245, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8504347673654558, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.8504518065452575, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.8521032073199748, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8521206232905388, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8527810308933258, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.8533767135273663, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.8534022096395493, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.853467783331871, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8545520440340042, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.8548299183249473, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8560123697519302, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.856945918560028, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.8570716993808745, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8571296677589416, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.8580345873832702, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.8585323095321655, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.8589471125900744, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.859129385650158, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.8597166538238525, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.8608447760343552, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.8612274858951569, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.8634447321891784, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8634465173482895, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8655187129974365, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.8659105095863342, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.8665681175142528, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8666381299495697, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.8667168498039246, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8672518496513366, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8674605057239532, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.8690516250133513, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8696977753043175, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8698150214403867, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.8700460231527686, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.870321896791458, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8706802502870559, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.8709582850337029, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8714911210536957, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8715643212795259, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8722456481158734, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.8723084300756454, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.8725837528705597, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.8734194145202636, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8761679697632789, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.877728431224823, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.8778105453252791, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.8789030776023864, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.8792613269090651, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.879950918674469, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8801492279767992, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8805919528007508, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.8806484047174454, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.8819353879094123, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8827753797769546, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8834430396556854, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8839577035903929, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8850332945585251, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8851434960216285, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8856113777160644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8859320417642593, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8870764970779419, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8897380667924881, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.8902682371139526, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.8907692958116531, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 0.891055073261261, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8913829044103622, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.8922944918870925, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.8924088195562362, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.8927029927372931, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8936026234626769, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8940398306846618, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8943172857165337, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.895813842177391, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8967934507131577, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.896855402112007, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.8971059186384082, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.8971753761768341, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8976442650556564, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8977669294774533, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8977671282291411, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.8979695290327072, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.898093959748745, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8988546520471573, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.8989679548740387, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8993723618984223, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.8997835044860839, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8999445319175721, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.8999978379011153, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.901022376537323, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 0.9011436626911162, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.9011730879545212, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9017507553100585, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9048452064394951, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9051538542509079, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 0.9053405702114106, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9063540596961974, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9066628800630567, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.9081665650606154, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9094477133750913, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9098775107264518, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.90991151034832, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9107101503610611, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9114870772361755, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.9117252755165101, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.9124425038695335, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9139630962610245, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9151637361049652, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9161894142627716, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.9165384531021118, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9173578476905824, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.9177226185798645, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9182149291038513, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.9189472422599791, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.9202301412820816, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9206541166305542, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9214926093816758, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9230821883678437, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9246643335223197, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.9247426838278769, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9255966365337371, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9257613406181335, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9272874615192415, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9287366108894346, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9294137642383575, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9301387057304382, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9307725846767425, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9314926658868788, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9315259994268417, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9315887600183487, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9320501998066902, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.932070283770561, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9322068907618523, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.9325052313804626, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.932658042192459, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.9331058443188667, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9334531636238097, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9340429635047911, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.934073592722416, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9344231162071228, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9351080030202865, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9377435848712921, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9385574072599411, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9393687658309936, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9394437425136566, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.9394940141439438, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9399453848600388, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.9400283012390137, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.9405326634645462, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 0.9407871012687682, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9409988552331925, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9410286727547647, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.941210518836975, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9414334982633591, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.941758621096611, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9419584976434706, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9421860694885253, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.9424801561236382, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.9429124925136566, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9439926207065582, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9444434449672698, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.944455280214548, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.9445515528917312, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9446372156143188, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9448823750019073, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.94577573543787, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9459739581346511, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.9464023113250732, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.9474287229776384, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9474303965568541, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9483466252684594, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9486241743564605, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.948669816851616, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9488877713680267, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9490073682069777, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9495644915103914, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.9500214550495147, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.95034086561203, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9505527883768081, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.9505964908599853, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9511664390563965, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9529300481081009, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9532027289867401, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9541055386066436, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 0.9544366257190703, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9566665158271789, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9585039422512054, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.9585937094688415, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9594492273330687, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.960048359632492, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9602059770822524, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.9604682222604751, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9615729413032532, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9617911726832389, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.962413466334343, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.9629912989139555, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.9631277294158934, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9641792745590209, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.9645057778656483, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9650960729122161, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.9651005196571351, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.9655772018432618, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.968866099834442, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9690815970897674, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.9691726677119732, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9695619601607323, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.9701418697834014, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.9706450001001358, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9713159010410308, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9718342811465263, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9724863637089729, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9735166597366334, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9742006033658981, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.974890673160553, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 0.9754368052482605, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9755847886800766, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.975655225276947, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9756732270121574, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.9757738307714462, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9763225027024746, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9764381438493729, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.976982370376587, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9771708877086638, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9772419661283493, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9773049818277357, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.9783452514410019, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.9783877407312392, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9794594392776489, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9804015383720397, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.9804305956363677, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.9808615539073944, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9811681048870085, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9815390795469284, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9816179441213606, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.9839325070977211, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9839725434780121, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9843457684516906, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9844231263399124, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9848730582594871, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9860930428504944, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.9862384550869464, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9868780481815339, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9869161476045847, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9872597247362137, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9872908093035221, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.9876141175627708, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9880595417022704, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9883729547262192, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9884670023918151, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9887511775493621, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9895137530416249, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9899633886218069, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.989976371884346, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9904485988616945, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9915076837539673, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.9915909414291381, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9922517509460448, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9925126001834869, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9927197054624557, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9934003980159758, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9937065947651863, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9938551109284163, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9938970268368721, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.995793079212308, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9961138949990271, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9965618357658386, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.9970300909727812, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.9974022626876831, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.9977785244584083, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.9980305448770522, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9981548563241958, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.998576426565647, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9989156053066253, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 0.9992621257901192, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9996528358459471, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.9997924596071244, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0000552892684937, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0012471899986266, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.0012910754084587, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0027410731315611, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.0028833688497543, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.0029092492461202, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0032648146152496, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0035855770111084, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.004199422955513, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.0048412487506866, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.00510250043869, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0067093908786773, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.0070194438695907, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.0073151216506957, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.007539366930723, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.008902898490429, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.009161776304245, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0096306488513946, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0097092896699906, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.0098917398452758, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.010254628121853, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.0104820356369018, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0113800749778747, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.0118906665444374, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.012331308722496, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0124546246528623, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.0126621712595223, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0127870547771454, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0133326277732848, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0133902642726897, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0134389386177063, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.014070186138153, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.014507696032524, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0146638751029968, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0149805967807768, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0158367025852204, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.0161958366632462, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0165661410093307, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.0172656841278076, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.017580284178257, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.018463968038559, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0193104926347734, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0202080655694008, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.020610624551773, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.0206860706806182, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.020788191318512, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.0208191859722138, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.021362805366516, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0218432891368867, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0225487271249292, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.0226155371665953, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.022706387937069, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.023616600394249, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.024474447131157, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0253974080085755, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.0254649446010589, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0258346294164657, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.025874263048172, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0262264508605003, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0264765083789826, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0265686976909638, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.0265974358320236, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0266997136175633, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0278421477079391, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0278435961008072, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0282114908695221, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0289222631454469, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0289236233234405, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.0293689177036285, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.029970814704895, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.031326590538025, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.031604826450348, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.0318925619125365, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.0329352931976317, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0329754948616028, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0336357653737067, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0340152177810669, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.0347794995307922, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0350257717072964, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0351076081991195, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0354762330651284, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.035498328924179, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.036913468003273, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0378706413507461, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0382787200808525, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0387021378278731, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0392061249017714, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.0393334809541703, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0402820677161215, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0404546320438386, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.041114322900772, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0419397552013396, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0420043069720268, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.042600088119507, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.042687835216522, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0427082359790802, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.042861752510071, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0435899123549461, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0439001698493957, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0440221458673478, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0442552716732023, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.044936180114746, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0455758526921273, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.0457575052976609, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.0469128773212433, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0471726834774018, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.0472084954977035, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0475649688243867, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0483686850070952, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0483694434165955, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0488992615789177, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0490334808826447, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0492015409469606, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.0492779514789583, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0497480944395066, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.0501325458884239, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.0502329289913177, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0506813633441925, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0508269877433776, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.050846247434616, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0510208249092101, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0513658702373505, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0516811640262602, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.052442467689514, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0535021126270294, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0535908982753752, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0536984640359879, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0539305836558341, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0540950894355774, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0543439511060715, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0549490993022919, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0566131700277328, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0579139012098313, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0586347043514253, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0589269061088562, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0589376435279845, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0592548944056035, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0593107018470764, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0593721661567688, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0603716448545455, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.060785198688507, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.061256624817848, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0618835583925246, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.0619545805454256, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0624287099838257, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.0628159493803977, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0641566023826599, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.0642847294807436, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0653473467826842, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0661357182264328, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.0666196205317973, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0668340311050415, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0670043904781341, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0680034726858139, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0681829083561898, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0686921194791794, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0693311439752577, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0698782638311386, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.070581117272377, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0706403541564942, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0706441328525542, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0707555108368396, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.0710142259597777, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0713419616222382, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0713543117642401, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0715382680892944, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0716411457061767, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0716948211193085, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0717600125074387, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0722410993576048, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.072314890220761, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.072603690624237, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0732078731060029, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.073650979310274, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.0741948399543761, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0742012221813202, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.074580644249916, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.0751376688480376, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.0752985137701034, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0756921679973601, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.076735294610262, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0774131492376327, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.077769433259964, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0778125740587712, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0779775099754332, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.079217530965805, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0796695057153702, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0797980997562409, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.0802641607820989, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0803521518707275, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.080408705949783, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0820650100708007, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0822831497192382, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0823623094558716, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.0825453953742978, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.083327202796936, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.0833412739634514, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.083363504767418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.0841315895318986, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.084328844755888, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0846343660652635, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.084816481590271, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.085886742591858, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0862491130828857, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0866394624710083, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.086936086475849, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.0875321340858934, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0878226444721222, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.088078898191452, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.088230104804039, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.089275209903717, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0895144448280334, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0897042379379271, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0899222109317779, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0901152849197389, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.091097836256027, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0912890970706939, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.0924107954502105, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.092526517868042, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.0937770698070526, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0938751522302628, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0939628844261169, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.0941764459013938, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.0942743990421295, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0943686742782592, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.095472993016243, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.0961927339434623, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0980191812515259, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.0987761557102202, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0994979084134102, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1007199600338935, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.1010433673858642, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.1010906457901002, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1012975022792815, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1016623467803002, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.102550098657608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1033662649989129, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.103560108564794, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1037141622304916, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1044815737009048, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1052216048538686, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1057054178714751, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.105893760919571, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1064059302806855, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1065229997634887, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.106527872443199, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1066235959529878, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.106881468296051, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.107204086303711, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1075651190280915, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1087197440862657, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1097685191631317, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.1100517600774764, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1110571771860123, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.1112224564552307, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1117547646164894, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1118240520954132, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1119961798191071, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1121876972913742, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1122084472179412, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.112245536327362, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1126086980700491, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1126668472290038, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1129486560821533, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1132547348737716, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.1136798218488693, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1142170131206512, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.114990519285202, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1166182503700255, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1168236628770827, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1170781210660934, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1173121399432422, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.118099238395691, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.1195269674062729, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.1196605435609819, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.119926503300667, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.1199304938316346, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1201983499526977, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.1202941477298736, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1208075528144836, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.1210597709417343, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1215272591114043, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.122370755970478, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1229263305664063, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.1232563242912292, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1242185267806053, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1246203848421572, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.1251030206680297, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1251817271113396, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1253704309463501, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1257029175758362, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.1265652179718018, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1269218326210975, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1272380948066711, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1275532352924347, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1282465860843658, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1283783781528474, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.1291059583425522, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.12932218170166, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1293941140174866, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1294322653859854, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1295561168193817, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.130066397100687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1309785828590393, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1321519852280617, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.132416479587555, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1325382965803148, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.132710320800543, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1328479603528976, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1338721074759959, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1342642740011215, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1344717059135436, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.134646280169487, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1350252070128917, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1356325731277466, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.1365522240400314, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1366797506809234, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.13671632707119, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.13683682847023, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1370276898145675, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1381354246139526, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.1388242813944818, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.139181356191635, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1392349660396577, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1395087213516235, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.1396423012018204, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1399101078510285, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1404609561562538, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1405060338974, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1424760193824768, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.1427434656620026, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1438857972621919, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.14406378865242, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1440683946609496, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1443023251295088, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.144988051056862, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1451707661151886, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1451862204670906, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1453259915709495, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.1457502335309981, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1462877541780472, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.147533522605896, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1477673414945602, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1478081093430519, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.148746195793152, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1491334125995636, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1492148265838622, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.149304316997528, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1499967626295984, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1504302397370338, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1522663474082946, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1529740154743195, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1547215626239775, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1550965011119843, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1553682233393192, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.1556893781423567, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.155978034734726, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1560877054929732, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.156422911643982, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1575050727128982, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.1580805070698261, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.158447265625, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1589796741008758, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.159177005648613, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1592004747390745, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1593240574598311, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1593245733380317, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1599270601272582, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.160514140188694, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.161376729786396, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1619692549705505, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.1623557872772217, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1627293915748595, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.162863756775856, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1638499915599823, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.163869074344635, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1642675642967224, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1644506767392158, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1645051602125167, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1652860090732573, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1660752207636833, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.166352427005768, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1665527880191804, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1670567111968992, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1676615328788755, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1680036354064942, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.1687471568584442, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.169631724357605, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1698786590099335, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.169943438768387, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1707190768718718, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1708724796772003, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1709176969379187, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1709428073763846, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.1711886260509492, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1714068803787232, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1715517343878745, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1716131925582887, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.171757330060005, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.1719075129032135, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.1725343749523163, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.1726222772598267, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.172731126099825, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1728973822593687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.1732904494404792, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1733663275837898, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1734163999557494, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1734553784132005, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.173721449136734, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1737823847532272, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1738640117645265, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.1741005972623824, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.17412093436718, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.174130481481552, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1745766252279282, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.1747539508342744, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.175797312259674, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.17603859603405, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1763273286819458, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1763556361198426, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1763800532817839, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1772977681159973, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.1775286853313447, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1784938354492187, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1785475396215914, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1788064458072185, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1788590536117554, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1795523599386215, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1799266550540923, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1806045177578928, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.180729979634285, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1809096500873566, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.180922313094139, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.1812626705169678, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1822544205188752, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1823428410887717, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.182465680003166, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1825273767709732, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.183336302638054, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1836046726107596, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1856967315673828, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.185770552664995, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1870422676801682, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1885135564804077, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.1887992756366728, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.1891784162521362, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1893329427242278, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.1897786026000976, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1898424863815307, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1903312265872956, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1905379891395569, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1909595952033996, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1912147763371468, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.1914721310138703, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.191513533949852, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1921170905828475, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1923226314783097, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.193011538684368, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1932858560830355, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1934251980781554, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.194228090405464, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1947636291980743, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1949568316936492, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.1950400904417038, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1957175029441713, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1959527790546418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1974721908569337, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.198767086982727, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1989935801029206, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1992623761892318, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.1993214969635009, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1995491820573807, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2003934339284896, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.2006638564169407, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2006974831819535, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2017523035407067, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2020080180168151, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2022306070327757, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2023740649223327, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2034845188856125, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.203589000105858, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2036739408969879, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2036983489990234, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2037106618285178, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.204601080775261, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.206292489171028, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.2074873244762423, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2079553816318511, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2083155289292336, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2086799581050873, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.208918525338173, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.2095628324747085, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2113046199083328, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.2121406303644178, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2121646761894227, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.212300381064415, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.213075375556946, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2134685341864824, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.2141593639850616, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.2147685573101044, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2149228692650795, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2149468020200729, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2150047063827514, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2155862197875975, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.215869292974472, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.2164634570479393, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2179839033484459, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2180655002593994, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.2182347044348716, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2183970916867257, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.218765609025955, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2188456342220306, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.219880692720413, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2199360654354094, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.220035719871521, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2209561395645143, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2210055031478404, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.2219280109405517, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.2228133187294006, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2228325456380844, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2234574933052063, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.2236117005348206, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2243560045957564, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.225004394352436, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.225172500371933, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2251747727394104, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.2253757685422897, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2259368613362311, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2259837571382524, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2268468902111054, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2270101189613343, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2273240283727644, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.22742484664917, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2277037177085877, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2277079105973243, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2284138917922973, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2284859031438828, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.2286129951477052, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2297819708585738, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2303008351325988, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.231125675201416, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2316720776557921, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.231753465592861, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.232228826165199, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2326258662939071, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.232729040145874, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2327508989572524, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2328656063079833, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2329449695199728, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2330015555620193, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.2343170046806335, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2348447115421295, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2349895792007444, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.235126222848892, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2359618828296661, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2366228699684143, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2372017860412599, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.237355664730072, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2374689251780508, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2375131607055665, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.2376206934452056, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.2384033278226851, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.2393899188041686, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2395631062984467, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2406124026179313, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2406694177389146, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2413958788514137, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2414695698022844, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2419797756373883, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2421698033809663, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2426537096500396, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2430524916648864, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.243053564429283, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2431426808834076, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.243456225156784, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.243661993741989, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2442595219612123, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445047547221182, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445318520665167, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2445571527481079, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2451037096977235, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.24555746614933, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.245790148139, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2461296141147613, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2464210275411607, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.24697012758255, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.247449083685875, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.248412902712822, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.248858909368515, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2492913488149644, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2495196838378906, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2500996903181076, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2507887959480286, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2514893040657042, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2524703726768494, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.2535302221775055, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2538080052137375, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.25447074174881, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2545394882559777, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2553999902606008, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.255672797679901, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.2559172365665436, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2568185716867446, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.2572679624557495, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.257878007173538, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.258162288427353, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.2581990916132928, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2583328559994698, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.258658321261406, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2588189766407012, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2588403031826019, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2594862492084502, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2596591730117797, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.260091652035713, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2610995729118586, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2612726211547851, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2618624180555345, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2622084241956473, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2627122163772584, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2629660741090774, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2637933254241944, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.264324443101883, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.2644008711576462, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2646747634410858, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2649731819629668, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.2649783864617348, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2651285932064056, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.265193262696266, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.265494620859623, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2656156569719315, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2657224659919737, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2665656403303145, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2669831202030182, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2672824837267398, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2674663960933685, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2675511837005615, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2675757185220717, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.2684665739536285, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2692975685596466, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2693283901214598, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.269498236835003, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2702135741710663, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2706028597354888, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2711218104362487, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2721146658658982, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2722176745533944, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.2728394241333008, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2730072708129883, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2735114455223084, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2735145252794027, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.273655313551426, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2736858278512955, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2745149836540222, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.2748253226280213, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.274883782863617, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2750106023550032, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2751694118976595, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2755898342132568, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.2756651029586792, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.276469317138195, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2764834616184235, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.276766179561615, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.2771128609776496, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.2774770901203154, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2776659578084946, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.2785214558839797, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2790948748588562, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2794184237718582, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.279567049741745, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2801245115995408, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.2802399591207503, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.280376872420311, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2806914303302765, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2807814006805418, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2808357685804368, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.2820487205982207, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2824026124477386, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.2824575755596161, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2833797991275788, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.283564223408699, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.2836234407424925, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2850175187587738, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.2850350186824797, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2852699309587479, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.285674626737833, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2863050699234009, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.286314210653305, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.286460910797119, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.2865045615136623, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2878554665148259, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.28789635181427, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.287969485282898, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.288053663134575, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.288068825006485, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.2882121626138687, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2883574829101563, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.288662077486515, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.2889633562266827, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.2889757871627807, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2893567517995834, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.2893610820770263, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2896505728363992, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2902149916887282, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2915854053497313, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.292645646929741, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2938129652142525, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2940377447605134, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.2940906286239624, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2941042470932007, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.295846273303032, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2961256757974624, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2965001881122589, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2966798727512359, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2968990956544875, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.2980957542657852, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2983018473386765, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.2983676288127899, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2986110941171645, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2989471554756165, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2993536133766175, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3003900170326232, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.300602905511856, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3014185265302658, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.301805184841156, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.301810483932495, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3023189607858658, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.3044717342853545, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3044827073812484, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.3047610018253326, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3049516544342041, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3057035731077193, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3059039340019225, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3061656594872475, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.306288183093071, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3067478083670139, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.306784102320671, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.307906848192215, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3080960268080233, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.308551162481308, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3097322063446044, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.310144631922245, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.310320417881012, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.311190249443054, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.3117063555717468, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3117224589586258, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3118670601844786, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.3129359312355517, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3131315932273864, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3141018942594527, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.3148029550909996, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.314983524441719, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.3154627685546874, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3157829687595366, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.315994225502014, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.3160212501883506, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.3161579877138139, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3163570433855056, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.3164802894592285, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.3174623684883116, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3178813235759734, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.318626489162445, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3193671987056732, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3196965992450713, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.3197059497833252, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3201689782738686, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.320310755252838, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3209193408489228, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.32132937759161, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3228353456258772, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3233416841030121, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3235272586941718, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.3245241001844406, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.3249909937381745, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.32668805873394, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.3267080783843994, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.326729215234518, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3276256430149078, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3277433071136475, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3277980056256056, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3278208632469177, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3283361272811889, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.328814271092415, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3288431212902068, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3288901090621947, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.329128805845976, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3297507659196852, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.329865675032139, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.330053715467453, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3306114077568054, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3307581782341003, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.3311425372958183, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3329135417938232, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3329702842831612, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.333287979722023, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3346209619790315, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3346728983521463, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3352928578853607, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3353062634468078, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.3356382161378861, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.3358825981616973, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3359504256248473, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3362213716506957, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3372200460433958, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3373357951641083, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3379688190221786, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3383282550275326, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3385834038853646, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.339330087661743, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.339451030254364, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.3399842683821916, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3402878971099852, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.34064542388916, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.3411517949104308, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3412682354450225, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.3414656937122345, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3416240200996399, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3419297322630883, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3419982314109802, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.3421750948429108, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.3425555679798127, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3425621151924134, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.3426572501659393, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3429890334606172, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3430540845394134, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.3434198067188263, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.3436618953943253, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3438133046627043, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.3438747049570083, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3439538061618805, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3457993969917297, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3458165690898896, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3459816489219665, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3463023979663848, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.347072219848633, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3473331645727158, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3473761591911315, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3474469230175017, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.347991520166397, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.3480030301809311, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3487317115068436, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3490514472723008, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3493617281913757, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3495793238878249, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3497422367930412, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.3503839701414109, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3507744699716568, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3509874577820302, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.351419883966446, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.351424762159586, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3517092064619063, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3520561428070068, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3526166605949403, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.353035505414009, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3532036989927292, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.353647212743759, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3544619619846343, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.355992341786623, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.356932810306549, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3581148461103438, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3582237632274627, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3583797693252564, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3587980136871338, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.3591956872940063, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3604056553840636, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3605182573795318, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3608753430843354, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.360919356405735, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.36185402572155, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.3618554845452309, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3618731305599212, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.3631398060023785, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3634249181747435, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3647117540836333, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3647809019908308, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3658879384994507, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3662926003932951, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3669246363639833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3669361785054206, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3687674403190613, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.369115690946579, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.3691217392683028, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.369421910047531, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3696078181266784, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3701489572525023, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.3702292048037052, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3712328106164933, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3716639697551727, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3731223106384278, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3742104530334474, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3743433923721313, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.374400000333786, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3745349810123444, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3753421798944472, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3754923090934752, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3759255588054657, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.377598753631115, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3777845860123634, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.3778532087802886, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3786060690879822, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.379000167608261, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3790293709039687, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3796684101819991, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3798093155622482, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.380611956551671, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.3807407736778259, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3814833270311353, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3817279160022735, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3821219201385975, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3824641168117524, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.382643179655075, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.3829119951128959, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3830936313271522, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3831788167953492, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3837285697460175, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3843189630508423, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3848715335726738, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.3853567422032356, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.38557870388031, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.386323773920536, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3873851954936982, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3879624485969544, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3879848376512527, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.3882122099995613, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3890215158462524, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3895928428173066, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3898489402532577, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.3899388880729675, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3905784369707106, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3914481106996537, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3914799213409423, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3919424176216126, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3920154005289078, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.392097571492195, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.3922474757432937, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.392300127506256, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3927817412316799, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3928238101303578, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3940250068902968, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3940303496122362, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.3940454349517821, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3941033065319062, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.3943568453788757, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3954484314918516, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3960285156965255, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3960764006376265, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3962278906106949, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.3963168486952782, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.397109228372574, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.397471097111702, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.3980314449071884, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.3984536323547363, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.398580132484436, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3988703126404434, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3993730098605155, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3998017713427544, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3998348641991616, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4004991441965102, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4009284124374388, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.401613317489624, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4020033001899719, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4027880776524544, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4036362636089326, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4054688379764557, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.406106551170349, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4069226239994168, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4074744403362274, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4078077630996702, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4082462356090546, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4082952439785004, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4096608672142028, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4103223905563353, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4108583152294158, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4111608282327652, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4112306044101715, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4112409591674804, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4127621088027955, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4137922406196595, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4138897690773011, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4149966708049178, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4150501847267152, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.415557039141655, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4158903524279594, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.415991908311844, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.416033923983574, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4165477008819578, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4168289752006529, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.416896034836769, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.417103001832962, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.417250825881958, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.417263792514801, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.4173446297645569, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4173992395401, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4174226911664007, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4175143394470215, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4177747431993484, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4178217158317565, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.418121071457863, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4184040546417236, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4191509306430816, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.4194887631237507, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.4196272314190863, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4200205281972884, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.420102985203266, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.420616219997406, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4210114166736603, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4216918766498565, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.422131054162979, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4223053634166718, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.4227982044816017, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.4231562033891678, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4233985096812247, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4238386318683625, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4241429806351662, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.424767118692398, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4264571014642715, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4270993203520774, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.427158652305603, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4273456010818482, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4273701775074006, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4274224955439567, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4287651569247246, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4288418308496476, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.430337804555893, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.4304524869918822, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4315102088451386, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.431624525785446, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.4319932818412782, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4322724536657332, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4324830473065375, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.4326510564088821, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4335243642926216, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.4341230276823045, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4341457191705704, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.4344475463628767, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.4346961483955383, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4355213106274605, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.436339031457901, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4367408440113068, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.437243476629257, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4375874012708665, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.4376198530197144, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4377725977897644, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4377964706039055, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4384397537708282, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4384685591459274, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4392974987626075, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.4393303513526916, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.439856425732374, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.440154141187668, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4405997693538666, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4406083450317382, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.4411447689533232, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4412494378089904, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.4421028423309328, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4422174947261808, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.4424711096286775, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.4426380264759064, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.4437544797062873, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.443949596643448, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.44395463347435, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.444097840845585, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.4444691263139249, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.445134162902832, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.445313729405403, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4463425070047378, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4465025444030761, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.446749873638153, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.4470076189041137, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4475651290267706, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.4480432436466217, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.448527179777622, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.4491006284952164, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.449122373819351, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.449397428393364, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4494286894798278, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4501372691243888, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4504877673387526, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4511441321372984, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4513078689575196, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4513372943401337, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.4522238838672639, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4529275152683259, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4530203363522887, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.4534035222530364, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4546473712921142, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4548569121062755, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.4548871250152586, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.455010360479355, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4566139028072356, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.456911626458168, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.457654752135277, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4580973595380784, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.458910585194826, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4590758994817734, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.4591062173247338, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4601812422275544, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4608954668045044, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4611959837973116, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4612959787845612, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.4622851313352583, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.462384913921356, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.4633462250232696, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4642929005622864, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4644216104075312, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4647246258258817, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4651694644093514, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.465279072880745, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4661257103681564, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4665672109127044, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4667618128657343, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4669915588498115, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4671219396591186, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4679341015070677, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4683350431919098, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.468501843690872, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.4686041954755784, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4695570245981215, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4696022897958756, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4701347068548203, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4706445832252502, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4707231402397156, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4710909113883972, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4715109829902648, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4723019901514054, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4725461230278014, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.4727415370941164, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4728660807609557, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4734120745658874, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.4740092531442641, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.474275733947754, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4753249781131743, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.4754662663936613, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4760962934494017, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4763009814471004, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4779886871576309, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4786576628684998, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4787994503974915, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4792503386735916, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4792756605148316, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4794279308319092, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4799288318157195, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4800875812768937, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.4802428305745123, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4808689299821853, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4812486829161642, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4813525319099425, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.482943373978138, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.4831846640110016, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4842892513275145, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4845762537717817, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.485069395661354, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4869631366729734, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.4873120877742767, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4879212722778319, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4881995052695274, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.488267421722412, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.488746618539095, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4895776227712632, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4895888016223906, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4897382185459136, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4897845589220524, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.4900380358695984, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4900921599864958, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4907044175863267, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4908448525369167, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.49088915219903, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4919388756752014, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.4922690115869046, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.4929342374801635, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.4930353016257285, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.493532812654972, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4935351238250731, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.4937691271305085, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.494155466556549, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4947805511951446, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4948421076536178, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.495291511774063, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4956667230129241, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4957764327526093, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4959711283445358, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4964612604379652, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4964879512786866, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4970610224306582, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4971264348030089, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4971350864171982, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4979722678661347, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4980430529117583, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.498643975019455, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4989364476203917, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4991245688796042, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.4994183871746063, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4995971113443374, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.4997069239616394, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.499851671665907, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4999164092540742, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.500087587594986, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.500456394314766, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5011395947933195, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5012647286653518, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5016118527054787, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.5031532676219939, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5036670804023742, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5045835668146608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5049042735099794, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5050567955970764, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5051952838897704, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5055404663085938, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.5057408676147461, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.5059518699645995, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.5068464622497557, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5072108428925275, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.50731849527359, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5075225130319594, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.5076407644748688, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.508324701398611, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5088348582983016, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.509845276236534, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5100231561660766, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5101907598972322, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5103061364889143, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.5113538340330124, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5129951238632202, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5144484505653382, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.5145435886383054, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5155210123062133, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.5164628878831863, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5170335814952849, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.517641043663025, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.5176684856414795, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5186109170913695, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.5189730763435363, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.519034262061119, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.5200535521507264, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.5201763973236084, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5206385464668273, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.520719330072403, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5208396956920622, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.522092010140419, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5223910586833953, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5231809512376784, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5233807862997053, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5234745786190032, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5236464619636536, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.524057889342308, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5242240205407143, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.5244111554622648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5246812748908998, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.5255212411880492, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5256811977028846, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.5270265519618988, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5273205861449242, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5274603471159935, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.527472234249115, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5279604229927064, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5281553239822387, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5284676032066344, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.528754660487175, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5289431303739547, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5291513056159018, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5297304723262788, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5297442295253276, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.5301416087150574, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5308593052625656, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5308994680643082, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5311471388339997, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5312813259661198, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.5313348803520204, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5322370147928595, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5324755446910856, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5332800924777985, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.53347171998024, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.5336250097751616, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5342887969017027, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.535782729834318, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5359099846929312, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.5370842606425286, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.537454183578491, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.5377355099320411, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.538382555603981, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.5385719866752623, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.5386232321262359, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.5391005964279174, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5392390996217729, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.5406735167503356, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.540907790184021, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5412804276943206, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.541915274143219, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5431840152740477, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5437105374336242, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.543982310771942, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.544145956993103, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5442402992248536, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5446757645010947, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5448535072803498, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.5450934141874313, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5456209421157836, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5460962698459624, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5472202286720276, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.5477503255605698, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5477801249027252, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.549125924706459, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.549153311729431, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5492777690887451, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.5493997485041617, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.5495794266462326, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5497839406728744, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.5498806822299958, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.550776258587837, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5511295483112335, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5512107179164887, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.551310858130455, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5516432017087936, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5523703013658523, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5530784014463426, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5532853341102602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.5550355405807494, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.5552442226409913, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5555772542953492, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5556509986519813, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5564271912574767, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5564892768859864, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5566252875328064, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5576226354241371, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5576801914572715, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.558823463320732, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.5592271324843168, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5593310761451722, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5593781995773317, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5595491428375243, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.5598769785761832, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5604266286492348, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.5616415657103062, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.5622257307767868, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5623150997459887, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.5631063163280488, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5637934196591377, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.5652460503578187, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.5655289278030395, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.565563789486885, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5657193840146064, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.566160239458084, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5673263580799102, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5673860807418822, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.567548280954361, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.5682341412305831, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5687083512544633, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5697367310523986, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.5699867442846298, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.570708061814308, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5707295604646205, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5712229553461075, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.5720596016049384, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.5722798244953153, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5734783191680908, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.574022530078888, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.574155135512352, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.5741650045514106, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.5742400567177683, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5747139990329742, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5749350206851958, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5763756737709045, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5765310690402985, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5767676323652267, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5769590125083923, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.5771525580883026, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.577446422100067, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5775317288786173, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.578176667973399, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.578631310224533, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.579625639438629, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5796981792747975, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5804679021835326, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.5807987065315245, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.581413322687149, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5816649533808231, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.581820364356041, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.5829287246465682, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.5833712086677552, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.5834887226223944, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.584499255180359, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5855218293070792, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5863343358635902, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5872633740901947, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5873322860002517, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.587926486134529, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5883457335829736, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5883658841848374, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5888580501079559, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5888893518447875, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.5890283495783806, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.589477723836899, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5898203552365302, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5912233397960662, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5917310684919357, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.5920956704616547, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.593385265827179, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.594790741920471, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5949699014425278, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5955701887607574, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.5957105785608292, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5961232051849366, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.5961959153413772, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.596220617175102, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.5964675101637842, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.596790479183197, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5973533154129982, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5978069657385348, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5979499683380127, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.597967255115509, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.6000946879982947, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.601586233139038, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6016839895248414, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.6027962136268616, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6028615951538085, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6028986156582832, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6046424396336079, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6049754738807678, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.6050685750246045, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6052088755369187, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6054216206073761, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.6056024137735367, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6060994267463684, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6061894357204438, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.6062880322933197, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6066079870462417, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.6068544074892999, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.6085808936357497, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.6088231086730957, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6088911123275758, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.608901499390602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.6089219913482666, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.609053906917572, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.6118724138140679, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.6121134419441223, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.612512287557125, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.6127665046453477, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6132668242454529, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.613269971370697, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6134663076400755, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.613594752550125, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6138822841644287, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6142002556324004, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6145376892089842, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.6149540083408354, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.6149865255355835, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.6161996845006943, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.6169966654777526, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.617002248764038, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.617080687046051, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.6180333063602448, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.6180418342351914, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.6180767915248873, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.6183684871196746, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6190730199813843, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6192914947867394, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.6204386487603188, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.6220894753932953, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6251214444637299, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.625308014512062, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6254666239619255, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6258640397191049, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.625891238451004, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.6261632130146026, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.626171737909317, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.6262701154351233, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6269377813339232, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.6271870419979095, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.6296569752693177, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6303403396606444, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6305015790462494, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6308828384280205, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.631142036676407, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.6314718604683875, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6351746678352357, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.63598140335083, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.636107897758484, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6364457309246063, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.636586892604828, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.6368995577096939, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6369876623153687, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.637423395037651, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.637818554162979, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.6378771352767945, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.638349692583084, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6385496586561203, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.6388198778629302, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.639149287700653, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6397341072559357, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6397615313529967, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.640686516523361, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.640715942144394, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6417351350784302, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.64206120967865, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.6421240419149399, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.6422480301856992, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.6435054976940155, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.6438249543309211, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.6442171589136123, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6450113848447798, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6452662916183471, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6464651541709898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6472749561071396, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6479135484695433, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.6482768373489378, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6488916521072388, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6492088422775268, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.6495755463838577, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.649846633076668, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.6500540823340415, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6501185879707336, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.6518700302839278, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.6521053105592727, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.652570258140564, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.6526816220283507, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.652726686000824, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.653188872396946, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6533589408397673, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6535077021121978, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6540178776383399, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.6540221080780029, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6549458341598509, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.6553491071462632, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.655961772918701, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.655973158955574, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6562079713344573, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6563528583049774, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.659054751753807, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.65910815179348, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.6596220955848693, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.6610590831041336, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6612754479050635, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.662747879385948, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6638370203971864, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.6641271338462829, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6641634151935576, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.6643911854028701, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.6646652817726135, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6652281806468963, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6665068343877791, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6667497382164, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.666830281972885, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.667265977025032, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.667952594280243, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.6682733998298644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.668950484752655, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.6695407526493071, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.6699607685804367, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6703035757541655, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6704502121210099, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6707015500068665, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6715821504592896, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6718625054359435, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6726088166236877, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.672736692905426, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6745841012001037, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.67474422454834, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.6747666358947755, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.6753859193325042, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.6766718739569186, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6773063097000123, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6783748769462108, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.6789251744747162, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.6794592008590699, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6799230308532713, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6800146684646606, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6808940515518187, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.681002618432045, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.683435659408569, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.684393870830536, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6850620613098144, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6850718200206756, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.686312511563301, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6872478783130647, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.688024725317955, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6880490038394929, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6882670879364015, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.688455948293209, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.6892227978706358, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6893699929714203, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6893859997987746, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6908744305968284, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6909005150794982, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.6913443308323621, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6919383273124695, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.6929773002862931, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.69306907636486, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.6930847840309142, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.6946387724876402, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6950820374488829, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.6954082061648368, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.6956776916980743, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6965408549308776, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6968272387981416, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.6989871129989624, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.6999855488538742, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7005616680383682, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7012091369628906, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7018252894878387, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7022667751312255, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.7024972498416902, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7028964655399321, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.7030796751976012, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.703391656398773, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7055030322074891, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7068614826202393, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.7083117232322693, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7088761613368988, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.709385883808136, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.709457209765911, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7100847721099854, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7101020709276198, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.710202185988426, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7112806544303893, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.7120026067495346, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7122117028236388, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.7126088634729384, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7126224145889282, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7130378901958465, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7133623480796814, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.7134972870349885, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7135540217757224, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.7136183590888976, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7139797315597534, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.7141844660043717, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.7154318228363992, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7156692714691162, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.7156890586614608, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.716011992841959, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.716227039694786, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.7162760317325592, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.7163412824869155, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.7176924601793289, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.7177523807287216, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.7179230451583862, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7180974708795547, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.7187690216898919, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7190667424201966, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7209585849046707, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7218889718055723, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.7219003841876983, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.7219190076589583, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.722057311296463, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7230394825935362, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7239278957247735, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7245009038448333, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.724538342654705, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7250207290649413, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7252617985457182, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.7269628422260284, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.726977269411087, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.7272652745246888, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.7287420654594896, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.7293228939771652, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7298509061336518, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.7302283601760862, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7303747057914733, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7307036638259887, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7314121589660645, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.7319075167179108, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.732295435667038, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.732524910569191, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7325358912944793, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.733296032309532, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.7339372055530546, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.7343085520565509, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.735089676141739, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.735130075365305, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.735245285987854, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7356451585143806, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.736712232351303, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7377657920718192, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7388700738549232, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.7392203407287596, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.7397438303232193, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.7400204854011534, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.740133303463459, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.7401804089546205, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7407579469680787, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.741133745074272, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.741139496922493, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.7423833445310593, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.742418247461319, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.7429313764572143, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7430600957870481, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7441899495124815, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7453706935644149, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.7459279820919036, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7463804125785827, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.746958520323038, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7479827032089232, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7484186097979546, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.7485512614250183, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.748627375125885, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.749409262895584, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.7504271820783615, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.7511304657906295, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7512264298200606, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7515728995800017, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7518246591091156, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.7520624340772628, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7525388585329054, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.752799540758133, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.7529126749038695, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7535233736038207, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7535314291715622, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7537784278392792, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7538860545158386, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.7539441004991532, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7547780485153197, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.7549011439681053, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7549213156700134, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7550443947315215, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.756304015636444, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7569941639900208, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.7571703345775602, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.7582494781017304, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7583915249109268, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.758692416667938, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7594976902008057, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7601345896720886, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7628629963696003, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.7640695543289184, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.7644579694271088, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7645261989831922, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7649804100990294, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.7658147633075714, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7662122145891188, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7684044466018676, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7684059948921202, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.76896444606781, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.768970169186592, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7696022171974182, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.7696832486093044, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7698858681917191, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7704019293785094, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.7722574934959412, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7751446858048439, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7754646204411983, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.775890165567398, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.776850337266922, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7772946999073027, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7780107603073119, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.7798802748918532, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.780283318012953, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7803962023258209, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7810661047697067, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.782600829064846, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7826528208255765, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7828125361204148, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7843420405387878, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7845523595809936, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7855927095413207, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.7878951699733734, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.7881029949188236, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7883336112499237, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.7886042892932892, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.7896199986934662, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7898313686251641, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7901215612888337, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7913545773029327, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.7933157370090484, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.7934130296707154, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7934389099478723, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.794656460046768, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.7948639497756957, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7950314640998841, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7952616260051726, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7956661007404329, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7978993713855744, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7979341865181921, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7987716064453125, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.7995828227996824, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8003283069133758, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.8008347842693329, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.803652210712433, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.8036522538661957, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8038252727389334, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8049427360296249, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8052691490650177, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.805625283718109, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8058169708251952, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8060016632080078, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8065179065465926, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.807133409500122, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.808211790204048, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.809084980249405, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8101681218147276, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8103778049945831, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.810582959651947, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.8106041059494018, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8119950459003449, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.8143767313957215, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.8157711625695228, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.815997906088829, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.8173689424991608, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.8184639797210693, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8185790256261825, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.819294129371643, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.8194591376781464, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8202139214277266, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8205865339040757, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.8208027110099791, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8229052529335021, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.823390348434448, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8235276312828064, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.82455791836977, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.825089852809906, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.8277069301605224, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8284483242034912, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.8287240147590638, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.830068975687027, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.8312065215706823, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.8326948791742326, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8328437447547912, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.8328442410230636, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8347806572914123, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.835990902841091, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8376560673713684, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.8395919964313507, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.8397361130714416, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.8402152673006058, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.8406830847859381, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.840829442501068, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.8408745527267456, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8410793514847754, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.8418196067810058, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8419162817299366, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.84203844666481, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.842875154495239, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.8430962954312562, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.843495047211647, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.844065702021122, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.8443952932953835, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8446020231246947, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.845271998643875, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.8454953999519348, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.8455752835273742, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8455784142017364, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.8474394456148147, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.8474742875099182, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.847792100906372, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.8481660813093186, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.848219861268997, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8482250349521636, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.8491930175423623, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.85025724619627, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.8547063797712326, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8550118267536164, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8550261214971542, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.8555288121700286, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8559451431632041, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.856734118670225, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.8571065683364865, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.858044574469328, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8590237263441085, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.860503324985504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.86068446777761, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.8607090876102448, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8613657430410384, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.8617945508956908, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8631911352872847, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.8658835619688035, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.8659023777246475, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.86623490190506, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.8668766990900039, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8671984914541244, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8677148163318633, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.8682186007499695, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.868643239200115, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.8694670648574827, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8715872623622416, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.8721141860485075, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8730671093463898, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8736142352819443, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8749783651828764, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8759938330650328, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.8770955029726024, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.8771304138600826, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.8790963859558105, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8791436882019041, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.8794854626655577, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.879826320707798, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.8798391968607902, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8799741716384886, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8801732425689697, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.8804706068038939, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8811773941516876, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8820032284259796, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.8823429703712464, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.8838593558073042, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8841309876441954, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.8841468945741653, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.8844422221183776, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.8844440221786498, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8847623512744902, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.8847812221050262, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8856355652809142, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8856610432863234, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.887393186300993, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8878778967857361, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.8882436275482177, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.888300313234329, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.888327965259552, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.8887332891225814, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8890158014297485, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.8921154890060425, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.8931716807186603, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.893958365917206, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.8963519916534426, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.8964144118726254, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.8971855373382567, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8974021569490431, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8984763860702514, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.8985360376536846, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.8985876992940907, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.898881264090538, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.8993401646614074, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9000274062156677, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.9002471178770066, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.9006402597427368, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9028469221591948, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9032050118446349, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9034287571907043, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.903832612991333, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9046104744672774, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.9049101696014403, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9049427704811095, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9051041648387907, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.9059335265159607, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.9063168935477735, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9075096354484558, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.9083795801401138, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.908993689775467, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.9093120262622834, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.90933727478981, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9104237303733824, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.9105084453374146, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.9108876662254333, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9113574192523957, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9117048387527464, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.912921197772026, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.913114196062088, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9145212143659591, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.9149996566772465, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9154980707168576, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.915706233739853, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.9159319460392, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.9161082954406736, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.9169115905761713, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.9172073125839233, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9172749161720275, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9180502713322638, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.9190798655748367, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9191463600695133, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.922565697193146, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.9250829823911189, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.9250909745693208, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9253533780574799, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.9264496564865112, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.9268941955566405, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.9269641075134278, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.928799307346344, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.9289744840860366, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.9300405592918395, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.9314128294438124, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.9322919920682906, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.932523000240326, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9326653764247894, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9328050584197043, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9329437346458433, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9334777668714522, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9342745319604873, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.9349317388534548, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9356876879930496, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.9366389416754246, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.937361756324768, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9376448541879654, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9380147397518157, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.938294498682022, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.938849555015564, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9409704045057297, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.94138206410408, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9421065837740898, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.943249243557453, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9444313392639159, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9463834375739097, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.9469791264533995, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.950475431293249, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9516332746148108, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.9517008786201473, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9523427203893662, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.9538272678852082, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.95460830783844, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.9566843718886375, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.9572237179279326, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.9573579061031339, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.9586571335792542, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.9596466200351714, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9618056178092957, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.9624540791511536, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9631543610841036, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.9634031847715376, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9653417469859122, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9665032938122748, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.966683383464813, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.9671439752578734, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9674201624393461, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.967553484916687, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.9675712213516239, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.96797962641716, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9700331091880798, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.9701451659202576, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9702601716518402, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.9711998686790466, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.9729253516197205, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.9730912506580354, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9730967149734497, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.9733081885278225, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.9736441643238067, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.9745340392589568, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.974722777366638, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.975356815934181, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9786889151334761, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.9786947399377823, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9798052716255186, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.980649572610855, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.9810063333511352, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9831476390361786, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.984850284576416, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.9875781551599503, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9876585111618041, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.9884053320884703, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9896997374743222, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.990847741127014, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.9910122649744153, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.9917332785129545, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9922024935483933, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.9922114973068237, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.993289938569069, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.9939743446111677, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9951442460194229, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.9955444917678833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.9956910174191003, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.995696872472763, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.9960896492004394, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.998582165375352, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9990154728889469, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.000362291991711, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0010712698698043, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.001096342563629, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.001984895825386, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.0071105022430418, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.007160742580891, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.0084685068130494, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.00968359708786, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.0128101289868354, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.0134480090141293, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.0149026572704316, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.0171797440052033, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.017586702108383, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.018459497451782, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0184739112854, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.0219015538692475, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.024794682919979, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.0250530049800872, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.0266250342130663, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.0272196531295776, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.029087449789047, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 2.0298323378562926, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.030778952121735, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.03167760848999, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.033275057435036, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.0345093579292297, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.037584570109844, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0375961080789566, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.039418058156967, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.0394655644893644, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.0401914227008815, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.0405101127922536, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.0412771478891374, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.042128403544426, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.0435629086494442, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.044292601466179, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.044837409734726, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.044934856891632, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.045956328630447, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.046544522047043, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.0476628035902977, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.048649752318859, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.0488290712833406, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.048884205579758, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0499174699783325, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0513546155691147, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.0514445700347426, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.0516196534633635, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.051832914352417, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.052586218774319, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.052972470283508, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.0531227827072143, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0537389397621153, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.054859972000122, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.055556089863181, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.056040491223335, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.0560965716838835, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.0561459751129147, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.0574438900351524, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.0579430595040322, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.0591199562549596, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.0594616458415986, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0620893602371213, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.062719964981079, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.063803866863251, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.064622406721115, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.0647753343582154, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.0648088455200195, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.0676073328256606, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.0677975997924802, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.070079334139824, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.070836775749922, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.071325051784515, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.071657341718674, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.0718498230576516, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.0722038940191267, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.073542498111725, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.0747727692127227, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.075014959335327, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.075873627513647, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.076865137428045, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.077954441308975, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.078225139141083, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.079453487753868, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.0814577147960662, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.085180877149105, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.086098995804787, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.087084526181221, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.088319371700287, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.0894282147884367, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.089542101383209, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.0899966076612477, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.0902798332870005, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.0909157947301864, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.0911002466380593, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.0912524461746216, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.0915614099502564, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.0923535064458845, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.0936098918914796, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.094252688169479, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.0948588104248045, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.095119853496551, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.0953568518161774, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.0960090861320495, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.098026460766792, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.0980671377182007, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.0984467582702635, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.1037427935600284, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.104536937236786, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.1071963535547256, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.10782697057724, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.1095364689826965, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.111678131103516, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 2.111763690471649, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.113142045021057, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.113944552898407, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1142090814113614, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.1147344068288803, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.11633536529541, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.1165059834718702, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.1179665670394896, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.1207922563552857, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.121137575864792, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.1224231884479523, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.1228313014507294, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.1229770854115486, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.1248700964450835, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.1285406995415683, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.128646969795227, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.129011590838432, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1299195842742917, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.1305911421775816, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.1311943118572234, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.131393481850624, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1324853856563566, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 2.132686434745789, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.1350850269794464, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.136883573293686, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.138095583438873, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.1388871163725853, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.139706157207489, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.139981006085873, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.1420151562690735, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.1432448194026947, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.1452305309474466, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1454857543706893, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1468250691890716, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.1484315128326417, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1494251461029052, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.1497225151062014, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.149927827835083, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.1511641428470614, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.1519680306911466, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.1530689626932142, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.1531429812908174, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.1553255156874656, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.1580598936080935, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.158605764865875, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1591765675544736, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1595361099243164, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.1617755131721497, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.1620195138454434, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1629947276115415, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.165790997505188, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1660262048244476, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1661195502281188, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.166303844809532, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.1678628311157224, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.169298859000206, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.1708863973617554, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.173025022506714, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.1731034190654754, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1736091212034223, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1742076174020766, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.1752003893852234, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.1782109575271607, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.1792540296912195, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.180105555534363, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.180269846320152, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.1819722623825073, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.1823269591331482, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.1845571444034575, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.1845811114311218, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.1849733710289003, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.185506668686867, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1863368556499485, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.1881432042121887, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.1887097672224045, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.190774138331413, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.191343186855316, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.195218495339155, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.1957105457782746, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.1980114564895628, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1985860452651975, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.1995634467005734, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.2004692912101746, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.207610981225968, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.21059903216362, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.2130393773317336, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.2133362382650374, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.2141740725040435, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.2143728256225588, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.214481160402298, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.214598279505968, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.2148191576004024, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.2191628173589706, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.2194352984428405, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.2210044251084327, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.222566197872162, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.2233117491602896, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.223574324011803, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.2276251718997955, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.2279289216995237, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.230036625444889, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.231529727935791, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.2344828338027, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2347698539495466, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.2354313850402834, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.2391082451343536, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.2394701898097993, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.244137595653534, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.244569304943085, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.245832419395447, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.2494699362516406, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.25117247402668, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.2513430134058, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.25994597530365, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.2604554266929626, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.2620479092597963, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.262953279972076, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.2630436973571775, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.2641238676309583, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.2689075291752814, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.2698918521404265, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.2724695103168484, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.2730577841997146, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.273338125705719, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.2782123403549193, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.282795798778534, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.2837203428745267, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.2841161929666995, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.2864682302474977, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.2885433718562127, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.2902920633554458, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.2917884871959684, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.2931435994803904, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.293800139427185, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.2940399603843686, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.2949512348175047, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.298683853626251, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.2987345860004424, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.299301622867584, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3011642665863037, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.301778863430023, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.3036632404327393, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.3044723675251007, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.306535981655121, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.306690436601639, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.3067020059227943, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.307020859479904, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.308794270515442, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.308952045440674, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.3119770706295966, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.3135028915405274, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.315435642004013, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.317508618593216, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.318241516113281, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.318445955395698, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3199576113224034, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.320818376541138, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.320935190081596, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.321748689174652, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.322174076795578, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.324331745624542, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.324379640996456, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.3245733234882353, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.32524663066864, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3259373903274536, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3285417170524596, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.3304125086069107, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.332355314552784, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.3335624427795407, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.3348226294517516, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.3378108143806458, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.3387243807315827, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.3400290690362455, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.3402976632118224, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.3440734834671018, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.3456249669790266, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.348347647666931, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3488015089035033, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3531298249959947, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.354297457695007, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.3566539422273634, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.357594362705946, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.365408286511898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.3685140312314035, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.368716421037912, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.3705247566699983, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.3762458102703095, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.376542870759964, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.3782636300325395, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.380768096446991, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.3813441932201385, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.382840000152588, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3830521211624145, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3873779133558273, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3893957302570343, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.3901876912117004, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.391151246547699, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.3912450571060178, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.392253859400749, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.3962662475109098, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3994904100894927, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.4003283083438873, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.401200239419937, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.407614386886358, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.4102375656962396, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.410561458826065, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.412057755947113, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.412959004998207, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.413552816271782, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.418061542510986, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.4186100766658782, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.419553357362747, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.4239822015166284, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.42441800570488, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.4258752822875977, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.4259236590862274, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.4303963069915766, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.43413844871521, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.4371638536453246, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.440468829870224, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.440752312541008, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.4438222095966338, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.4441592321395875, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.4442741751670836, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.452475400328636, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.4568203092217447, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.45941830432415, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.4635427419692277, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.466722925066948, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.4671855211257934, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.4684245321750637, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.469028131723404, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4697919116020204, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.4746531563997265, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.480398269057274, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.481179675579071, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.4841539398431776, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.488544668316841, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4916726559996603, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.4917479679584504, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.4919800058603285, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4921403542757035, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.4950780510902404, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.4977822482585905, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.501889357402921, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.5022410616874695, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.507000987291336, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.5079334393143653, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.514095245361328, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.5182691488265987, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.519612734079361, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.5208762288093567, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.5242081701755525, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.524999520540237, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.5331138105392457, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.534331890940666, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.5354546504020687, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.535784955382347, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.537845239162445, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.5379346877336504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.5436976120471955, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5454398469924926, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.54894557762146, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.5506374225616453, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.55356089925766, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.558982105731964, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.5631247535943986, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.5654521927833556, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.56702621281147, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.571935909986496, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.575710658788681, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.5760038599967956, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.5764323205947877, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.5768654661178587, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.578273500561714, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.583166411876678, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.587136280536652, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.588696889638901, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.5891943722963333, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.590064583778381, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5954928741455077, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.59977793264389, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.601329207420349, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.601901505947113, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.602644822359085, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.6128387019634247, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.6147365542054173, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.622867947816849, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.625325876161456, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.6267674342393876, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.628404844239354, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.629312935590744, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.630978247523308, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.631418771961704, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.6352659787982704, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.6395965013504026, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6398198561668393, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.6448491752147674, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.6561413288116453, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6586707339286804, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.664280910849571, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.6680451110601426, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.6702974177226424, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.674652694225311, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.6855965719223023, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.688511425256729, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.6993220925331114, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.701877100944519, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.7139180302619934, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.7152185292243955, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.7194894165992736, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.722136028289795, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.723188541889191, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.724814936637878, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.735076573848725, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.7379768388271333, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.739984595775604, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.749227763772011, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.753536377906799, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.757665436029434, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.761810897350311, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.764680408000946, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.7654168754816055, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.7712779359817503, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.7717042059898374, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.774302265167236, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.788458643913269, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.7929939703941344, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.801421770572662, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.811801800251007, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.8260716676712034, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.8286366925239563, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.8297799842357634, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.8320538507699964, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.833484319031238, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.854437692642212, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.8599672094583513, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.8600312576293945, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.862335965156555, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.8649203734397886, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.874296113848686, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.8773375306129454, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.8844206199645996, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.888055741786957, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.8924584493637084, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.8952078745365144, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.89608642911911, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.896396240711212, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.8971294522285462, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.903628206253052, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.9176550731658937, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.9270001504421237, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.929804211854935, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.9365611748695373, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.9565970771610735, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.984579122066498, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.987040515422821, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 3.0039432943463327, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 3.0065708861351013, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 3.009886054754257, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 3.018104356586933, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 3.0183619604110716, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 3.018407331466675, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 3.0264869556427003, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 3.035234998345375, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 3.0364126608371733, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 3.049882178068161, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 3.054473400115967, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 3.0728003606796266, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 1
MAE: 3.0774910867214205, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 3.090915502667427, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 3.1046783730983734, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 1
MAE: 3.105064995646477, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 3.1190274552106856, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 3.1285714404582974, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 3.1315883890390395, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 3.1362825334072113, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 3.1394094079732895, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 5
MAE: 3.1639172986745834, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 3.1818889126777647, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.1884463267326355, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.19628550863266, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.240051233768463, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.2574724512100217, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 1
MAE: 3.2770698934793474, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 3.2774167344570158, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 4
MAE: 3.3179026857614518, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 3.358060486793518, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 3.3582792000770567, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 3.4833023028373717, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 3.517246386528015, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 3.621103637099266, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 3.66705295753479, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 3.8687748544514178, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 4.237235291481018, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
Results saved successfully in dir `results/test2/NN_results_3000_lessData.pkl.pkl`.
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3001/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3002/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 116ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 116ms/step
Now training the model 3003/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3004/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3005/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3006/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3007/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3008/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 3009/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3010/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3011/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3012/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 3013/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3014/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3015/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3016/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3017/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3018/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3019/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3020/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3021/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3022/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3023/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3024/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3025/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3026/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3027/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3028/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3029/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3030/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3031/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3032/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3033/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3034/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3035/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3036/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3037/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3038/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3039/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3040/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3041/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3042/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3043/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3044/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3045/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3046/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3047/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3048/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3049/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3050/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3051/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3052/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3053/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3054/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3055/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3056/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3057/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3058/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3059/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3060/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3061/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3062/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3063/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3064/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3065/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3066/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3067/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3068/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3069/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3070/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3071/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3072/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3073/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3074/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3075/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3076/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3077/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3078/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3079/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3080/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3081/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3082/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3083/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3084/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3085/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3086/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3087/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3088/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3089/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3090/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3091/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3092/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3093/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3094/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3095/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3096/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3097/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3098/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3099/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3100/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3101/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 3102/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3103/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3104/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 3105/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3106/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3107/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3108/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3109/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3110/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3111/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3112/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3113/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3114/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3115/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3116/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3117/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3118/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3119/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3120/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3121/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3122/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3123/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3124/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3125/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3126/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3127/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3128/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3129/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3130/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3131/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3132/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3133/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3134/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3135/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3136/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3137/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3138/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3139/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3140/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3141/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3142/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3143/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3144/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3145/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3146/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3147/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3148/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3149/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3150/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3151/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3152/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3153/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3154/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3155/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3156/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3157/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3158/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3159/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3160/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3161/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3162/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3163/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3164/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3165/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3166/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3167/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3168/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3169/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3170/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3171/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3172/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3173/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3174/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3175/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3176/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3177/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3178/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3179/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3180/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3181/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3182/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3183/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3184/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3185/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3186/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3187/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3188/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3189/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3190/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3191/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3192/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3193/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3194/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3195/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3196/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3197/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3198/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3199/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3200/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3201/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3202/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3203/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3204/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3205/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3206/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3207/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3208/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3209/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3210/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3211/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3212/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3213/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3214/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3215/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3216/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3217/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3218/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3219/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3220/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3221/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3222/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3223/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3224/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3225/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3226/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3227/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3228/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3229/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3230/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3231/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3232/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3233/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3234/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3235/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3236/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3237/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3238/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3239/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3240/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3241/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3242/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3243/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3244/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3245/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3246/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3247/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3248/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3249/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3250/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3251/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3252/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3253/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3254/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3255/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3256/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3257/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3258/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3259/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3260/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3261/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3262/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3263/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3264/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3265/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3266/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3267/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3268/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3269/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3270/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3271/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3272/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3273/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3274/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3275/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3276/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3277/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3278/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3279/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3280/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3281/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3282/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3283/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3284/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3285/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3286/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3287/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3288/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3289/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3290/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3291/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3292/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3293/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3294/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3295/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3296/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3297/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3298/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3299/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3300/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3301/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3302/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3303/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3304/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3305/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3306/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3307/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3308/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3309/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3310/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3311/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3312/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3313/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3314/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3315/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3316/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3317/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3318/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3319/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3320/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3321/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3322/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3323/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3324/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3325/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3326/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3327/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3328/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3329/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3330/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3331/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3332/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3333/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3334/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3335/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3336/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3337/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3338/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3339/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3340/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3341/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3342/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3343/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3344/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3345/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3346/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3347/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3348/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3349/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3350/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3351/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3352/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3353/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3354/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3355/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3356/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3357/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3358/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3359/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3360/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3361/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3362/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3363/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3364/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3365/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3366/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3367/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3368/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3369/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3370/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3371/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3372/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3373/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3374/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3375/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3376/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3377/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3378/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3379/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3380/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3381/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3382/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3383/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3384/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3385/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3386/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3387/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3388/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3389/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3390/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3391/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3392/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3393/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3394/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3395/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3396/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3397/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3398/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3399/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3400/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 80ms/step
Now training the model 3401/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 75ms/step
Now training the model 3402/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 85ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 85ms/step
Now training the model 3403/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step
Now training the model 3404/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step
Now training the model 3405/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step
Now training the model 3406/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 3407/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 3408/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 3409/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 3410/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3411/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3412/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 3413/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 3414/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3415/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3416/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3417/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3418/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3419/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3420/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3421/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step
Now training the model 3422/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3423/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3424/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3425/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3426/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3427/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3428/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3429/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3430/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3431/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3432/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3433/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3434/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3435/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3436/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3437/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3438/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3439/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3440/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 3441/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3442/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3443/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3444/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 3445/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3446/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3447/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3448/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 3449/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3450/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3451/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3452/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 3453/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3454/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3455/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3456/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3457/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3458/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3459/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3460/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3461/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3462/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3463/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3464/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3465/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3466/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3467/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3468/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 3469/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3470/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3471/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3472/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3473/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3474/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3475/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3476/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3477/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3478/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3479/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3480/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3481/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3482/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3483/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3484/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 3485/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3486/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3487/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3488/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3489/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3490/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3491/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3492/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3493/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3494/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3495/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3496/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3497/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3498/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3499/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3500/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 124ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 124ms/step
Now training the model 3501/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3502/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3503/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3504/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3505/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3506/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3507/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3508/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3509/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3510/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3511/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3512/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3513/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3514/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3515/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3516/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3517/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3518/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3519/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3520/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3521/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3522/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3523/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3524/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3525/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3526/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3527/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3528/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 89ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 89ms/step
Now training the model 3529/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3530/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3531/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3532/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 3533/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3534/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3535/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3536/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3537/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3538/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3539/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3540/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3541/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3542/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3543/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3544/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3545/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3546/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3547/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3548/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3549/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3550/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3551/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3552/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3553/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3554/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3555/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3556/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3557/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3558/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3559/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3560/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3561/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3562/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3563/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3564/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3565/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3566/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3567/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3568/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3569/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3570/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3571/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3572/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3573/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3574/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3575/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3576/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3577/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3578/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3579/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3580/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3581/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3582/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3583/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3584/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3585/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3586/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3587/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3588/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3589/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3590/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3591/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3592/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3593/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3594/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3595/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3596/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3597/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3598/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3599/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3600/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3601/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3602/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3603/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3604/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3605/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3606/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3607/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3608/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3609/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3610/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3611/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3612/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3613/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3614/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3615/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3616/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3617/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3618/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3619/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3620/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3621/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3622/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3623/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3624/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3625/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3626/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3627/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3628/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3629/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3630/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3631/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3632/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3633/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3634/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3635/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3636/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3637/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3638/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3639/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3640/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3641/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3642/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3643/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3644/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3645/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3646/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3647/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3648/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 3649/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3650/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3651/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3652/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3653/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3654/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3655/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3656/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3657/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3658/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3659/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3660/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3661/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3662/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3663/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3664/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3665/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3666/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3667/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3668/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3669/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3670/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3671/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3672/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3673/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3674/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3675/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3676/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3677/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3678/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3679/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3680/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3681/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3682/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3683/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3684/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3685/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3686/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3687/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3688/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3689/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3690/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3691/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3692/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3693/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3694/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3695/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3696/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3697/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3698/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3699/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3700/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3701/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3702/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3703/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3704/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3705/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3706/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3707/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3708/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3709/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3710/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3711/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3712/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3713/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3714/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3715/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3716/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3717/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3718/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3719/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3720/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3721/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3722/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3723/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3724/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3725/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3726/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3727/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3728/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3729/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3730/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3731/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3732/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3733/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3734/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3735/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3736/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3737/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3738/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3739/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3740/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3741/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3742/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3743/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3744/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3745/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3746/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3747/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3748/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3749/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3750/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3751/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3752/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3753/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3754/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3755/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3756/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3757/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3758/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3759/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3760/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3761/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3762/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3763/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3764/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3765/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3766/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3767/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3768/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3769/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3770/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3771/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3772/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3773/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3774/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3775/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3776/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3777/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3778/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3779/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3780/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3781/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3782/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3783/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3784/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3785/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3786/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3787/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3788/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3789/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3790/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3791/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3792/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3793/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3794/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3795/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3796/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3797/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3798/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3799/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3800/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3801/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3802/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3803/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3804/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3805/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3806/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3807/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3808/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3809/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3810/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3811/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3812/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3813/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3814/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3815/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3816/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3817/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3818/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3819/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3820/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3821/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3822/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3823/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3824/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3825/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3826/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3827/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3828/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3829/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3830/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3831/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3832/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3833/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3834/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3835/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3836/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3837/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3838/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3839/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3840/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3841/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3842/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3843/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3844/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3845/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3846/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3847/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3848/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3849/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3850/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3851/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3852/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3853/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3854/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3855/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3856/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3857/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3858/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3859/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3860/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3861/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3862/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3863/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3864/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3865/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3866/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3867/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3868/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3869/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3870/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3871/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3872/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3873/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3874/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3875/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3876/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3877/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 3878/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3879/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3880/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3881/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3882/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3883/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 3884/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3885/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3886/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 3887/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3888/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3889/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3890/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3891/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3892/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3893/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3894/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3895/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3896/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3897/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3898/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3899/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3900/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3901/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3902/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3903/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3904/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3905/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3906/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3907/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3908/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3909/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3910/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3911/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3912/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3913/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3914/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3915/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3916/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3917/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3918/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3919/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3920/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3921/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3922/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3923/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3924/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3925/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3926/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3927/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3928/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3929/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3930/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3931/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3932/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3933/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 76ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 76ms/step
Now training the model 3934/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step
Now training the model 3935/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 85ms/step
Now training the model 3936/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step
Now training the model 3937/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 74ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 75ms/step
Now training the model 3938/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 167ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 167ms/step
Now training the model 3939/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 3940/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 3941/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step
Now training the model 3942/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3943/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3944/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3945/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 3946/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3947/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3948/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3949/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 3950/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 3951/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 3952/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 3953/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3954/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3955/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3956/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3957/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 3958/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 3959/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 98ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 99ms/step
Now training the model 3960/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3961/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3962/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 3963/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3964/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 3965/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 3966/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 126ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 126ms/step
Now training the model 3967/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3968/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3969/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 3970/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3971/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 3972/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3973/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3974/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3975/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3976/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3977/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 3978/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3979/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3980/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3981/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 3982/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3983/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3984/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 3985/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 3986/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 3987/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 3988/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3989/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 3990/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3991/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3992/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3993/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 3994/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3995/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 3996/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 3997/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 3998/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 3999/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4000/5600
MAE: 0.38881727933883664, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.4487369272708893, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.44923205232620245, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.4543892282247543, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.46465788340568537, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.5049285150766372, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.5055112452507019, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.5063707337379456, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.5160409662723541, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.5361168746948242, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.5501246765851975, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.5529182021617889, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.5551680672168732, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.5552848892211915, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.5708359527587891, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.5762537271976471, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.5819763049483299, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.582234782576561, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.5827870640754699, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.5863663447201252, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.5872042841911317, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.5898485127687454, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.5913026275038719, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.5919127702713012, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.5971074137687682, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.598156087398529, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.6009200127124786, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.6039543664455412, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.6043278205394744, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.6051378774642944, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.6126239690780639, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.613431718379259, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.6209640562534331, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.6221203017234802, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6238624141216278, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.626114649295807, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.6290297050476075, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.6300478296279907, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.6324208295345305, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.6327485294342041, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.6345163732767104, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.6421627748608588, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.6444715872406959, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6476881194114685, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 0.6484179026484489, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.6489730063676833, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.6505117759704591, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.6589588187932969, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.6656275681257248, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.6665548310279845, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.6699212644100189, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.6699385811686516, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.6731036055088043, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.6741763727664947, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.6742677688598632, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.6774953011274337, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.6791027084589003, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.6792059335708618, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.6847699747085569, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.6891725853681565, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.6892478972673415, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6904150829315185, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.6905417340993881, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.6928469658493994, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.6934066742658614, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.6971244856715202, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.6977494410276412, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.6979007499217986, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.700491947054863, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.7019101973474025, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.7047316002845764, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.7050580998063087, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7075721465349198, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.7077806682586669, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.708240001320839, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.7093756214380262, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7105564594268798, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.715821725487709, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.7184530720710754, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.719034685254097, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7210422322154044, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.7225016031265258, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7270399197936057, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7275242509320378, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7302863355576992, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.7314684736728668, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.7349561529159545, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.7350464780330659, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.7355337245389818, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.735611266374588, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.7379527900218963, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.7398571476936341, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7406543646007775, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.7407054695487022, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.7440746413469316, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7449507315158844, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.7457273457050323, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.7472233951091766, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.748293634802103, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.7499705779552459, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.7513210134506225, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.751535209327936, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.7521494121551513, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.7522475079298018, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.7524505364894867, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.7537141907215118, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7539760146141051, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7540670692920683, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.756956045627594, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.7572228129208087, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.7584530577659607, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.7612696056365966, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.7616818272173405, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7638712931275367, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 3
MAE: 0.7640164750814438, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7642340128421783, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.766611597418785, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.7674060136079788, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.7679757560789585, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.7696955114603041, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.7707334638237952, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.7721868157386779, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.7736304850578308, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.7745808262825012, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.7747560548782348, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7749056569933892, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.7754869047403334, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.7768042478561401, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7780994164943695, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.7789265978336334, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.77917187666893, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.780275191783905, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.7804029048681259, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.781268697977066, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7818216059207915, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.7825557769536972, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.7839247748851774, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.7843046984672546, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.7852131143212318, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.7864446636140345, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.7908255714774131, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.7916259945631027, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.7922014999389648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7931078165769576, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.7931723882555961, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7938894394636153, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.7940007553100584, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.7957228590250016, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.7963610444068908, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.7966920361518859, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.7968507007360457, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.7979138526916503, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7979372117519378, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.7989478409290313, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.799071231842041, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.7993579388260842, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7995453178882598, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8007047452032566, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8015161591768265, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.8020954713821411, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.8024944529533388, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.8029407175183294, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8031515436172484, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.8065524086952209, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8072243332862854, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8083462480306626, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8088162930011749, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.8100414131879805, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.8103890091776847, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.8145017178058623, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.8151992249488831, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.8156524032354355, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.815883231639862, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8159161418676376, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.8162349867820741, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.81647955930233, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.818424189388752, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.8191137883663178, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8203614697456361, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.8207148022651672, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8209879121780397, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.8217294384241104, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.821796715259552, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8225435081720353, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8225992131233216, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8226669018268584, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 0.8228256285190583, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8239878654479981, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.8252090245485306, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8264583021402359, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.8272567216157913, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8284354555606843, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8286043152809143, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.829092726111412, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.8294511542320251, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8298073694705963, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8309720594286919, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8311921567916869, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8318441540598869, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8319679604768752, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8342636034488677, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.8355040255784989, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.8355076717063785, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.8355214231312275, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8355222228765488, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8389996933937074, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8403890595436095, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.8407961115837097, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.8429517626762391, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8432644817829132, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.8432858943939209, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8441968295574188, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.844295244693756, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.845367192029953, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.8469060148894787, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8477217183113097, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.847765215218067, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8482646036148072, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.848490445792675, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.8486416981220245, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8504347673654558, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.8504518065452575, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.8514600131511688, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.8521032073199748, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8521206232905388, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8527810308933258, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.8533767135273663, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.8534022096395493, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.853467783331871, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8545520440340042, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.8548299183249473, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8560123697519302, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.856945918560028, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.8570716993808745, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8571296677589416, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.8580345873832702, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.8585323095321655, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.8589471125900744, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.859129385650158, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.8597166538238525, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.8608447760343552, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.8612274858951569, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.8615726459026337, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.8634447321891784, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8634465173482895, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8655187129974365, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.8659105095863342, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.8665681175142528, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8666381299495697, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.8667168498039246, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8672518496513366, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8674605057239532, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.8690516250133513, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8696977753043175, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8698150214403867, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.8700460231527686, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.870321896791458, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8706802502870559, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.87081907248497, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8709582850337029, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8714911210536957, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8715643212795259, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8722456481158734, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.8723084300756454, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.8723343048095703, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8725837528705597, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.8734194145202636, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8761679697632789, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.8774999879300595, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.877728431224823, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.8778105453252791, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.8789030776023864, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.8791858391761778, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.8792613269090651, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.879950918674469, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8800075232982636, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.8801492279767992, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8804440290927886, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.8805919528007508, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.8806484047174454, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.881877100944519, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.8819353879094123, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8827753797769546, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8834430396556854, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8839577035903929, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8848200368881226, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.8850332945585251, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8851434960216285, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8856113777160644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8859320417642593, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8870764970779419, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8894733388423919, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.889531497657299, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.8897380667924881, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.8902682371139526, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.8907692958116531, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 0.891055073261261, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8913829044103622, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.8922944918870925, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.8924088195562362, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.8927029927372931, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8934642613530158, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.8936026234626769, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8940398306846618, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8942403547465801, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.8943172857165337, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.8949114339351653, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.895813842177391, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8967934507131577, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.896855402112007, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.8969866514205933, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8971059186384082, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.8971753761768341, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8974049810171127, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.8976442650556564, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8977669294774533, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8977671282291411, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.8979695290327072, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.898093959748745, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8988546520471573, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.8989679548740387, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8993723618984223, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.8997835044860839, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8999445319175721, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.8999978379011153, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.9003936320543289, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.901022376537323, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 0.9011436626911162, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.9011730879545212, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9013283795118333, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.9017507553100585, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9048452064394951, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9051538542509079, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 0.9053405702114106, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9063540596961974, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9066628800630567, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.9076109924018383, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9081665650606154, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.908467345237732, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9094477133750913, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9098775107264518, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.90991151034832, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9107101503610611, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9114870772361755, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.9117252755165101, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.9119437809884549, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9120943892002107, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9124425038695335, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9139630962610245, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9140006561279297, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.9151637361049652, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9161894142627716, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.9165384531021118, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9173578476905824, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.9177226185798645, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9182149291038513, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.9189472422599791, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.9202301412820816, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9206541166305542, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9214926093816758, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9224572677612304, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9225891790390015, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 0.922929659485817, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9230821883678437, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9246643335223197, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.9247426838278769, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9255966365337371, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9257613406181335, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9272874615192415, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9287366108894346, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9294137642383575, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9301387057304382, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9307725846767425, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9314004063606263, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 0.9314926658868788, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9315259994268417, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9315887600183487, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9320501998066902, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.932070283770561, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9322068907618523, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.9323363888263703, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9325052313804626, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.932658042192459, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.9331058443188667, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9334531636238097, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9340429635047911, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.934073592722416, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9344231162071228, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9351080030202865, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9377435848712921, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9385574072599411, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9393687658309936, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9394437425136566, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.9394940141439438, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9399453848600388, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.9400283012390137, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.9405326634645462, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 0.9407871012687682, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9409988552331925, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9410286727547647, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.941210518836975, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9414334982633591, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.941758621096611, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9419584976434706, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9421860694885253, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.9424801561236382, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.9429124925136566, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9439926207065582, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9444434449672698, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.944455280214548, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.9445515528917312, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9446372156143188, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9448823750019073, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.94577573543787, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9459739581346511, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.9464023113250732, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.9474287229776384, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9474303965568541, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9483466252684594, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9486241743564605, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.948669816851616, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9488877713680267, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9490073682069777, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9495644915103914, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.9500214550495147, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.95034086561203, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9505527883768081, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.9505964908599853, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9511664390563965, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.951452179312706, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9526399612426758, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.9529300481081009, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9532027289867401, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9541055386066436, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 0.954253763437271, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9544366257190703, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9566665158271789, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9585039422512054, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.9585937094688415, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9594492273330687, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.960048359632492, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9602059770822524, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.9604682222604751, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9607293233275414, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9615729413032532, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9617911726832389, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.962413466334343, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.9628803060054778, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.9629912989139555, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.9631277294158934, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9631651699542999, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9638951826095582, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9641792745590209, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.9645057778656483, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9650960729122161, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.9651005196571351, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.9655772018432618, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.9661470293998718, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.968866099834442, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9690815970897674, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.9691173986196517, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.9691726677119732, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9695619601607323, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.9701418697834014, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.9706450001001358, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9713159010410308, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9718342811465263, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9724863637089729, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9735166597366334, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9742006033658981, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.9744121850132942, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.974890673160553, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 0.9752628564834595, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.9754368052482605, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9755847886800766, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.975655225276947, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9756732270121574, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.9757738307714462, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9763225027024746, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9764381438493729, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.976982370376587, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9771708877086638, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9772419661283493, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9773049818277357, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.9779151473045349, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.9781887322664261, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.9783452514410019, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.9783877407312392, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9786642180681226, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.9793386385440825, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9794594392776489, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9804015383720397, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.9804305956363677, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.9808615539073944, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9811681048870085, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9815390795469284, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9816179441213606, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.9821611956357955, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9827964425086975, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9839325070977211, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9839687094688415, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.9839725434780121, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9843457684516906, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9844231263399124, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9848730582594871, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9849210683107377, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9855397597551345, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.9860930428504944, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.9862384550869464, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9868780481815339, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9869161476045847, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9872064027786255, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9872597247362137, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9872908093035221, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.9876141175627708, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9880595417022704, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9880970857702195, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9881328821182251, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9883729547262192, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9884670023918151, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9887511775493621, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9892827498912812, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 0.9895137530416249, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9899633886218069, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.989976371884346, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9904485988616945, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9915076837539673, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.9915909414291381, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9922517509460448, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9925126001834869, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9926679924726486, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9927197054624557, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9934003980159758, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9937065947651863, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9938551109284163, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9938970268368721, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9942321807146073, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9944535799175501, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.995793079212308, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9961138949990271, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9965618357658386, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.9970248789787292, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 0.9970300909727812, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.9974022626876831, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.9977785244584083, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.9980305448770522, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9981548563241958, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.998576426565647, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.998724822998047, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.9989156053066253, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 0.9992621257901192, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9996528358459471, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.9997924596071244, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0000552892684937, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0012471899986266, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.0012910754084587, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0025267407894134, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0027410731315611, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.0028833688497543, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.0029092492461202, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0032648146152496, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0035855770111084, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.004199422955513, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.0048412487506866, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.00510250043869, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0067093908786773, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.0070194438695907, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.007028979063034, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0073151216506957, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.007539366930723, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.008902898490429, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.009161776304245, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0096306488513946, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0097092896699906, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.0098917398452758, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.010254628121853, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.0104820356369018, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0113800749778747, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.0118906665444374, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.012331308722496, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0124546246528623, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.0126621712595223, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0127870547771454, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0133326277732848, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0133902642726897, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0134389386177063, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.014070186138153, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.0141622633337974, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.014507696032524, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0146638751029968, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0149805967807768, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0150784537792206, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0158367025852204, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.0161958366632462, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.01643154501915, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.0165661410093307, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.0172656841278076, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.017580284178257, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.018463968038559, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0193104926347734, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0202080655694008, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.020610624551773, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.0206860706806182, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.020788191318512, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.0208191859722138, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.021362805366516, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0218432891368867, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0225487271249292, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.0226155371665953, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.022706387937069, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.022925196647644, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.023616600394249, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.024474447131157, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.024759867787361, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0253974080085755, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.0254649446010589, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0258346294164657, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.025874263048172, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0262264508605003, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0264765083789826, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0265686976909638, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.0265974358320236, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0266997136175633, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0268100470304489, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0278421477079391, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0278435961008072, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0278841004371642, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0282114908695221, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0289222631454469, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0289236233234405, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.0293615698814391, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0293689177036285, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.0297445998191832, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.029970814704895, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.0310723543167115, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.031326590538025, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.031604826450348, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.0318925619125365, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.0320964829921722, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0329352931976317, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0329754948616028, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0336357653737067, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0340152177810669, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.0345458583831786, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.0347794995307922, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0350257717072964, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0351076081991195, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0354762330651284, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.035498328924179, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0360704959034919, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.036913468003273, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0378706413507461, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0382787200808525, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0387021378278731, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0392061249017714, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.0393334809541703, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0402820677161215, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0404546320438386, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.041114322900772, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0419397552013396, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0420043069720268, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0424412667751313, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.042600088119507, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.042687835216522, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0427082359790802, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.042861752510071, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0435899123549461, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0439001698493957, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0440221458673478, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.044129446208477, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0442552716732023, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.044936180114746, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0455758526921273, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.0457575052976609, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.0460700664520264, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0469128773212433, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0471726834774018, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.0472084954977035, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0475649688243867, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0483686850070952, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0483694434165955, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0488992615789177, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0490334808826447, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0492015409469606, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.0492779514789583, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0497480944395066, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.0501325458884239, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.0502329289913177, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0506813633441925, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0508269877433776, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.050846247434616, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0510208249092101, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0513658702373505, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0516811640262602, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.052442467689514, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0533795107007027, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0535021126270294, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0535028697252273, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0535908982753752, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0536984640359879, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0539305836558341, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0540950894355774, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0543439511060715, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0549490993022919, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0552239999771118, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0558278535604475, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0562497828006745, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.0566131700277328, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0569332570433616, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0579139012098313, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0581531710624694, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0583294916152954, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0586347043514253, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0589269061088562, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0589376435279845, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0592548944056035, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0593107018470764, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0593721661567688, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0593965831995011, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0596677601337432, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.0598453149795533, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0603716448545455, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.060785198688507, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.061256624817848, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0618468225002289, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0618835583925246, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.0619545805454256, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0624287099838257, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.0628159493803977, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0639570460319518, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.0641566023826599, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.0642847294807436, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0649144847393035, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.0653473467826842, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0661357182264328, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.0666196205317973, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0668340311050415, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0670043904781341, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0680034726858139, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0681829083561898, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0684595351219177, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0686921194791794, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0693311439752577, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0698782638311386, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.070581117272377, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0706403541564942, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0706441328525542, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0707555108368396, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.0710142259597777, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0711428971886634, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0713419616222382, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0713543117642401, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0715382680892944, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0716411457061767, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0716948211193085, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0717600125074387, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0722410993576048, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.072314890220761, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.072603690624237, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0731649923920632, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0732078731060029, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.073387649655342, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.073650979310274, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.0741948399543761, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0742012221813202, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.074580644249916, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.0751376688480376, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.0752985137701034, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0756921679973601, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.0759500265717505, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.0764539751410485, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.076735294610262, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.076962058544159, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0774131492376327, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.077769433259964, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0778125740587712, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0779775099754332, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0782990589737893, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.079217530965805, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0796695057153702, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0797980997562409, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.0802209317684173, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0802641607820989, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0803521518707275, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.080408705949783, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0805104765892029, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0818873512744904, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0818959760665894, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0820650100708007, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0822831497192382, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0823623094558716, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.0825453953742978, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.083327202796936, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.0833412739634514, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.083363504767418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.0841315895318986, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.084328844755888, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0846343660652635, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.084816481590271, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.0855912685394287, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.085886742591858, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0862491130828857, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.086532599210739, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0866394624710083, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.086936086475849, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.0875321340858934, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0878226444721222, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.088078898191452, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.088230104804039, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0883969233036042, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0885959163904189, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0889974851608275, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.089275209903717, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0895144448280334, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0897042379379271, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0899222109317779, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0900471585989, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0901152849197389, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.091097836256027, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0912417218685149, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0912890970706939, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.0922888606786727, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.0924107954502105, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.092526517868042, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.0934453994631768, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0937770698070526, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0938751522302628, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0939628844261169, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.0941764459013938, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.0942743990421295, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0943686742782592, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0948666516542436, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.095472993016243, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.0961927339434623, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0962527232170103, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0980191812515259, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.0987761557102202, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0993497207760812, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0994979084134102, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1007199600338935, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.1010433673858642, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.1010906457901002, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1011817544698714, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1012975022792815, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1016623467803002, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.102550098657608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1033662649989129, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.103560108564794, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1037141622304916, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1044815737009048, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1048774063587188, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1052216048538686, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1057054178714751, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1057543680667876, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.105893760919571, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1064059302806855, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1065229997634887, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.106527872443199, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1066235959529878, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.106881468296051, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.107204086303711, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1074355394244193, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1075651190280915, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1087197440862657, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1088109940290451, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1097685191631317, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.1100517600774764, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1107550964355468, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1110571771860123, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.111091426372528, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.1112224564552307, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1117547646164894, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1118240520954132, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1119961798191071, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1121876972913742, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1122084472179412, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.112245536327362, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1126086980700491, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1126668472290038, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1128060162067412, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.1129486560821533, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1132547348737716, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.1136798218488693, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1142170131206512, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.114990519285202, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1160058319568633, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1166182503700255, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1168236628770827, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1169887051582337, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1170781210660934, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1173121399432422, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1180929094552994, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.118099238395691, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.1195269674062729, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.1196605435609819, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.119926503300667, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.1199304938316346, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1201983499526977, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.1202941477298736, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1208075528144836, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.1210597709417343, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1211458222866058, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1215272591114043, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1217362809181215, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.122370755970478, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1229263305664063, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.1232563242912292, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1242185267806053, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1246203848421572, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.1246937453746795, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1251030206680297, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1251817271113396, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1253704309463501, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1256030082702637, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1256788909435271, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1257029175758362, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.1265652179718018, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1269218326210975, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1272380948066711, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1275532352924347, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.128172285914421, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1282465860843658, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1283783781528474, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.1291059583425522, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.12932218170166, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1293941140174866, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1294322653859854, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1294667776860297, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.1295561168193817, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.129657448887825, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.130066397100687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1309785828590393, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1314569429159165, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.1321519852280617, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.1322445482611656, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.132416479587555, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1325382965803148, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1326542973518372, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.132675685286522, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.132710320800543, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1328479603528976, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1329798862934113, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1336679563522338, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1338721074759959, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1342642740011215, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1344717059135436, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.134646280169487, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1350252070128917, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1354083523750305, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1356325731277466, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.1365522240400314, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1366797506809234, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.13671632707119, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.13683682847023, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1370276898145675, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1372797459959982, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1377322289943694, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1381354246139526, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.1388242813944818, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.139181356191635, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1392349660396577, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1395087213516235, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.1396423012018204, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1399101078510285, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1404609561562538, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1405060338974, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1418172389268875, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1424760193824768, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.1427407117486, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1427434656620026, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.142810611784458, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1432729530334473, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.1438857972621919, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.14406378865242, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1440683946609496, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1443023251295088, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1449538472890854, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.144988051056862, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1451707661151886, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1451862204670906, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1453259915709495, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.1457502335309981, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1461452366113662, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1462877541780472, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.147533522605896, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1477673414945602, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1478081093430519, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.148675607442856, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.148746195793152, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1491334125995636, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1492148265838622, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1492296457886695, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.149304316997528, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1499967626295984, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1504302397370338, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1514975011348725, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1522663474082946, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1529740154743195, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1547215626239775, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1550965011119843, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1551009283065796, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1553682233393192, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.1556893781423567, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.155978034734726, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1560142159461975, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1560575425624848, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1560877054929732, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.156422911643982, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1566076443195343, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1574367970228194, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1575050727128982, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.1580805070698261, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.158277866721153, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.158447265625, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1584796118736267, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.158585971593857, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1589796741008758, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.159177005648613, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1592004747390745, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1593240574598311, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1593245733380317, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1599270601272582, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.160514140188694, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.161376729786396, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1616141028404237, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1619692549705505, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.1623557872772217, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1627293915748595, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.162863756775856, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.163649632036686, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1638499915599823, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.163869074344635, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1642675642967224, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1644506767392158, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1645051602125167, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1645661570727825, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1649076819419861, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1652860090732573, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1660752207636833, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.166352427005768, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1664682821035384, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1665527880191804, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.166648354291916, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1667070746421815, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1670567111968992, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1676615328788755, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1680036354064942, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.1687471568584442, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.169631724357605, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1698786590099335, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.169943438768387, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1700107023715973, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1707190768718718, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1708724796772003, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1709176969379187, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1709428073763846, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.1711886260509492, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1714068803787232, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1715517343878745, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1716131925582887, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.171757330060005, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.1719075129032135, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.1725343749523163, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.1726222772598267, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.172731126099825, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1728973822593687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.1732904494404792, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1733663275837898, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1734163999557494, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1734553784132005, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.173721449136734, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1737823847532272, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1738640117645265, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.1741005972623824, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.17412093436718, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.174130481481552, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1745766252279282, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.1747539508342744, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.175797312259674, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.17603859603405, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1763273286819458, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1763556361198426, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1763800532817839, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1770922392606735, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1772977681159973, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.1775286853313447, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1784938354492187, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1785475396215914, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1788064458072185, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1788590536117554, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1795523599386215, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1796953797340393, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1799266550540923, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1801714555472134, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.1806045177578928, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.180729979634285, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1809096500873566, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.180922313094139, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.181095473766327, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1812008291482925, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.1812626705169678, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1818133056163789, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1819174618124961, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1822544205188752, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1823428410887717, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1823925570249556, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.182465680003166, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1825273767709732, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1827707040309907, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1832415610551834, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.183336302638054, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1836046726107596, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1847861194908618, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1856967315673828, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.185770552664995, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1870422676801682, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1870985665619371, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.187456034183502, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1885135564804077, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.1887992756366728, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.1890507459640502, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.1891784162521362, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1893329427242278, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.1897786026000976, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1898424863815307, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1903312265872956, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1905379891395569, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1909595952033996, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1912147763371468, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.1914721310138703, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.191513533949852, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1921170905828475, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1923226314783097, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.1926681563854218, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.193011538684368, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1932858560830355, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1934251980781554, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.1937037125825882, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.194228090405464, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1947636291980743, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1949568316936492, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.1950400904417038, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1953844026327132, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.1957175029441713, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1959527790546418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1967217206954956, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1974721908569337, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.198767086982727, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1989935801029206, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1992623761892318, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.1993214969635009, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1995410074144601, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.1995491820573807, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.199572672009468, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2003934339284896, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.2006638564169407, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2006974831819535, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2017000504434108, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.2017523035407067, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.201946598768234, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2020080180168151, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2022306070327757, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2023740649223327, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.202992297887802, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2034845188856125, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.203589000105858, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2036739408969879, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2036983489990234, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2037106618285178, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2042333397865295, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.204601080775261, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.204626046180725, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.206292489171028, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.206504605770111, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.2074873244762423, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.207822914600372, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2079553816318511, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2083155289292336, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2086799581050873, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.208918525338173, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.2091000989675522, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.209413358926773, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2095628324747085, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2108691544532775, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2113046199083328, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.2113183349370957, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.2118237602710724, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.2121406303644178, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2121646761894227, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.212300381064415, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.213075375556946, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2131316125392915, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.2131961078643798, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2134685341864824, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.2141593639850616, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.2147558987140656, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.2147685573101044, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2149228692650795, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2149468020200729, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2150047063827514, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2155731070041658, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.2155862197875975, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2156518012881279, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.2158183955848216, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.215869292974472, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.2164634570479393, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2169479954242708, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2179839033484459, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2180655002593994, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.2182242006063462, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.2182347044348716, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2183970916867257, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.218765609025955, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2188456342220306, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.219880692720413, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2199360654354094, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.220035719871521, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2209561395645143, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2210055031478404, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.2219280109405517, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.222249651312828, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.2228133187294006, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2228325456380844, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2234574933052063, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.2236117005348206, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2241217181086541, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2243560045957564, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.224702876806259, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.225004394352436, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.225172500371933, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2251747727394104, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.2253757685422897, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2259368613362311, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2259837571382524, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2261759088039397, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2264927492141724, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2268468902111054, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2270101189613343, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2271782414913175, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2273240283727644, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.22742484664917, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2277037177085877, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2277079105973243, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2282076060771943, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2284138917922973, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2284859031438828, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.228560088634491, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2286129951477052, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2290545761585236, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.2297819708585738, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2303008351325988, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.231125675201416, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2316720776557921, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.231753465592861, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.232228826165199, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2323781665414573, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2326258662939071, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.232729040145874, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2327508989572524, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2328656063079833, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2329449695199728, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2330015555620193, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.2341341882944108, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.2343170046806335, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2348447115421295, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2349895792007444, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.235126222848892, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2359618828296661, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2366228699684143, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2372017860412599, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.237355664730072, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2374689251780508, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2375131607055665, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.2376206934452056, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.2384033278226851, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.2389122724533081, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2393899188041686, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2394693703651427, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.2395631062984467, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2406124026179313, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2406694177389146, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2413958788514137, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2414695698022844, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2419797756373883, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2421698033809663, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2426537096500396, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2430524916648864, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.243053564429283, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2431426808834076, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.243456225156784, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.243661993741989, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2442595219612123, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445047547221182, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445318520665167, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2445571527481079, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2451037096977235, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2453710362911223, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.24555746614933, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.245790148139, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2461296141147613, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2464210275411607, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.2464781866073609, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.24697012758255, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.247449083685875, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.248412902712822, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.248858909368515, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2492913488149644, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2495196838378906, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.249805443048477, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.2500996903181076, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2506614446640014, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.2507887959480286, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2514893040657042, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2523872871398924, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2524703726768494, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.2535302221775055, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2538080052137375, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.25447074174881, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2545394882559777, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2547107093036174, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2553999902606008, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.255672797679901, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.2559172365665436, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.256157116651535, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2568185716867446, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.2568597660064698, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2572149872630836, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2572679624557495, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2573097109794618, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.257878007173538, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.2579129383563994, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.258162288427353, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.2581990916132928, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2583328559994698, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.258658321261406, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2588189766407012, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2588403031826019, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2590452094078064, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2594862492084502, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2596591730117797, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.260091652035713, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2605842638015747, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2610995729118586, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2612726211547851, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2618624180555345, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2622084241956473, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2627122163772584, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2629660741090774, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.263277733385563, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2637933254241944, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.264198021888733, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.264324443101883, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.2644008711576462, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2646747634410858, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2649731819629668, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.2649783864617348, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2651285932064056, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.265193262696266, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.265494620859623, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2656156569719315, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2657224659919737, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2665656403303145, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2668405151367188, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2668662514686584, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.2669831202030182, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2672824837267398, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2674663960933685, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2675511837005615, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2675757185220717, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.2676679823398591, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2684665739536285, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2686259225606917, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2692975685596466, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2693283901214598, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.269498236835003, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.269600009918213, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.2699883937835694, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2702135741710663, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2706028597354888, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2711218104362487, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2721146658658982, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2722176745533944, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.272444124519825, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.27256670743227, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.2728394241333008, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2730072708129883, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2735114455223084, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2735145252794027, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.273655313551426, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2736858278512955, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2737457292079923, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2745149836540222, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.2748253226280213, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.274883782863617, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2750106023550032, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.275108258485794, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2751694118976595, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2755898342132568, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.2756651029586792, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.2759167492389678, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.276469317138195, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2764834616184235, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.276766179561615, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.2771128609776496, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.2774770901203154, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2776659578084946, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.2783773452043534, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.278399002611637, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.2785214558839797, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2790948748588562, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2794184237718582, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.279567049741745, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2801245115995408, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.2802399591207503, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.280376872420311, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2806914303302765, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2807814006805418, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2808357685804368, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.2820487205982207, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2824026124477386, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.2824575755596161, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2833797991275788, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.283564223408699, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.2836234407424925, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2850175187587738, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.2850350186824797, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2852699309587479, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.285674626737833, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2863050699234009, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.286314210653305, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.286460910797119, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.2865045615136623, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2878554665148259, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.28789635181427, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.287969485282898, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.288053663134575, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.288068825006485, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.2882042840719223, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.2882121626138687, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2883574829101563, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.288662077486515, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.2889633562266827, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.2889757871627807, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2893567517995834, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.2893610820770263, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2896505728363992, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2902149916887282, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2903265001177786, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.291357508301735, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2915854053497313, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.292645646929741, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2928828254938125, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2929395660758018, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.292986238002777, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2938129652142525, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2940377447605134, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.2940906286239624, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2941042470932007, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.294788048028946, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.295846273303032, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2961256757974624, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.29648896753788, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2965001881122589, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2966798727512359, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2968990956544875, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.2979236737489699, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2980957542657852, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2983018473386765, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.2983676288127899, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2986110941171645, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2989471554756165, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2993536133766175, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3003900170326232, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.300602905511856, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3014185265302658, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.3014895901083947, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3017965793609618, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.301805184841156, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.301810483932495, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3023189607858658, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.3044309780597687, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3044717342853545, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3044827073812484, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.3047610018253326, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3049516544342041, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3054452613592147, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3057035731077193, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3059039340019225, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3061656594872475, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.306288183093071, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3064177635908127, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3064480991363525, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3067478083670139, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.306784102320671, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.307906848192215, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3080960268080233, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.308551162481308, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3090039092302324, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3092384294271469, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.3097322063446044, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.310144631922245, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.310320417881012, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.311190249443054, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.311542965888977, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3117063555717468, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3117212817668915, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.3117224589586258, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3118670601844786, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.3119568840265274, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3124546796679497, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.3124562639594077, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.3128689140677452, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3129359312355517, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3131315932273864, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3132178382873534, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3134556994438171, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3139395639896392, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3141018942594527, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.3148029550909996, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.314983524441719, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.3154627685546874, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3157829687595366, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.315994225502014, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.3160212501883506, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.3161579877138139, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3163570433855056, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.3164451763629912, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3164802894592285, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.317182038784027, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.3172523515224455, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3174623684883116, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3178813235759734, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.318626489162445, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3193671987056732, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3196965992450713, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.3197059497833252, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3201689782738686, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.320310755252838, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3209193408489228, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.32132937759161, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3228353456258772, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3233416841030121, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3233602770268917, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3235272586941718, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.3245241001844406, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.3249909937381745, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.32668805873394, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.3267080783843994, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.326729215234518, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3276256430149078, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3277433071136475, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3277980056256056, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3278208632469177, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3283361272811889, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.328814271092415, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3288431212902068, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3288901090621947, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.329128805845976, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3291599839925765, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3297507659196852, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.329865675032139, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.329993736743927, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.330053715467453, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3306114077568054, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3307581782341003, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.3311425372958183, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.331734648346901, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.3329135417938232, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3329461888074874, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3329702842831612, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.333287979722023, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3346209619790315, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3346728983521463, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3352928578853607, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3353062634468078, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.3356382161378861, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.3358825981616973, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3359504256248473, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3362213716506957, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3372200460433958, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3372941882014273, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3373357951641083, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3379688190221786, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3383282550275326, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3385834038853646, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.339330087661743, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.339451030254364, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.3399842683821916, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3402878971099852, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.34064542388916, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.341056701540947, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3411517949104308, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3412682354450225, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.3414656937122345, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3416240200996399, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3419297322630883, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3419982314109802, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.3421663615703583, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.3421750948429108, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.3425555679798127, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3425621151924134, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.3426572501659393, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3429890334606172, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3430540845394134, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.3434198067188263, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.3436618953943253, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3438133046627043, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.3438747049570083, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3439538061618805, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3443136917352674, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3455763921737671, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3457993969917297, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3458165690898896, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.345816738963127, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3459816489219665, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3463023979663848, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3466098413467407, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.346781825274229, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.347072219848633, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3473331645727158, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3473761591911315, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3474469230175017, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.347991520166397, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.3480030301809311, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3487317115068436, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3489252555370332, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3490514472723008, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3493617281913757, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3495793238878249, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3497422367930412, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.3501017365455628, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3503839701414109, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3507744699716568, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3508429232984782, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.3509022772312165, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.3509874577820302, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.351419883966446, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.351424762159586, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3515627340078353, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3517092064619063, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3520561428070068, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3521182894706727, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3526166605949403, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.353035505414009, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3532036989927292, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.353425912618637, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.353647212743759, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3540404796600343, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3543722302317618, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3544619619846343, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3548461299985646, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.3548656195402144, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3554134645164013, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.355992341786623, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3565146418213843, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.356932810306549, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3581148461103438, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3582237632274627, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3583797693252564, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3587980136871338, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.3588591716438532, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.3591956872940063, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3604056553840636, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3605182573795318, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3608753430843354, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.360919356405735, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.36185402572155, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.3618554845452309, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3618731305599212, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.3631398060023785, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3634249181747435, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.363643764257431, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3647117540836333, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3647809019908308, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3658879384994507, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3662383365631103, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3662926003932951, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3669246363639833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3669361785054206, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3677672371864318, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3687674403190613, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3687836885452271, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.369115690946579, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.3691217392683028, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.369421910047531, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3696078181266784, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3701489572525023, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.370218774676323, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3702292048037052, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.370653076827526, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3706976991146802, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.370978860616684, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3712328106164933, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3716639697551727, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.371949361562729, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3720141053199768, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3731223106384278, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3742104530334474, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3743419706821443, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3743433923721313, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.374400000333786, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.374490545988083, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.3745349810123444, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3749801129698753, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.3749926613569259, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.3753421798944472, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3754923090934752, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3759255588054657, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.377598753631115, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3777417466640471, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3777845860123634, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.3778532087802886, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3786060690879822, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.379000167608261, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3790293709039687, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3796684101819991, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3798093155622482, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3798220351934432, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.3799200385808945, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.3801362231969834, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.380561923980713, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.380611956551671, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.3807407736778259, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3811505708694458, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.3814833270311353, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3817279160022735, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3821219201385975, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3822018563747407, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.3824641168117524, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.382643179655075, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.3829119951128959, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3830936313271522, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3831788167953492, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3837285697460175, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3843189630508423, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3848715335726738, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.38499972820282, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3853567422032356, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.38557870388031, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.386323773920536, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.387208648085594, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3873851954936982, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3879624485969544, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3879848376512527, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.3882122099995613, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3890215158462524, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3894233971834182, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.3895928428173066, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3898478388786315, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3898489402532577, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.3899388880729675, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3905784369707106, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3906566561460494, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3912955420017241, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3914481106996537, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3914799213409423, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.391789934158325, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.3919424176216126, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3920154005289078, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.392097571492195, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.3922474757432937, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.392300127506256, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3923653721809388, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.3927490442991257, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3927817412316799, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3928238101303578, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3930594787597657, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.393179510831833, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.393390619814396, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3936654002070425, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3940250068902968, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3940303496122362, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.3940454349517821, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3941033065319062, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.3943568453788757, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3954484314918516, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3960285156965255, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3960764006376265, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3962278906106949, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.3963168486952782, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.397109228372574, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.397471097111702, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.3977055393755435, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3980314449071884, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.3984536323547363, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.398580132484436, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3988703126404434, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3993730098605155, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.399439267873764, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.3995672065019609, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.3998017713427544, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3998348641991616, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4004991441965102, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4009284124374388, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.401613317489624, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4020033001899719, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4021509163677692, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4027880776524544, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4031451511383057, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.4036362636089326, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.404047726392746, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4041470930576323, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4050356120467185, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.4054688379764557, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.406106551170349, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4069226239994168, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4074744403362274, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4078077630996702, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4082462356090546, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4082952439785004, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4096608672142028, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4103223905563353, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4107495040893554, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4108583152294158, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4111608282327652, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4112306044101715, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4112409591674804, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4113329428434374, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4127621088027955, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4130271777510643, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4137922406196595, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4138897690773011, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.414388462215662, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4145033602714538, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4145190641880034, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4149966708049178, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4150501847267152, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.4151182923316956, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.415557039141655, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4158903524279594, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.415991908311844, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.416033923983574, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4165477008819578, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4168289752006529, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.416896034836769, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.417103001832962, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.417250825881958, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.417263792514801, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.4173446297645569, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4173992395401, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4174226911664007, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4175143394470215, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4177747431993484, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4178217158317565, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.418121071457863, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4184040546417236, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4185050487518311, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4188990741968155, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4191509306430816, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.4194887631237507, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.4196272314190863, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4200205281972884, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.420102985203266, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.420616219997406, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4210114166736603, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4214343552589415, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4216918766498565, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4217666134834288, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.422131054162979, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4223053634166718, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.4227982044816017, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.4231562033891678, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.423182737827301, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4233819308876992, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4233985096812247, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4238386318683625, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4241429806351662, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.424767118692398, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4248010770082473, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.4253272120952605, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.4257213473320007, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4263512479066847, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4264571014642715, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4270993203520774, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.427158652305603, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4273456010818482, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4273701775074006, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4273761794567108, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4274224955439567, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4278223842382431, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4280325682163237, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.4284487038850784, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.4287651569247246, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4288418308496476, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.430337804555893, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.4304524869918822, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4311604604721069, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4315102088451386, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.431624525785446, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.4319932818412782, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4322724536657332, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4324830473065375, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.4325110960006715, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4326510564088821, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4335243642926216, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.4341230276823045, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4341457191705704, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.4343675493858754, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.4344475463628767, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.4346961483955383, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4355213106274605, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.436339031457901, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4367408440113068, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.437243476629257, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4375874012708665, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.4376198530197144, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4377725977897644, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4377964706039055, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4378126459121703, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.43823813354969, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4383385882377624, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.438396360039711, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4384397537708282, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4384685591459274, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4392974987626075, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.4393303513526916, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.439856425732374, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.440154141187668, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4405997693538666, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4406083450317382, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.4411447689533232, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4412494378089904, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.4418153017759323, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.4421028423309328, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4422174947261808, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.4424711096286775, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.4426380264759064, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.4437544797062873, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.443949596643448, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.44395463347435, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.444097840845585, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.444392555952072, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4444691263139249, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.445134162902832, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4452842209339143, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.445313729405403, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4463425070047378, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4465025444030761, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.446749873638153, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.4470076189041137, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4475651290267706, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.447571572780609, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4480432436466217, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4481541589498519, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.448527179777622, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.4491006284952164, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.449122373819351, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.449397428393364, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4494286894798278, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4494871840476988, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.4496923804283142, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.449744176864624, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4501372691243888, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4504877673387526, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.451099687501788, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.4511441321372984, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4513078689575196, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4513372943401337, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.4522238838672639, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4529275152683259, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4530203363522887, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.4534035222530364, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4536720410585402, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4539482401013373, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.4546473712921142, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4548569121062755, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.4548871250152586, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.455010360479355, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4555073590278624, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4560959310531616, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4561827063560486, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4566139028072356, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.456911626458168, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4570552453398704, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.457326684951782, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.457654752135277, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4580973595380784, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.458910585194826, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4590758994817734, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.4591062173247338, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4601812422275544, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4608954668045044, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4611959837973116, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4612959787845612, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.4618914723396301, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4621831991374492, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4622851313352583, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.462384913921356, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.4629014868736268, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4631351679563522, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4633462250232696, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4637993515729903, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.463882452249527, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4642929005622864, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4644216104075312, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4647246258258817, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4651694644093514, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.465279072880745, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4655372874736785, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4659411566257474, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4661257103681564, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4663045973181723, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.466325932741165, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.4665672109127044, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4667618128657343, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4669915588498115, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4671219396591186, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4678708218038081, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4679341015070677, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4683241799473763, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4683350431919098, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.468501843690872, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.4686041954755784, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4695570245981215, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4696022897958756, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.469834205508232, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.4701347068548203, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4706445832252502, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4707231402397156, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4710909113883972, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4715109829902648, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4723019901514054, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4725461230278014, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.4727415370941164, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4728660807609557, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4734120745658874, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.4740092531442641, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4741270051002502, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.474275733947754, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4753249781131743, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.4754662663936613, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.475969217777252, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4760962934494017, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4763009814471004, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.476808111667633, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.476892344713211, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4777283895015718, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.477847488284111, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4779886871576309, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4786576628684998, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4787994503974915, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4788737260401248, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4789028928279877, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.4792503386735916, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4792756605148316, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4794279308319092, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4799288318157195, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4800875812768937, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.4802428305745123, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4805942014455795, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4808689299821853, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4812486829161642, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4813525319099425, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4818754659891127, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.4826995968818664, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.482801127433777, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.482943373978138, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.4831846640110016, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4835413098931312, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4842892513275145, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4845762537717817, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.485069395661354, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4851923959255218, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4852456078529357, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.4860647887587546, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4869631366729734, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.4870971739292145, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4873120877742767, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4879212722778319, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4881995052695274, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.488267421722412, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.488311934649944, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.488746618539095, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.488984634041786, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4890272111296654, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.4895776227712632, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4895888016223906, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4897382185459136, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4897845589220524, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.4900380358695984, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4900921599864958, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4907044175863267, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4908448525369167, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.49088915219903, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4919388756752014, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.4922690115869046, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.4923984841108322, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4929342374801635, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.4930353016257285, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.493532812654972, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4935351238250731, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.4935428619384765, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4937691271305085, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.494155466556549, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4944718227386473, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.4947805511951446, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4948421076536178, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.495204614162445, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.495291511774063, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4956667230129241, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4957764327526093, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4959711283445358, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4964612604379652, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4964879512786866, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4970610224306582, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4971264348030089, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4971350864171982, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4975742094218731, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.4979722678661347, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4980430529117583, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.498643975019455, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4989364476203917, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4991245688796042, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.4994183871746063, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4995138362646103, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.4995971113443374, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.4997069239616394, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.499750470727682, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.499851671665907, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4999164092540742, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.4999502782821654, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.500087587594986, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.500456394314766, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5011395947933195, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5012647286653518, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.501524379968643, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.5016118527054787, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.5020666748285294, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.5031532676219939, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5036670804023742, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.503720236301422, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5045835668146608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5049042735099794, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5050567955970764, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5051952838897704, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5055404663085938, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.5057408676147461, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.5058841094970703, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5059518699645995, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.5064925253987311, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5068464622497557, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.507130558222532, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.5072108428925275, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.50731849527359, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5075055212974546, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.5075225130319594, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.5075392980724573, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5076407644748688, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.508324701398611, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5088348582983016, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.509845276236534, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5100231561660766, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5101907598972322, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5103061364889143, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.5113538340330124, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5114100337028504, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.511416956782341, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.5115058646202086, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5129951238632202, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5144484505653382, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.5145435886383054, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5155210123062133, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.5164628878831863, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5165960773825646, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5168158099651337, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5168563008904457, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.5170335814952849, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.517641043663025, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.5176684856414795, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5186109170913695, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.5189730763435363, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.519034262061119, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.5195272491574285, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5200535521507264, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.5201763973236084, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5206385464668273, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.520719330072403, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5208396956920622, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5215993136167527, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5220387058258056, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.522092010140419, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5223910586833953, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5231809512376784, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5233807862997053, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5234745786190032, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5236464619636536, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.524057889342308, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5242240205407143, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.5244111554622648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5246812748908998, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.525346432685852, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5255212411880492, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5256811977028846, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.5262339369058608, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.526802677333355, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5270265519618988, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5273205861449242, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5274603471159935, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.527472234249115, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5279604229927064, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5281553239822387, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5284676032066344, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.528754660487175, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5289431303739547, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5290359005928038, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5291513056159018, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5297304723262788, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5297442295253276, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.5301416087150574, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5307980851531027, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5308593052625656, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5308994680643082, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5311471388339997, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5312813259661198, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.5313348803520204, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5322370147928595, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5324755446910856, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5332800924777985, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.5333744900226591, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.53347171998024, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.5336250097751616, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5340503261089324, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.5342887969017027, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.534945899248123, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.535782729834318, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5359099846929312, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.536663310289383, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.5370842606425286, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.537454183578491, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.5377355099320411, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.538382555603981, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.5384469244480132, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5385719866752623, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.5386232321262359, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.5391005964279174, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5392390996217729, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.5406735167503356, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.540907790184021, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5412804276943206, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.541915274143219, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5422400817871094, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.5431840152740477, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5434700504541397, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5437105374336242, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.543982310771942, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.544145956993103, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5442402992248536, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5446757645010947, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5448535072803498, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.5450934141874313, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.545379231929779, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.5454605922698974, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5456209421157836, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5460962698459624, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5468488916754723, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5472202286720276, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.5477503255605698, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5477801249027252, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.549125924706459, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.549153311729431, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5492777690887451, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.5493997485041617, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.5495794266462326, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5497839406728744, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.5498806822299958, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5507353949546814, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.550776258587837, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5511295483112335, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5512107179164887, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.551310858130455, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5516432017087936, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5521598875522613, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5523703013658523, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5530194520950318, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5530784014463426, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5532853341102602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.5533569650650023, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5534903764724732, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5535690784454346, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5550355405807494, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.5552442226409913, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5555772542953492, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5556509986519813, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5564271912574767, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5564892768859864, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5566252875328064, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5576226354241371, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5576801914572715, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.558823463320732, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.5592271324843168, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5593310761451722, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5593781995773317, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5595491428375243, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.5598769785761832, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5604266286492348, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.5616415657103062, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.56174245929718, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5621443689465522, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5622257307767868, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5623150997459887, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.5631063163280488, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5632397323846816, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5637934196591377, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.5652460503578187, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.5655289278030395, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.565563789486885, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5657193840146064, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.566160239458084, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5673263580799102, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5673860807418822, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.567548280954361, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.5682341412305831, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5687083512544633, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5697367310523986, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.5699867442846298, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.570708061814308, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5707295604646205, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5708311983048915, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.570857548713684, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5712229553461075, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.5720596016049384, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.5722798244953153, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5734360084533692, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5734783191680908, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.574022530078888, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.574155135512352, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.5741650045514106, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.5741697624921798, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5742400567177683, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5743831634521483, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5747139990329742, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5749350206851958, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.575216560125351, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5763756737709045, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5765310690402985, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5767676323652267, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5769590125083923, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.5771525580883026, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.577446422100067, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5775317288786173, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5777460248470305, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.5777576044797896, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5781004905700684, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.578176667973399, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.5785086210817099, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.578631310224533, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5787812844514846, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.579625639438629, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5796981792747975, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5803554013371468, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5804679021835326, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.58053626871109, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5807987065315245, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5808343980312347, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.5809907112121582, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.581413322687149, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5816649533808231, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.581820364356041, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.582530400276184, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.5829287246465682, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.5833712086677552, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.5834887226223944, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.584121295928955, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.584499255180359, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5845229820013045, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5845437870025634, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.5848249942064285, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.5855218293070792, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5859596894979475, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5863343358635902, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.587017528772354, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5872633740901947, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5873322860002517, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5877507706284522, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5877726927399636, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.587926486134529, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5883457335829736, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5883658841848374, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5888580501079559, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5888893518447875, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.5890283495783806, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.589477723836899, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5895458803176878, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.5898203552365302, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5905885577201844, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.5912233397960662, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5917310684919357, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.5920956704616547, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.593385265827179, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.5939129235148428, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.594790741920471, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5949699014425278, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5955701887607574, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.5957105785608292, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5960649252533912, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5961232051849366, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.5961959153413772, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.596220617175102, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.5964675101637842, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5966936510652303, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.596790479183197, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5973533154129982, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5976469163894653, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5978069657385348, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5979499683380127, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.597967255115509, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5981436939239502, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.5988126251101495, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6000946879982947, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.60047317302227, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.601586233139038, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6016839895248414, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.601874183177948, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6025818049907685, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6027962136268616, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6028615951538085, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6028986156582832, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6029678094983102, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.6039721474647521, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6046424396336079, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.604734609335661, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6049288556575774, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6049754738807678, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.6050685750246045, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6052088755369187, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6054216206073761, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.6056024137735367, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6060994267463684, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6061894357204438, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.6062880322933197, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6066079870462417, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.6068544074892999, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.6070415019989013, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.6075833768248557, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.6080554217100143, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6085808936357497, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.6088231086730957, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6088911123275758, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.608901499390602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.6089219913482666, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.609053906917572, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.6094139039516449, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6099451192319392, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6106128215789794, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.610857654094696, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6118724138140679, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.6121134419441223, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.612512287557125, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.6125524759292602, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.6127665046453477, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6132668242454529, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.613269971370697, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6134663076400755, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.613594752550125, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6138822841644287, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6142002556324004, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6145376892089842, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.6149540083408354, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.6149865255355835, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.6159905881881713, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.6161996845006943, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.6163668708801269, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.616696138858795, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.6169966654777526, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.617002248764038, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.617080687046051, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.617394228339195, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.6180333063602448, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.6180418342351914, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.6180767915248873, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.618256782054901, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6183372364044188, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.6183684871196746, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6190730199813843, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6192914947867394, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.6204386487603188, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.620681487083435, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6215388581752777, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6215849995613099, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6220894753932953, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6233161152005195, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6248542354106903, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6251214444637299, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.625308014512062, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6254666239619255, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6258640397191049, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.625891238451004, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.6260187003612518, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.6261632130146026, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.626171737909317, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.6262701154351233, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6269377813339232, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.6271870419979095, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.6275010930299758, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.6296569752693177, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6303403396606444, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6305015790462494, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6308828384280205, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.631142036676407, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.6314718604683875, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.632968135356903, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.6330769941806793, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.6351746678352357, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6359140698909758, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.63598140335083, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.636107897758484, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6364457309246063, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.636586892604828, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.6368995577096939, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6369876623153687, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6370614529848098, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.6372363731861115, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6373905453681945, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.637423395037651, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.637818554162979, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.6378771352767945, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6382166981697082, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.638349692583084, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6385496586561203, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.6388198778629302, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.639149287700653, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6397341072559357, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6397615313529967, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.640686516523361, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.640715942144394, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6417351350784302, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6417883336544037, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.641940794944763, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.64206120967865, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.6421240419149399, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.6422480301856992, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.6435054976940155, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.6438249543309211, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.6442171589136123, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6447685286998748, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.6450113848447798, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6452662916183471, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6462226269766689, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.6464651541709898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6472749561071396, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6479135484695433, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.6481681988239287, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.6482768373489378, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6488916521072388, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6492088422775268, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.6494706362485885, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.6495634571313857, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6495755463838577, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.6498304426670074, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.649846633076668, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.649953810930252, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6500540823340415, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6501185879707336, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.650158830165863, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6518700302839278, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.652088304042816, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.6521053105592727, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.652570258140564, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.6526816220283507, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.6526885882019997, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.652726686000824, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.653188872396946, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6533589408397673, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6535077021121978, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6540178776383399, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.6540221080780029, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6545829684734343, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.6549458341598509, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.6553491071462632, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.655961772918701, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.655973158955574, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.65614213514328, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6562079713344573, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6563528583049774, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.6569371025264263, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.657737931728363, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.658493208885193, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.659054751753807, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.65910815179348, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.6596220955848693, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.659724180459976, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.6610590831041336, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6612754479050635, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.662747879385948, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6638370203971864, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.6641271338462829, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6641634151935576, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.6643911854028701, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.6645798802971838, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.6646652817726135, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6652281806468963, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6661522328853606, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.6665068343877791, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6667497382164, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.666830281972885, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.6670170545578002, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.667265977025032, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.667952594280243, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.6682733998298644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.668950484752655, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.6695407526493071, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.6699607685804367, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6703035757541655, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6704502121210099, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6704627559185028, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6707015500068665, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6715821504592896, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6718625054359435, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6726088166236877, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.672736692905426, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6745841012001037, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.67474422454834, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.6747666358947755, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.6753859193325042, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.67638665959239, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6766718739569186, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6771184220910071, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6773063097000123, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6783748769462108, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.6789251744747162, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.6794592008590699, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6799230308532713, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6800146684646606, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6808940515518187, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.681002618432045, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.6818055973052979, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6823516504764555, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6826151423156261, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.6828778789043426, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6831728920936584, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.683435659408569, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6841323599219322, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.684393870830536, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6850620613098144, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6850718200206756, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6851101908683777, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.68602172421664, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.6861732893288135, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.686312511563301, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6864166741371154, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6869608566761016, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6872478783130647, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.687251471042633, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.688024725317955, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6880490038394929, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6882636785507201, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6882670879364015, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.6883925318717956, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.688455948293209, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.6892227978706358, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6893699929714203, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6893859997987746, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6895153313875197, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6907401442527772, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.6908744305968284, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6909005150794982, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.6910286680459976, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6913443308323621, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6919383273124695, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.692380005121231, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6929311990737914, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6929773002862931, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.69306907636486, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.6930847840309142, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.6939195215702056, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6946387724876402, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6950820374488829, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.6954082061648368, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.6956776916980743, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6965408549308776, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6968272387981416, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.6989871129989624, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.6999855488538742, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7005616680383682, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7012091369628906, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7018252894878387, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7022667751312255, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.7024972498416902, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7028964655399321, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.7030796751976012, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.703391656398773, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7047621414661407, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.7055030322074891, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7063772532939911, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.7068614826202393, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.707135702729225, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7073437405675649, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.7083117232322693, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7088761613368988, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.7091852992773056, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.7093651401996612, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.709385883808136, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.709457209765911, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7100847721099854, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7101020709276198, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.710202185988426, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7104276881217957, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7112806544303893, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.7114568427801131, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7120026067495346, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7122117028236388, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.7125446498394012, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7126088634729384, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7126224145889282, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7130378901958465, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7133623480796814, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.7134972870349885, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7135540217757224, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.7136183590888976, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7139797315597534, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.7141844660043717, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.7154089142680167, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7154318228363992, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7156692714691162, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.7156890586614608, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.716011992841959, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.716227039694786, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.7162760317325592, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.716319939494133, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7163412824869155, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.7176924601793289, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.7177523807287216, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.7179230451583862, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7180974708795547, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.7187690216898919, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7190667424201966, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7209585849046707, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7218889718055723, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.7219003841876983, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.7219190076589583, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.722057311296463, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7223270909786224, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.7224907875061035, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.7230394825935362, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7239278957247735, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7244097873568536, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7245009038448333, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.724538342654705, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7250207290649413, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7252617985457182, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.726160048007965, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.726392878651619, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7269628422260284, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.726977269411087, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.7272652745246888, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.7272713334560392, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7287420654594896, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.7293228939771652, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7298509061336518, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.7302283601760862, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7303747057914733, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7307036638259887, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7314121589660645, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.7319075167179108, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.732295435667038, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.732524910569191, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7325335249900817, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7325358912944793, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.733296032309532, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.7339372055530546, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.7339461714029312, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.7343085520565509, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7349163608551024, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.735089676141739, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.735130075365305, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.735245285987854, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7356451585143806, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.736712232351303, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7377657920718192, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7388700738549232, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.7392203407287596, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.7397438303232193, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.7400204854011534, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.740133303463459, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.7401804089546205, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7402725204825402, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7406356678009032, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7407579469680787, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.741133745074272, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.741139496922493, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.7423833445310593, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.742418247461319, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.7429313764572143, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7430600957870481, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.743184237241745, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.7438256413340572, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.7441899495124815, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7450364515781402, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7452405423521995, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7453706935644149, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.7455829963684082, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7459279820919036, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7463804125785827, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.746958520323038, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7474043521881104, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.7474734053611756, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7479827032089232, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7484186097979546, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.7485512614250183, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.748627375125885, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.749409262895584, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.7504271820783615, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.7511304657906295, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7512264298200606, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7515728995800017, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7518246591091156, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.7520624340772628, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7525388585329054, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.752799540758133, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.7529126749038695, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7535233736038207, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7535314291715622, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7537410244941711, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.7537784278392792, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7538860545158386, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.7539441004991532, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7547780485153197, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.7549011439681053, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7549213156700134, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7550312072634697, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7550443947315215, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7556672514677047, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.756304015636444, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7564259592294693, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.756563608407974, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.7569941639900208, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.7571703345775602, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.7580705286264418, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.7582494781017304, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7583915249109268, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.7586350589990616, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.758692416667938, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7594976902008057, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7595305161476134, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7598211903572083, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7601345896720886, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7628629963696003, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.7640695543289184, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.7644579694271088, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7645261989831922, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7649804100990294, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.7656977506279943, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.7658147633075714, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7658924241065974, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7662122145891188, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7663642048835755, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7667497992515564, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7673211873769759, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7684044466018676, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7684059948921202, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7685283899307251, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.76896444606781, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.768970169186592, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7692087815999984, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.7696022171974182, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.7696832486093044, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7698560345172882, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.7698858681917191, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.770346012711525, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.7704019293785094, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.7722574934959412, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7751446858048439, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7754646204411983, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.7756221570074557, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.775890165567398, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.776221640586853, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.776850337266922, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7772946999073027, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7780107603073119, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.7787774614989758, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7798802748918532, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.780283318012953, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7803962023258209, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7810661047697067, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7815556988716126, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.782600829064846, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7826528208255765, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7828125361204148, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7832651376724242, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7843420405387878, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7843876332044601, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7845523595809936, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7853631228804587, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.7855927095413207, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.7870150417089463, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.7878924131393432, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7878951699733734, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.7881029949188236, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7883336112499237, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.7886042892932892, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.7896199986934662, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7898313686251641, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7901215612888337, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.790847204685211, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.791159351348877, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7913545773029327, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.7923191585242748, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7933157370090484, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.7934130296707154, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7934389099478723, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.794656460046768, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.7948639497756957, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7950314640998841, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7952616260051726, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7956661007404329, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7965043366551399, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7969268172979356, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.7978993713855744, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7979341865181921, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7987716064453125, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.7995828227996824, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.800223227024078, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.8003283069133758, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.8008347842693329, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.8010922849178315, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.803652210712433, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.8036522538661957, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8038252727389334, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8049427360296249, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8052691490650177, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.805625283718109, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8058169708251952, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8060016632080078, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8065179065465926, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8065878168940543, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.807133409500122, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.808211790204048, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8085465685129165, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.809084980249405, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8100489139556886, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8101681218147276, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8103778049945831, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.810582959651947, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.8106041059494018, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8119950459003449, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.813783778309822, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8143767313957215, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.8157711625695228, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.815997906088829, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.8173689424991608, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.817462757229805, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.81791153717041, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.8184639797210693, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8185790256261825, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8189500913619994, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.819294129371643, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.8194591376781464, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8198575407266617, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.8202139214277266, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8205865339040757, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.8208027110099791, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8229052529335021, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.823390348434448, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8235276312828064, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.823876106351614, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.82455791836977, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.8247808680534363, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8248538494706152, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.825089852809906, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.8277069301605224, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8284483242034912, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.8287240147590638, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.82917581653595, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.830068975687027, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.8304269999861718, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8305879549980162, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.8312065215706823, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.831299501657486, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.8326948791742326, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8328437447547912, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.8328442410230636, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8331368060111999, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.8343690142631535, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.8347806572914123, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.835990902841091, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8365147084593771, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.8376560673713684, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.8385679125785828, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.8391573116779327, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.8391670510768894, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.8395919964313507, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.8397361130714416, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.8401006984710695, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8402152673006058, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.8406830847859381, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.840716791629791, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.840829442501068, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.8408745527267456, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8410793514847754, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.8418196067810058, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8419162817299366, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.84203844666481, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.842875154495239, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.8429850846529008, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.8430962954312562, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.8433706612586973, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.843495047211647, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.843511392980814, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.844065702021122, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.8443952932953835, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8446020231246947, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.845271998643875, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.8454021483659744, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.8454953999519348, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.8455752835273742, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8455784142017364, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.8461190090179442, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.8467881398200992, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8474394456148147, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.8474742875099182, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.847792100906372, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.8481660813093186, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.848219861268997, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8482250349521636, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.8490148580074313, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.849183492541313, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8491930175423623, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8500335142612456, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.85025724619627, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.853067138969898, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.8539777965545654, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8547063797712326, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8550118267536164, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8550261214971542, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.8555288121700286, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8559451431632041, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8565638170242313, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8565674231052398, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.856734118670225, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.8571065683364865, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.858044574469328, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8590237263441085, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.860503324985504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.86068446777761, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.8607090876102448, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8613657430410384, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.8617945508956908, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8631911352872847, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.8658373714089393, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.8658835619688035, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.8659023777246475, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.86623490190506, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.866550542473793, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8668766990900039, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8671984914541244, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8677148163318633, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.8682186007499695, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.868643239200115, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.8694670648574827, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8712605714797974, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.8715872623622416, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.8716534779071807, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.8721141860485075, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8730671093463898, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8736142352819443, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8746617496013642, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.8749783651828764, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8759938330650328, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.8770955029726024, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.8771304138600826, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.87760897731781, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8782722890377044, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.8790963859558105, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8791436882019041, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.8794854626655577, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.879826320707798, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.8798391968607902, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8799741716384886, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8801732425689697, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.8804706068038939, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8811773941516876, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8812625662088394, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.8813213901519774, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.8820032284259796, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.8823429703712464, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.8838593558073042, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8841309876441954, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.8841468945741653, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.8843070566654205, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.8844422221183776, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.8844440221786498, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8847623512744902, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.8847812221050262, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8856355652809142, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8856610432863234, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.887393186300993, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8878778967857361, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.8882436275482177, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.888300313234329, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.888327965259552, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.8885407820940017, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.8887332891225814, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8890158014297485, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.8911680475473402, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.8921154890060425, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.8929673448204993, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.8931716807186603, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.893958365917206, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.8963519916534426, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.8964144118726254, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.8971855373382567, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8974021569490431, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8984763860702514, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.8985360376536846, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.8985876992940907, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.898881264090538, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.8993401646614074, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9000274062156677, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.9002471178770066, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.9006402597427368, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9017922565937042, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.9028469221591948, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9032050118446349, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9034287571907043, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.903433437824249, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.903832612991333, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9046104744672774, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.9049101696014403, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9049427704811095, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9051041648387907, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.905371485710144, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9059335265159607, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.905943088293076, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.9061113064289092, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.9063168935477735, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9075096354484558, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.9081677155494687, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.9083795801401138, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.908993689775467, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.9093120262622834, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.90933727478981, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9104237303733824, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.9105084453374146, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.9108876662254333, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9113574192523957, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9117048387527464, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.9124116510152818, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.912631102323532, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.912921197772026, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.913114196062088, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9145212143659591, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.9149996566772465, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9154980707168576, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.915706233739853, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.9159319460392, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.9161082954406736, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.9162866861224175, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.9169115905761713, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.9172073125839233, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9172749161720275, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9180502713322638, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.9190798655748367, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9191463600695133, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9214809358119964, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.9216798859834672, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.922565697193146, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.9250829823911189, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.9250909745693208, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9253533780574799, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.9258907408714294, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.9264496564865112, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.9268941955566405, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.9269641075134278, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.928799307346344, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.9288315148353576, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9289744840860366, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.9300405592918395, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.9311276302337645, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.9314128294438124, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.9322919920682906, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.932523000240326, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9326653764247894, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9328050584197043, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9329437346458433, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9331853270530701, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9334777668714522, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9342745319604873, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.9344578104019168, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9345938473939897, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.9349317388534548, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9350599616765976, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.9356156527996062, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.9356876879930496, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.9366389416754246, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.9367585525512694, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9367867797613143, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.937361756324768, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9376448541879654, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9380147397518157, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.938294498682022, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.9383493721485139, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.938849555015564, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9395577118396758, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9409704045057297, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.94138206410408, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9421065837740898, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.943249243557453, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9443202018737793, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.9444313392639159, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9463834375739097, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.9469791264533995, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9491699311733242, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.950475431293249, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9505077674984932, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.9516332746148108, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.9517008786201473, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9523427203893662, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.9526316092014315, Hidden Layers: [12, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.9538272678852082, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9544293746948243, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.95460830783844, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.955149308651686, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.9566843718886375, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.9572237179279326, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.9573579061031339, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.9577749047279358, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9586571335792542, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.9586886644363404, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9588118568658832, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9596466200351714, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9618056178092957, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.9624540791511536, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9631543610841036, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.9634031847715376, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9653417469859122, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9665032938122748, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.966683383464813, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.9667405233979225, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.9671439752578734, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9674201624393461, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.9675153195858002, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.967553484916687, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.9675712213516239, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.96797962641716, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9688195706009863, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9699249312877654, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.9700331091880798, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.9701451659202576, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9702601716518402, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.9711998686790466, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.9712628083229067, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9718848139643668, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.972036017656326, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.9729253516197205, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.9730912506580354, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9730967149734497, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.9733081885278225, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.9736441643238067, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.9745340392589568, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.974611924648285, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.974722777366638, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9751867965459824, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.975356815934181, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9757091790437697, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.976364533662796, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.9777335555553435, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.9786889151334761, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.9786947399377823, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9798052716255186, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.980649572610855, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.9810063333511352, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9822281531989574, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.9831476390361786, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.984850284576416, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.9856613577008246, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.9875781551599503, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9876585111618041, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.988246449947357, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9884053320884703, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9884292230606078, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9885560826063156, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.9896997374743222, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.990847741127014, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.9910122649744153, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.9914798737764356, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.9917332785129545, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9922024935483933, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.9922114973068237, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.993289938569069, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.9939743446111677, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9941370654851198, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.9951442460194229, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.9955444917678833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.9956910174191003, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.995696872472763, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.995809498786926, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.9960896492004394, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9967879698276518, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.9975146577358245, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.9975791783332824, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.9978902444839477, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.998582165375352, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9990154728889469, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.9995101351886988, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.000362291991711, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0010712698698043, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.001096342563629, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.001984895825386, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.002246473789215, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.0071105022430418, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.007160742580891, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.0084685068130494, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.008544883131981, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.00968359708786, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.010382813215256, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.0128101289868354, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.0134480090141293, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.0149026572704316, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.0171797440052033, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.0172990530729296, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.017429518699646, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.017586702108383, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.018459497451782, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0184739112854, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.0214748620986938, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.0219015538692475, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.023029864132404, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.024794682919979, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.0250530049800872, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.0266250342130663, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.0272196531295776, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.029087449789047, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 2.0290900856256484, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.0298323378562926, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.0303828083574773, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.030778952121735, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.03167760848999, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.0316823422908783, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.033275057435036, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.034463533818722, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.0345093579292297, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.0348528653383253, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.037091014146805, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 2.037584570109844, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0375961080789566, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.039259505271912, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.039418058156967, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.0394655644893644, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.0401914227008815, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.0404397830963137, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.0405101127922536, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.0412771478891374, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.042128403544426, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.0435629086494442, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.044292601466179, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.044441722512245, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.0448270533084867, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.044837409734726, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.044934856891632, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.045678307116032, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.045956328630447, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.0459713847637175, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.046191961497068, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.046544522047043, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.0465540652275083, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.0476628035902977, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.0484800848960876, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.048649752318859, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.0488290712833406, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.048884205579758, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0499174699783325, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0513546155691147, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.0514445700347426, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.0515184462070466, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.0516196534633635, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.051832914352417, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.052158921957016, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.052586218774319, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.052972470283508, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.0531227827072143, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0537389397621153, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.054859972000122, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.055556089863181, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.0556229338645933, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.056040491223335, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.0560965716838835, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.0561459751129147, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.056454388976097, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.0574438900351524, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.0579430595040322, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.0591199562549596, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.0594616458415986, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0610601530075074, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.0620893602371213, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.062719964981079, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.063803866863251, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.064094202280045, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.064622406721115, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.0647753343582154, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.0648088455200195, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.0676073328256606, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.0677975997924802, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.070079334139824, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.070836775749922, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.071325051784515, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.071657341718674, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.0718498230576516, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.0722038940191267, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.073542498111725, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.0747727692127227, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.075014959335327, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.075873627513647, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.076026823043823, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.076865137428045, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.077954441308975, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.078225139141083, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.079453487753868, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.081443870544433, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.0814577147960662, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.085180877149105, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.086098995804787, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.087084526181221, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.0875950515270234, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.088319371700287, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.0894282147884367, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.089542101383209, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.0899966076612477, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.0902798332870005, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.090518339782953, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.0909157947301864, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.0911002466380593, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.0912524461746216, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.0915614099502564, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.0919780955314637, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.0923535064458845, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.0936098918914796, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.094252688169479, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.094554181575775, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.0948588104248045, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.0949272871017457, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.095119853496551, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.0953568518161774, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.0960090861320495, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.098026460766792, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.0980671377182007, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.0984467582702635, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.0999307261705398, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.1032484963536264, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.1037427935600284, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.104536937236786, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.1071963535547256, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.10782697057724, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.1095364689826965, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.1115400433540343, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.111678131103516, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 2.111763690471649, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.113142045021057, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.113944552898407, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1142090814113614, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.1147344068288803, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.11633536529541, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.1165059834718702, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.1179665670394896, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.119750660657883, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1202010929584505, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.1207922563552857, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.121137575864792, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.121818995475769, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.1224231884479523, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.1228313014507294, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.1229770854115486, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.1248700964450835, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.125870610833168, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.126598563969135, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.1285406995415683, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.128646969795227, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.129011590838432, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1299195842742917, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.1305911421775816, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.1311943118572234, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.131393481850624, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1324853856563566, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 2.132686434745789, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.134915567994118, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.1350850269794464, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.135184167385101, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.136883573293686, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.138095583438873, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.1388871163725853, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.139706157207489, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.139981006085873, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.1420151562690735, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.1432448194026947, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.1452305309474466, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1454857543706893, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1468250691890716, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.147635163784027, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1481082649230956, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1484315128326417, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1485152111053467, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1494251461029052, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.1497225151062014, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.149927827835083, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.1511641428470614, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.1519680306911466, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.1524018347263336, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.1525599048137662, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.1530689626932142, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.1531429812908174, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.155236092209816, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.1553255156874656, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.1580598936080935, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.158605764865875, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1591765675544736, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1594497561454773, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.1595361099243164, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.1617755131721497, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.1620195138454434, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1624618068933485, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1629947276115415, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.1656475142240525, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.165790997505188, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.165927071928978, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.1660262048244476, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1661195502281188, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.166303844809532, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.167704227566719, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.1678628311157224, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.169298859000206, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.1694029211997985, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.1708863973617554, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.173025022506714, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.1731034190654754, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1736091212034223, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1742076174020766, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.1752003893852234, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.1782109575271607, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.178882855653763, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.1792540296912195, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.180105555534363, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.180269846320152, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.1819722623825073, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.182156965136528, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.18218843793869, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1823269591331482, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.1839795049279926, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.1845571444034575, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.1845811114311218, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.1849733710289003, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.185506668686867, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1863368556499485, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.1881432042121887, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.1887097672224045, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.190774138331413, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.191343186855316, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.195218495339155, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.1957105457782746, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.1963380932807923, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.1980114564895628, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1985860452651975, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.1995634467005734, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.2004692912101746, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.200614310860634, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.2024274468421936, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.206496705174446, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.207610981225968, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.208293315887451, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.21059903216362, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.211073023080826, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2130393773317336, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.2133362382650374, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.213669481873512, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.2141740725040435, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.2143728256225588, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.214481160402298, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.214598279505968, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.2148191576004024, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.214858201146126, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.2191628173589706, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.2194352984428405, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.2210044251084327, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.222566197872162, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.2233117491602896, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.223574324011803, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.22573318195343, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.2276251718997955, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.2279289216995237, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.230036625444889, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.231529727935791, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.2344828338027, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2347698539495466, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.2354313850402834, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.2370448083877563, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.2391082451343536, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.2394701898097993, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.2412079275250436, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 2.241900208771229, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.2428644169569014, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.244137595653534, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.244569304943085, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.2449592561125753, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.245832419395447, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.247641749739647, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.247841094493866, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.2494699362516406, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.25117247402668, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.2513430134058, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.2534097151756285, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.2537581592798235, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.2544884011745454, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.25994597530365, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.2604554266929626, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.2620479092597963, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.262953279972076, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.2630436973571775, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.2641238676309583, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.26635569190979, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.2689075291752814, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.2698918521404265, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.2713723526000975, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.2724695103168484, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.2730577841997146, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.273069883942604, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.273168870925903, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.273338125705719, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.2782123403549193, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.282795798778534, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.2837203428745267, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.2841161929666995, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.286444008409977, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.2864682302474977, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.2885433718562127, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.2902920633554458, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.2917884871959684, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.2931435994803904, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.293800139427185, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.2940399603843686, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.2949512348175047, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.296251250863075, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.297421401053667, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.298683853626251, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.2987345860004424, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.299301622867584, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3011642665863037, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3015500605106354, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.301778863430023, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.3036632404327393, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.3044723675251007, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.30471311211586, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.3051772520542144, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.306535981655121, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.306690436601639, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.3067020059227943, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.307020859479904, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.3073035821914676, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.308794270515442, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.308952045440674, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.3119770706295966, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.3122993767261506, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.3130649642944334, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.3135028915405274, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.315435642004013, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.317508618593216, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.318241516113281, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.318445955395698, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.319876595020294, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.3199576113224034, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.320818376541138, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.320935190081596, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.321748689174652, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.322174076795578, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.323934182524681, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.324331745624542, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.324379640996456, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.3245733234882353, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.32524663066864, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3259373903274536, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3285417170524596, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.3304125086069107, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.332355314552784, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.3331160232424737, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.3335624427795407, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.3348226294517516, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.3375438511371613, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.3378108143806458, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.3387243807315827, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.3400290690362455, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.340112790584564, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3402976632118224, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.3440734834671018, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.3450471656322476, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3456249669790266, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.348347647666931, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3488015089035033, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3506338567733764, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.3531298249959947, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.354297457695007, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.3566539422273634, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.357594362705946, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.3604211545214056, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.3620734647512434, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.365408286511898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.366042521595955, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.366333425104618, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3685140312314035, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.368716421037912, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.3702467844486237, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.3705247566699983, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.3762458102703095, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.376542870759964, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.3772923887372017, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.3782636300325395, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.378778412938118, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.380768096446991, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.3813441932201385, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.381423051834106, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.382840000152588, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3828917310237885, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.3830521211624145, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3857659147977825, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.3862526239752766, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.3873779133558273, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.388888675034046, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3893957302570343, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.3901876912117004, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.391151246547699, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.3912450571060178, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.392253859400749, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.3941409215927125, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.394390641212463, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3962662475109098, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3969700083732604, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.3994904100894927, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.4003283083438873, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.401200239419937, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.406046192407608, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.407614386886358, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.409356162071228, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.4102375656962396, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.410561458826065, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.412057755947113, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.412959004998207, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.413552816271782, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.4162468538284303, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.418061542510986, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.4186100766658782, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.419553357362747, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.419939374923706, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.422223424911499, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.4239822015166284, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.4240941166877747, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.42441800570488, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.4251906888484953, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.4258752822875977, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.4259236590862274, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.4303963069915766, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.431993655920029, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.4333626568317412, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.43413844871521, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.435729643821716, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.4371638536453246, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.4392266809940337, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.440468829870224, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.440752312541008, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.4438222095966338, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.4441592321395875, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.4442741751670836, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.4499911413192748, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.4518509761095046, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.452475400328636, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.45379753112793, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.4568203092217447, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.45941830432415, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.45956379032135, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.4596230570077897, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.4635427419692277, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.466722925066948, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.4671855211257934, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.4684245321750637, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.469028131723404, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4697919116020204, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.4746531563997265, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.478027348279953, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.480398269057274, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.481179675579071, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.4841539398431776, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.486843165874481, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.488544668316841, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4890575573444367, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.4900323659181596, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.4916726559996603, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.4917479679584504, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.4919800058603285, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4921403542757035, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.4950780510902404, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.4977822482585905, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.5014610085487368, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.501889357402921, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.5022410616874695, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.507000987291336, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.507335530281067, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.5079334393143653, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.5139967918396, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.514095245361328, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.514732132911682, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.5148113071918488, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.5182691488265987, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.519612734079361, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.5208762288093567, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.522928927898407, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.5233595477342603, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.5242081701755525, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.524999520540237, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.5297669336795807, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.530125877261162, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.530291934490204, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.5331138105392457, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.534331890940666, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.5354546504020687, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.535784955382347, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.537845239162445, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.5379346877336504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.539952166557312, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.5402603857815267, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.5430226802825926, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.5436976120471955, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5454398469924926, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.54894557762146, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.5506374225616453, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.5510831434726713, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.552740550041199, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.55356089925766, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.558982105731964, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.5631247535943986, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.564605771064758, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.5654521927833556, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.56702621281147, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.570459740161896, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.571935909986496, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.575710658788681, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.5760038599967956, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.5764323205947877, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.5768654661178587, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.578273500561714, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.5823566184043885, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.5826634615659714, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.583166411876678, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.5857137188911437, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.587136280536652, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.588696889638901, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.5891943722963333, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.590064583778381, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5954928741455077, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.59977793264389, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.601329207420349, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.601901505947113, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.602644822359085, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.602812612056732, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.6034919366836546, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.6128387019634247, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.6147365542054173, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6165882892906667, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.6208210263252254, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.622867947816849, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.625325876161456, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.6267674342393876, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.628404844239354, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.628985068321228, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.629312935590744, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.630978247523308, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.631418771961704, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.6352659787982704, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.6395965013504026, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6398198561668393, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.6448491752147674, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.6455543756484987, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.6561413288116453, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6586707339286804, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.664280910849571, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.6680451110601426, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.6702974177226424, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.673434201240539, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.6738338813781737, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.674652694225311, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.6855965719223023, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.688511425256729, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.6912023767828943, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.6957205638885497, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.697273391544819, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.6993220925331114, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.701877100944519, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.7109540820121767, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.7139180302619934, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.7152185292243955, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.718012340426445, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.7194894165992736, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.722136028289795, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.723188541889191, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.7236596064567564, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.724814936637878, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.7256677001714706, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.7327556461691858, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.735076573848725, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.73578289604187, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.735939732193947, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.7379768388271333, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.739984595775604, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.7456139981746674, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.749227763772011, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.7533131853342057, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.753536377906799, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.757665436029434, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.761810897350311, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.764680408000946, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.7654168754816055, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.7685442180633544, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.7712779359817503, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.7717042059898374, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.774302265167236, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.7790858850479125, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.7879556894302366, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.788458643913269, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.7929939703941344, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.801421770572662, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.8018717379570006, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.811801800251007, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.8146447391510008, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.8260716676712034, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.8286366925239563, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.8297799842357634, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.8320538507699964, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.833197115421295, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.833484319031238, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.854437692642212, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.8599672094583513, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.8600312576293945, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.862335965156555, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.8649203734397886, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.874296113848686, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.87527836894989, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.8773375306129454, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.8819887237548825, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.8844206199645996, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.888055741786957, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.889387345314026, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.8924584493637084, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.8952078745365144, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.89608642911911, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.8963429272174834, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.896396240711212, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.8971294522285462, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.897729878127575, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.903628206253052, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.908469091415405, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.9176550731658937, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.9264913529753684, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.9270001504421237, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.929804211854935, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.9365611748695373, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.9565970771610735, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.9728186190128327, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.984579122066498, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.987040515422821, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 3.0039432943463327, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 3.0065708861351013, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 3.009886054754257, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 3.013174387931824, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 3.018104356586933, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 3.0183619604110716, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 3.018407331466675, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 3.0264869556427003, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 3.035234998345375, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 3.0364126608371733, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 3.046756519436836, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 3.049882178068161, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 3.050548718929291, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 3.054473400115967, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 3.071227213859558, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 3.0728003606796266, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 1
MAE: 3.0774910867214205, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 3.090915502667427, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 3.1046783730983734, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 1
MAE: 3.105064995646477, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 3.107300700426102, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 3.1190274552106856, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 3.1285714404582974, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 3.1315883890390395, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 3.1362825334072113, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 3.1394094079732895, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 5
MAE: 3.1473915711641314, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 3.1639172986745834, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 3.1818889126777647, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.1884463267326355, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.19628550863266, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.2311410784721373, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 3.240051233768463, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.2574724512100217, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 1
MAE: 3.2770698934793474, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 3.2774167344570158, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 4
MAE: 3.3179026857614518, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 3.358060486793518, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 3.3582792000770567, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 3.3849009737968445, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 3.431247495174408, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 3.4833023028373717, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 3.517246386528015, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 3.621103637099266, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 3.6276449546813962, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 3.66705295753479, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 3.8687748544514178, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 4.237235291481018, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
Results saved successfully in dir `results/test2/NN_results_4000_lessData.pkl.pkl`.
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4001/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4002/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4003/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4004/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4005/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4006/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4007/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 4008/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4009/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4010/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4011/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4012/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4013/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4014/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4015/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4016/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4017/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4018/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4019/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4020/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4021/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4022/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4023/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4024/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4025/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4026/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4027/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4028/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4029/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4030/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4031/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4032/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4033/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4034/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4035/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4036/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4037/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4038/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4039/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4040/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4041/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4042/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4043/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4044/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4045/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4046/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4047/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 4048/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4049/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4050/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4051/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 118ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 118ms/step
Now training the model 4052/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4053/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4054/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4055/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4056/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4057/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4058/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4059/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4060/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4061/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4062/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4063/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4064/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4065/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4066/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4067/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4068/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4069/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4070/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4071/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4072/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4073/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4074/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4075/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4076/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4077/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4078/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4079/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4080/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4081/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4082/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4083/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4084/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4085/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4086/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4087/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4088/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4089/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4090/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4091/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4092/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4093/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4094/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4095/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4096/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4097/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4098/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4099/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4100/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4101/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4102/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4103/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4104/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4105/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4106/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4107/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4108/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4109/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4110/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4111/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4112/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4113/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4114/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4115/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4116/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4117/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4118/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4119/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4120/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4121/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4122/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4123/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 4124/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 4125/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4126/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4127/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4128/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4129/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Now training the model 4130/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4131/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4132/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4133/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4134/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4135/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4136/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4137/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4138/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 596ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 596ms/step
Now training the model 4139/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4140/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4141/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4142/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4143/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4144/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4145/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4146/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4147/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4148/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4149/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4150/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4151/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4152/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4153/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4154/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4155/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4156/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4157/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4158/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4159/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4160/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4161/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4162/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4163/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4164/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4165/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4166/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4167/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4168/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4169/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4170/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4171/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4172/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4173/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4174/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4175/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4176/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4177/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4178/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4179/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4180/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4181/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4182/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4183/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4184/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4185/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4186/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4187/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4188/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4189/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4190/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4191/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4192/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4193/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4194/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4195/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4196/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4197/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4198/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4199/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4200/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4201/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4202/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4203/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4204/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4205/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4206/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4207/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4208/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4209/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4210/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4211/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4212/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4213/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4214/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4215/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4216/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4217/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4218/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4219/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4220/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4221/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4222/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4223/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4224/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4225/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4226/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4227/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4228/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4229/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4230/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4231/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4232/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4233/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4234/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4235/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4236/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4237/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4238/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4239/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4240/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4241/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4242/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4243/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4244/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4245/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4246/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 4247/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4248/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4249/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4250/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4251/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4252/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4253/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4254/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4255/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4256/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4257/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4258/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4259/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 4260/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4261/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4262/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4263/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4264/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4265/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4266/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4267/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4268/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4269/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4270/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4271/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4272/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4273/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4274/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4275/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4276/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4277/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4278/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4279/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4280/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4281/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4282/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4283/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4284/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4285/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4286/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4287/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4288/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4289/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4290/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4291/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4292/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4293/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4294/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4295/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4296/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4297/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4298/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4299/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4300/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4301/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4302/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4303/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4304/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4305/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4306/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4307/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4308/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4309/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4310/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4311/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4312/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4313/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4314/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4315/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4316/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4317/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4318/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4319/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4320/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4321/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4322/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4323/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4324/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4325/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4326/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4327/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4328/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4329/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4330/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4331/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4332/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4333/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4334/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4335/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4336/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4337/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4338/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4339/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4340/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4341/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4342/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4343/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4344/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4345/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4346/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4347/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4348/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4349/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4350/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4351/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4352/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4353/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4354/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4355/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4356/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4357/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4358/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4359/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4360/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4361/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4362/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4363/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4364/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4365/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4366/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4367/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4368/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4369/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4370/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4371/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4372/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4373/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4374/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4375/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4376/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4377/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4378/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4379/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4380/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4381/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4382/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4383/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4384/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4385/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4386/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4387/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4388/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4389/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4390/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4391/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4392/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4393/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4394/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4395/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4396/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 4397/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 4398/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4399/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4400/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4401/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4402/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4403/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4404/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4405/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4406/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4407/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 4408/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4409/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4410/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4411/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4412/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 4413/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4414/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4415/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4416/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4417/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4418/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4419/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4420/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4421/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4422/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4423/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4424/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4425/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4426/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4427/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4428/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step
Now training the model 4429/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4430/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4431/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4432/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4433/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4434/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4435/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4436/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4437/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4438/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4439/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4440/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4441/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4442/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4443/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4444/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4445/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4446/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4447/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4448/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4449/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4450/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4451/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4452/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4453/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4454/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4455/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4456/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4457/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4458/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4459/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4460/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4461/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4462/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4463/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4464/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4465/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4466/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4467/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4468/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4469/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4470/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4471/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4472/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4473/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4474/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4475/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4476/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4477/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4478/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 4479/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4480/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4481/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4482/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4483/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4484/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4485/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4486/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4487/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4488/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4489/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4490/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4491/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4492/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4493/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4494/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4495/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4496/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4497/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4498/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4499/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4500/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4501/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4502/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4503/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4504/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4505/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4506/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4507/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4508/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4509/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4510/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4511/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4512/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4513/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4514/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4515/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4516/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4517/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4518/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4519/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4520/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4521/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4522/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4523/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4524/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4525/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4526/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4527/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4528/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4529/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4530/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4531/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4532/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4533/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4534/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4535/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4536/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4537/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4538/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4539/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4540/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 4541/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4542/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4543/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4544/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4545/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4546/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4547/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4548/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4549/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4550/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4551/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4552/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4553/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 78ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 78ms/step
Now training the model 4554/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step
Now training the model 4555/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 83ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 83ms/step
Now training the model 4556/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 83ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 83ms/step
Now training the model 4557/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 89ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 89ms/step
Now training the model 4558/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step
Now training the model 4559/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step
Now training the model 4560/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step
Now training the model 4561/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step
Now training the model 4562/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4563/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 4564/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4565/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4566/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4567/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step
Now training the model 4568/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 4569/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4570/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 4571/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 4572/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4573/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4574/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4575/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step
Now training the model 4576/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4577/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4578/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4579/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step
Now training the model 4580/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4581/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4582/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4583/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 4584/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4585/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4586/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4587/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4588/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4589/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4590/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4591/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4592/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4593/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 4594/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4595/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step
Now training the model 4596/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 4597/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 165ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 165ms/step
Now training the model 4598/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4599/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 4600/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4601/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4602/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4603/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 4604/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4605/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4606/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4607/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 67ms/step
Now training the model 4608/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4609/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4610/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4611/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4612/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4613/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4614/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4615/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4616/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4617/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4618/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4619/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 4620/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4621/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4622/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4623/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4624/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4625/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4626/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4627/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4628/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4629/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4630/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4631/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4632/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4633/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4634/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4635/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4636/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4637/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4638/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4639/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4640/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4641/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4642/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 97ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 97ms/step
Now training the model 4643/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4644/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4645/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4646/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4647/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 4648/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4649/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4650/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4651/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4652/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4653/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4654/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4655/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4656/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4657/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4658/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4659/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4660/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4661/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4662/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4663/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4664/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4665/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4666/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4667/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 4668/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4669/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4670/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4671/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4672/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4673/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4674/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4675/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4676/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4677/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4678/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4679/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 4680/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4681/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4682/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4683/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4684/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4685/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4686/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4687/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4688/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4689/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4690/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4691/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4692/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4693/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4694/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4695/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 4696/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4697/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4698/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4699/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4700/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4701/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4702/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4703/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4704/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4705/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4706/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4707/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4708/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4709/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4710/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4711/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4712/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4713/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4714/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4715/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4716/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4717/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4718/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4719/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4720/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4721/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4722/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4723/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4724/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4725/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4726/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4727/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 4728/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4729/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4730/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4731/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4732/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4733/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4734/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4735/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4736/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4737/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4738/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4739/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 4740/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 91ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 91ms/step
Now training the model 4741/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4742/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4743/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4744/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4745/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4746/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4747/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4748/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4749/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4750/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4751/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4752/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4753/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4754/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4755/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4756/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4757/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4758/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4759/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4760/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4761/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4762/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4763/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4764/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4765/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4766/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4767/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4768/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 4769/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4770/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4771/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4772/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4773/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4774/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4775/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4776/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4777/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4778/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4779/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4780/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4781/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4782/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4783/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4784/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4785/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4786/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4787/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4788/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4789/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4790/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4791/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4792/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4793/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4794/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4795/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4796/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4797/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4798/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4799/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4800/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4801/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4802/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4803/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4804/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4805/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4806/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4807/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4808/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4809/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4810/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4811/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4812/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4813/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4814/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4815/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4816/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4817/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4818/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4819/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4820/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4821/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4822/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4823/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4824/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4825/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4826/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4827/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4828/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4829/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4830/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4831/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4832/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4833/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4834/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4835/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4836/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4837/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4838/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4839/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4840/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4841/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4842/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4843/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4844/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4845/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4846/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4847/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4848/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4849/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4850/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4851/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4852/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4853/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4854/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4855/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4856/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4857/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4858/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4859/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4860/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4861/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4862/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4863/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4864/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4865/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4866/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4867/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4868/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4869/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4870/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4871/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4872/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4873/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4874/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4875/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 4876/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4877/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4878/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4879/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4880/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4881/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 4882/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4883/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4884/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4885/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4886/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4887/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4888/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4889/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4890/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4891/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4892/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4893/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4894/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4895/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4896/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4897/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4898/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4899/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4900/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4901/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 4902/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4903/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4904/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4905/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4906/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4907/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4908/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 4909/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 4910/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4911/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 4912/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4913/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4914/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4915/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4916/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4917/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4918/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4919/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4920/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 717ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 717ms/step
Now training the model 4921/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4922/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 4923/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4924/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4925/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4926/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4927/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4928/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4929/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 4930/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 4931/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4932/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 4933/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4934/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4935/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 4936/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4937/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 4938/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4939/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 4940/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4941/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4942/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4943/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 4944/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4945/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4946/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4947/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4948/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4949/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4950/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4951/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4952/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4953/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4954/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4955/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4956/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4957/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4958/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4959/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4960/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4961/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4962/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4963/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 4964/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4965/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 4966/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4967/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4968/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4969/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4970/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4971/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4972/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4973/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4974/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4975/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4976/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4977/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4978/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4979/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4980/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4981/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4982/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4983/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 4984/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4985/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 4986/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 4987/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 4988/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4989/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4990/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4991/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4992/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4993/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 4994/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 4995/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 4996/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 4997/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 4998/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 4999/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5000/5600
MAE: 0.38881727933883664, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.4487369272708893, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.44923205232620245, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.4543892282247543, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.46465788340568537, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.4790906581878661, Hidden Layers: [14, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.5049285150766372, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.5055112452507019, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.5063707337379456, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.5160409662723541, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.5361168746948242, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.5501246765851975, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.5529182021617889, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.5551680672168732, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.5552848892211915, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.5708359527587891, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.5762537271976471, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.5819763049483299, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.582234782576561, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.5827870640754699, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.5863663447201252, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.5872042841911317, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.5898485127687454, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.5913026275038719, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.5919127702713012, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.5971074137687682, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.598156087398529, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.6009200127124786, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.6039543664455412, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.6043278205394744, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.6051378774642944, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.6111841950416564, Hidden Layers: [14, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.6126239690780639, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.613431718379259, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.6209640562534331, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.6221203017234802, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6238624141216278, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.626114649295807, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.6290297050476075, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.6300478296279907, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.6324208295345305, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.6327485294342041, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.6345163732767104, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.6421627748608588, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.6444715872406959, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6476881194114685, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 0.6484179026484489, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.6489730063676833, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.6505117759704591, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.6589588187932969, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.6656275681257248, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.6665548310279845, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.6699212644100189, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.6699385811686516, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.6731036055088043, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.6741763727664947, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.6742677688598632, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.6774953011274337, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.6791027084589003, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.6792059335708618, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.6795307169854641, Hidden Layers: [16, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 0.6847699747085569, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.6891725853681565, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.6892478972673415, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.6897916786670686, Hidden Layers: [16, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.6900004003047943, Hidden Layers: [14, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.6904150829315185, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.6905417340993881, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.6928469658493994, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.6934066742658614, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.6941176578998566, Hidden Layers: [16, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.6971244856715202, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.6977494410276412, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.6979007499217986, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.700491947054863, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.7010343301296234, Hidden Layers: [14, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7016707215309143, Hidden Layers: [14, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.7017572925090788, Hidden Layers: [12, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.7019101973474025, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.7047316002845764, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.7050580998063087, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7075721465349198, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.7077806682586669, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.708240001320839, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.7091290179491042, Hidden Layers: [12, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.7093756214380262, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7095131015777587, Hidden Layers: [14, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.7105564594268798, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.7110386881828308, Hidden Layers: [14, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.715821725487709, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.717508258342743, Hidden Layers: [12, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7184530720710754, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.719034685254097, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7210422322154044, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.7225016031265258, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.7270399197936057, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7275242509320378, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7278420375585555, Hidden Layers: [14, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.7285632119178772, Hidden Layers: [14, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.7302863355576992, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.7314684736728668, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.7341725208461283, Hidden Layers: [16, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7349561529159545, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.7350464780330659, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.7355337245389818, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.735611266374588, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.737280950307846, Hidden Layers: [14, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7379527900218963, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.7398571476936341, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7406543646007775, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.7407054695487022, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.7440746413469316, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7440862134695052, Hidden Layers: [14, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.7447226304411887, Hidden Layers: [14, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.7449507315158844, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.7457273457050323, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.7462758633494377, Hidden Layers: [14, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.7472233951091766, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.748293634802103, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.7484889912605286, Hidden Layers: [12, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.7499705779552459, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.7513210134506225, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.751535209327936, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.7521494121551513, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.7522475079298018, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.7524505364894867, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.7537141907215118, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7539760146141051, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.7540670692920683, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.756956045627594, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.7572228129208087, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.7584530577659607, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.7605609837770462, Hidden Layers: [14, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7612696056365966, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.7616818272173405, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.7638712931275367, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 3
MAE: 0.7640164750814438, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.7642340128421783, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.766611597418785, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.7674060136079788, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.7679757560789585, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.7696955114603041, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.7707334638237952, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.7721868157386779, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.7736304850578308, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.7745808262825012, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.7747560548782348, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7749056569933892, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.7754869047403334, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.7768042478561401, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7780994164943695, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.7789265978336334, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.77917187666893, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.780275191783905, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.7804029048681259, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.781268697977066, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7818216059207915, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.7825557769536972, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.7839247748851774, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.7843046984672546, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.7852131143212318, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.7864446636140345, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.7908179432749747, Hidden Layers: [14, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.7908255714774131, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.7916259945631027, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.7922014999389648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7931078165769576, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.7931723882555961, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.7938894394636153, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.7940007553100584, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.7957228590250016, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.7963610444068908, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.7966920361518859, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.7968507007360457, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.7979138526916503, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.7979372117519378, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.7989478409290313, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.799071231842041, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.7993579388260842, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.7995453178882598, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8007047452032566, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8015161591768265, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.8020954713821411, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.8024944529533388, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.8029407175183294, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8031515436172484, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.8040326495170593, Hidden Layers: [14, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8059429008960723, Hidden Layers: [16, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.8065524086952209, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8072048187851906, Hidden Layers: [14, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.8072243332862854, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8078937977552414, Hidden Layers: [14, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8083462480306626, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8088162930011749, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.8100414131879805, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.8103890091776847, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.8123950332403183, Hidden Layers: [14, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.8145017178058623, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.8151992249488831, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.8156524032354355, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.815883231639862, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8159161418676376, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.8160206097364426, Hidden Layers: [14, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8162349867820741, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.81647955930233, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.818424189388752, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.8191137883663178, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8203614697456361, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.8207148022651672, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8209879121780397, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.8217294384241104, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.821796715259552, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8225435081720353, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8225992131233216, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8226669018268584, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 0.8228256285190583, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8239878654479981, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.8252090245485306, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8264583021402359, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.8272567216157913, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8284354555606843, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8286043152809143, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8286486375927925, Hidden Layers: [16, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.829092726111412, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.8291576728820802, Hidden Layers: [12, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.8294511542320251, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8298073694705963, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8309720594286919, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8311921567916869, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.8318441540598869, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8319679604768752, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8342636034488677, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.8355040255784989, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.8355076717063785, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.8355214231312275, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8355222228765488, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8389996933937074, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8403890595436095, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.8407961115837097, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.8429517626762391, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8432644817829132, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.8432858943939209, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8441968295574188, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.844295244693756, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.845367192029953, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.8469060148894787, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8477217183113097, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.847765215218067, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8482646036148072, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.848490445792675, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.8486416981220245, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8504347673654558, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.8504518065452575, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.8514600131511688, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.8521032073199748, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8521206232905388, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8527810308933258, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.8533767135273663, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.8534022096395493, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.853467783331871, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8545520440340042, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.8548299183249473, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8555025265216827, Hidden Layers: [12, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.8560123697519302, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.856945918560028, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.8570716993808745, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8571296677589416, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.8572267919778824, Hidden Layers: [14, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.8580345873832702, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.8585323095321655, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.8589471125900744, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.859129385650158, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.8597166538238525, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.8608447760343552, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.8612274858951569, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.8615726459026337, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.8634447321891784, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8634465173482895, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8655187129974365, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.8659105095863342, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.8665681175142528, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8666381299495697, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.8667168498039246, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8672518496513366, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8673605442047119, Hidden Layers: [14, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 0.8674605057239532, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.8674960232377054, Hidden Layers: [12, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.8690516250133513, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.8696977753043175, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 0.8698150214403867, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.8700460231527686, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.870321896791458, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8706802502870559, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.87081907248497, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8709582850337029, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.8710382789969444, Hidden Layers: [12, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.8714911210536957, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8715643212795259, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.8722456481158734, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.8723084300756454, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.8723343048095703, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8725837528705597, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.8731963131427765, Hidden Layers: [14, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.8734194145202636, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 0.8757573038339614, Hidden Layers: [14, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8761679697632789, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.877230018734932, Hidden Layers: [14, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8774999879300595, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.877728431224823, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.8778105453252791, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.8789030776023864, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.8791858391761778, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.8792613269090651, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.8797536432743073, Hidden Layers: [14, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 0.879950918674469, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 0.8800075232982636, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.8801492279767992, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8804440290927886, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.8805919528007508, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.8806484047174454, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.8815809428691864, Hidden Layers: [14, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.881877100944519, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.8819353879094123, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.8827753797769546, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8834430396556854, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.8839577035903929, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.8848200368881226, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.8850332945585251, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8851434960216285, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8854329439997674, Hidden Layers: [14, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.8856113777160644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8859320417642593, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.8870764970779419, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.8878205001354218, Hidden Layers: [14, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8894733388423919, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.889531497657299, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.8897380667924881, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.8902682371139526, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.8907692958116531, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 0.891055073261261, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.8911098589003086, Hidden Layers: [14, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8913829044103622, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.8922944918870925, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.8924088195562362, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.8927029927372931, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.8927859381437301, Hidden Layers: [12, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.892808051019907, Hidden Layers: [16, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.8934642613530158, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.8936026234626769, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8940398306846618, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8942403547465801, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.8943172857165337, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.8949114339351653, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.895813842177391, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.8967934507131577, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.896855402112007, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.8969866514205933, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.8971059186384082, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.8971753761768341, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.8974049810171127, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.8976442650556564, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.8977669294774533, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.8977671282291411, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.8979695290327072, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.898093959748745, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.8988546520471573, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.8989679548740387, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.8993723618984223, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.8997835044860839, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.8998730063438416, Hidden Layers: [14, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.8999445319175721, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 0.8999978379011153, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 0.9003936320543289, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.901022376537323, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 0.9011436626911162, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.9011730879545212, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9013283795118333, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.9017507553100585, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9048452064394951, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9051538542509079, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 0.9053405702114106, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9063540596961974, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9066628800630567, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.9067276630401612, Hidden Layers: [14, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.9076109924018383, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9081665650606154, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.908467345237732, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9094477133750913, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9098775107264518, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.90991151034832, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.91033353215456, Hidden Layers: [16, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.9106894004344941, Hidden Layers: [16, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.9107101503610611, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9114870772361755, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.9117252755165101, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.9119437809884549, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9120943892002107, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9124425038695335, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.912783475279808, Hidden Layers: [14, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9139630962610245, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9140006561279297, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.9151637361049652, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9154018893092871, Hidden Layers: [12, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9161894142627716, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 0.9165384531021118, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9173578476905824, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.9177226185798645, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9182149291038513, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.9189472422599791, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 0.9200851634740829, Hidden Layers: [14, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9202301412820816, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9206541166305542, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9214926093816758, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9224572677612304, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9225891790390015, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 0.922929659485817, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9230821883678437, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9246643335223197, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.9247426838278769, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9255966365337371, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9257613406181335, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9263497859239578, Hidden Layers: [14, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 0.9269252450466154, Hidden Layers: [14, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.9270305775701999, Hidden Layers: [14, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.9272874615192415, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9287366108894346, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9294137642383575, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9301387057304382, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9307725846767425, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.9312215671539306, Hidden Layers: [14, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.9314004063606263, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 0.9314926658868788, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9315259994268417, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9315887600183487, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9320501998066902, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.932070283770561, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9322068907618523, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.9323363888263703, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9325052313804626, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 0.932658042192459, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 3
MAE: 0.9331058443188667, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9333056688308716, Hidden Layers: [14, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 0.9334531636238097, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9339234875440596, Hidden Layers: [14, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.9340429635047911, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.934073592722416, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9344231162071228, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9347929048538208, Hidden Layers: [14, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 0.9351080030202865, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9352625713348388, Hidden Layers: [16, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.9355951078236103, Hidden Layers: [14, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.9377435848712921, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9385574072599411, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9393687658309936, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9394437425136566, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.9394940141439438, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9399453848600388, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.9400283012390137, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.9405326634645462, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 0.9407871012687682, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9409988552331925, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 0.9410286727547647, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 0.941210518836975, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9414334982633591, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.941758621096611, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9419584976434706, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 0.9421860694885253, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.9424801561236382, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.9429124925136566, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9439926207065582, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9444434449672698, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.944455280214548, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 0.9445515528917312, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9446372156143188, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9448823750019073, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.94577573543787, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9459739581346511, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.9464023113250732, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 0.9466219992041587, Hidden Layers: [14, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.9474287229776384, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9474303965568541, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9483466252684594, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9486241743564605, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.948669816851616, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9486806139945984, Hidden Layers: [14, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.9488877713680267, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9490073682069777, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9495644915103914, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.9500214550495147, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.95034086561203, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9505527883768081, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.9505964908599853, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 0.9511664390563965, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.951452179312706, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9526271269321441, Hidden Layers: [16, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.9526399612426758, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.952675031542778, Hidden Layers: [14, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9529300481081009, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9532027289867401, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9541055386066436, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 0.954253763437271, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9544366257190703, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9547281429767608, Hidden Layers: [12, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 0.955125859439373, Hidden Layers: [14, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.9557466673851014, Hidden Layers: [14, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9566665158271789, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9568023651838302, Hidden Layers: [14, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.9585039422512054, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.9585937094688415, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 0.9594492273330687, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 2
MAE: 0.9598619651049376, Hidden Layers: [12, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.960048359632492, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 0.9602059770822524, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 0.9604682222604751, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9607293233275414, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9607772753238677, Hidden Layers: [12, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9615729413032532, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9617911726832389, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.962413466334343, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.962788513302803, Hidden Layers: [16, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9628803060054778, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 0.9629912989139555, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 0.9631277294158934, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9631651699542999, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 0.9638951826095582, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9641792745590209, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 0.9645057778656483, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9649411082267761, Hidden Layers: [14, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 0.9650960729122161, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 0.9651005196571351, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 0.9655772018432618, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.9661470293998718, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.968866099834442, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9688926019370555, Hidden Layers: [14, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 0.9690815970897674, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 0.9691173986196517, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.9691726677119732, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9695619601607323, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 0.9701418697834014, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.9706450001001358, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 0.9713159010410308, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9715924636125564, Hidden Layers: [16, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 0.9718342811465263, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 0.9724863637089729, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 0.9735166597366334, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9742006033658981, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 0.9744121850132942, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.974890673160553, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 0.9752628564834595, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.9754368052482605, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9755847886800766, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 0.975655225276947, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9756732270121574, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 0.9757738307714462, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9763225027024746, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 0.9764381438493729, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.976982370376587, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9771708877086638, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9772304015159605, Hidden Layers: [12, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 0.9772419661283493, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.9773049818277357, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 2
MAE: 0.9779151473045349, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.9780210748314857, Hidden Layers: [14, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.9781887322664261, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.9783452514410019, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 0.9783877407312392, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9786642180681226, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.9787543371915817, Hidden Layers: [16, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 0.9793386385440825, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9794594392776489, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 0.979972098827362, Hidden Layers: [14, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 0.9804015383720397, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 0.9804305956363677, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 0.9808615539073944, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9811681048870085, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9815390795469284, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 0.9816179441213606, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 0.9821611956357955, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9827964425086975, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 0.9828528628349303, Hidden Layers: [14, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 0.9839325070977211, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9839687094688415, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 0.9839725434780121, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 0.9843457684516906, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9844231263399124, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 0.9848730582594871, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9849210683107377, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 0.9855397597551345, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 0.9858655545711518, Hidden Layers: [14, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 0.9858936250209809, Hidden Layers: [14, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 0.9860930428504944, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 0.9862384550869464, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9868780481815339, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9869161476045847, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9872064027786255, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 0.9872597247362137, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9872908093035221, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 0.9876141175627708, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9880595417022704, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 0.9880970857702195, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9881328821182251, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 0.9883729547262192, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 0.9884670023918151, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9887511775493621, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.9892827498912812, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 0.9895137530416249, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.9897131416611373, Hidden Layers: [14, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.9899633886218069, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 0.989976371884346, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 0.9904485988616945, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 0.9915076837539673, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 0.9915909414291381, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 0.9922517509460448, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 0.9925126001834869, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 0.9926679924726486, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 0.9927197054624557, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9934003980159758, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 0.9937065947651863, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9938551109284163, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 0.9938970268368721, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 0.9942321807146073, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9943213522434234, Hidden Layers: [16, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 0.9944535799175501, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 0.9949962954819203, Hidden Layers: [12, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 0.995793079212308, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 0.9961138949990271, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 0.9964211065769195, Hidden Layers: [14, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 0.9965618357658386, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 0.9970248789787292, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 0.9970300909727812, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 0.9974022626876831, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 0.9976693794727325, Hidden Layers: [12, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9977747678756714, Hidden Layers: [14, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 0.9977785244584083, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 0.9980305448770522, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 0.9981548563241958, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 0.998576426565647, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 0.998724822998047, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 0.9989156053066253, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 0.9992621257901192, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 0.9996528358459471, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 0.9997924596071244, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0000552892684937, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.000851561307907, Hidden Layers: [14, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0009792387485503, Hidden Layers: [16, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0011428579688073, Hidden Layers: [14, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0012471899986266, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.0012910754084587, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0022631227970122, Hidden Layers: [14, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0025267407894134, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0027410731315611, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.0028833688497543, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.0029092492461202, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0032648146152496, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0033881404101848, Hidden Layers: [12, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.0035855770111084, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.004199422955513, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.0048412487506866, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.00510250043869, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0058906111717225, Hidden Layers: [14, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0067093908786773, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.0070194438695907, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.007028979063034, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.00729053068161, Hidden Layers: [14, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.0073151216506957, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.007539366930723, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.008902898490429, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.009161776304245, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0093028274029492, Hidden Layers: [14, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0096306488513946, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0097092896699906, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.0098917398452758, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.010254628121853, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.0104820356369018, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0113800749778747, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.0118906665444374, Hidden Layers: [4, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0119259271621703, Hidden Layers: [16, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.012331308722496, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0124546246528623, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.0126621712595223, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0127870547771454, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0133326277732848, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0133902642726897, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0134389386177063, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.014070186138153, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.0141622633337974, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.014507696032524, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0146638751029968, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.0149805967807768, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0150784537792206, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0153566585779188, Hidden Layers: [14, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0158367025852204, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.0161958366632462, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.01643154501915, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.0165661410093307, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.0172656841278076, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.017580284178257, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0183678138256074, Hidden Layers: [14, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.018463968038559, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0193104926347734, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0202080655694008, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.020610624551773, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.0206860706806182, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.020788191318512, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.0208191859722138, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.021362805366516, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0218432891368867, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0225487271249292, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.0226155371665953, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.022706387937069, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.022925196647644, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.023616600394249, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.0243376955986023, Hidden Layers: [14, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.024474447131157, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.024759867787361, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0252013593912124, Hidden Layers: [14, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0253974080085755, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.0254649446010589, Hidden Layers: [8, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0258346294164657, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.025874263048172, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0262264508605003, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0264765083789826, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0265686976909638, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.0265974358320236, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0266997136175633, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0268100470304489, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0276158125400543, Hidden Layers: [12, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.0276894793510436, Hidden Layers: [14, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.0278421477079391, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0278435961008072, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0278841004371642, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0282114908695221, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0289222631454469, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0289236233234405, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.0293615698814391, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0293689177036285, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.0297028038501739, Hidden Layers: [14, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.0297445998191832, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.029970814704895, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.0299731075763703, Hidden Layers: [14, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.0310723543167115, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.031326590538025, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.031604826450348, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.0318925619125365, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.0320964829921722, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.032854974269867, Hidden Layers: [14, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.0329352931976317, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0329754948616028, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0335939407348633, Hidden Layers: [14, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0336357653737067, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0340152177810669, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.0345458583831786, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.0347794995307922, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.034914834856987, Hidden Layers: [16, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0350257717072964, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.0351076081991195, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0354762330651284, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.035498328924179, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0360704959034919, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.036913468003273, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0378706413507461, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0382787200808525, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.038502524793148, Hidden Layers: [14, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0387021378278731, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0388482246398927, Hidden Layers: [14, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.0392061249017714, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.0393334809541703, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0397745322287082, Hidden Layers: [14, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.0402820677161215, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0404546320438386, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.041114322900772, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0418516397476196, Hidden Layers: [14, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.0419397552013396, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.0420043069720268, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0420568883419037, Hidden Layers: [12, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.0424412667751313, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.042600088119507, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.042687835216522, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0427082359790802, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.042861752510071, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0435899123549461, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0439001698493957, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0440221458673478, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.044129446208477, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0442552716732023, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.044936180114746, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0455758526921273, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.0457575052976609, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.0460700664520264, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0469128773212433, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0471726834774018, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.0472084954977035, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0472783148288727, Hidden Layers: [14, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.0475079283714295, Hidden Layers: [14, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.0475649688243867, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0482591137886046, Hidden Layers: [14, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0483686850070952, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0483694434165955, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0488534688949585, Hidden Layers: [14, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.0488992615789177, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0490334808826447, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0492015409469606, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.0492779514789583, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0497480944395066, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.0501325458884239, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.0502329289913177, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0502421754598619, Hidden Layers: [14, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0506813633441925, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0507885818481444, Hidden Layers: [14, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0508269877433776, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.050846247434616, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.0510208249092101, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0513658702373505, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0516811640262602, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.052442467689514, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0533795107007027, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0535021126270294, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.0535028697252273, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0535908982753752, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0536984640359879, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.053828214108944, Hidden Layers: [12, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0539305836558341, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0540950894355774, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0543439511060715, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0543442729711532, Hidden Layers: [12, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.0545746192932128, Hidden Layers: [14, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0549490993022919, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0552239999771118, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0558278535604475, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0562497828006745, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.0566131700277328, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0569332570433616, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.05739982175827, Hidden Layers: [14, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0579139012098313, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0581531710624694, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0583294916152954, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0586347043514253, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.0589269061088562, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0589376435279845, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0592548944056035, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0593107018470764, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0593721661567688, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0593965831995011, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0596677601337432, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.0598453149795533, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0603716448545455, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.060785198688507, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.061256624817848, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0618468225002289, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0618835583925246, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.0619545805454256, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0620881009101868, Hidden Layers: [12, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0624287099838257, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.0628159493803977, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0638855055570602, Hidden Layers: [16, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0638957442641257, Hidden Layers: [14, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.0639570460319518, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.0641566023826599, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.0642847294807436, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0649144847393035, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.0653473467826842, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.0661357182264328, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.0666196205317973, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.0668340311050415, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0670043904781341, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0680034726858139, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0681829083561898, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0684595351219177, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0686921194791794, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0693311439752577, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0698782638311386, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.070406852722168, Hidden Layers: [14, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.070581117272377, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.0706403541564942, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0706441328525542, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0707555108368396, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.0710142259597777, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.0711428971886634, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0713419616222382, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0713543117642401, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.0715382680892944, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0716411457061767, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.0716948211193085, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0717600125074387, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.0722410993576048, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.072314890220761, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.072603690624237, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.0731649923920632, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0732078731060029, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.073387649655342, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.073650979310274, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.073729924917221, Hidden Layers: [14, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.0739199209213257, Hidden Layers: [14, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.0741948399543761, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.0742012221813202, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.074580644249916, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.0745923743247985, Hidden Layers: [14, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0751376688480376, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.0752985137701034, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0756921679973601, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.0759500265717505, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.0764539751410485, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.076735294610262, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.076962058544159, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.0774131492376327, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.077769433259964, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.0778125740587712, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0779775099754332, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.0782990589737893, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.079217530965805, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.0796695057153702, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.0797980997562409, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.080132450222969, Hidden Layers: [16, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0802209317684173, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.0802641607820989, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0803521518707275, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.080408705949783, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0805104765892029, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0818873512744904, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.0818959760665894, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0820650100708007, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0821861546337606, Hidden Layers: [12, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.0822831497192382, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.0823623094558716, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.0825453953742978, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.082599133551121, Hidden Layers: [14, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.083327202796936, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.0833412739634514, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.083363504767418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.0841315895318986, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.0841876821517942, Hidden Layers: [14, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.084328844755888, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.0846343660652635, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.084816481590271, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.0855912685394287, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.085886742591858, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.0862491130828857, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.086532599210739, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.0866394624710083, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.086936086475849, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.087072280049324, Hidden Layers: [12, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.0875321340858934, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.0878226444721222, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.088078898191452, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.088230104804039, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0883969233036042, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0885959163904189, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.0889974851608275, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.089275209903717, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.0895144448280334, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.0897042379379271, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.0899222109317779, Hidden Layers: [6, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.0900471585989, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0900777637958527, Hidden Layers: [14, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0901152849197389, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.091097836256027, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.091228516459465, Hidden Layers: [14, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.0912417218685149, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.0912890970706939, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.0921016575098037, Hidden Layers: [14, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.0922888606786727, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.0924107954502105, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.092526517868042, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.0934453994631768, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.0934803665876387, Hidden Layers: [14, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.0937770698070526, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.0938751522302628, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.0939628844261169, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.0941764459013938, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.0942743990421295, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0943490180969238, Hidden Layers: [14, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.0943686742782592, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.0948666516542436, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.095472993016243, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.0959488317966462, Hidden Layers: [14, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.0961927339434623, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.0962225768566132, Hidden Layers: [14, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.0962527232170103, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.0967379765510556, Hidden Layers: [14, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.0980191812515259, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.0987761557102202, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.0990946490764617, Hidden Layers: [14, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.0993497207760812, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.0994979084134102, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1000234652161598, Hidden Layers: [14, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1001107767820357, Hidden Layers: [14, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.1007199600338935, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.1010433673858642, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.1010906457901002, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1011817544698714, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1012975022792815, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1016623467803002, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1016926502808928, Hidden Layers: [14, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1018274664878844, Hidden Layers: [14, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.102550098657608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1033662649989129, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.103560108564794, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1037141622304916, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1044815737009048, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1048774063587188, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1052216048538686, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1054862246513366, Hidden Layers: [14, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1057054178714751, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1057543680667876, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.105893760919571, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1061467353105545, Hidden Layers: [12, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1064059302806855, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1065229997634887, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.106527872443199, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1065662965774536, Hidden Layers: [14, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.1066235959529878, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.106881468296051, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.1070700678825378, Hidden Layers: [14, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.107204086303711, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1074355394244193, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1074698095321653, Hidden Layers: [14, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.1075008455514908, Hidden Layers: [14, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.1075651190280915, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1087197440862657, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1088109940290451, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1089854109287263, Hidden Layers: [12, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1097685191631317, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.1100517600774764, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1107550964355468, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1110571771860123, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.111091426372528, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.1112224564552307, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1117547646164894, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1118240520954132, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1119961798191071, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1120510915219781, Hidden Layers: [14, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.1121876972913742, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1122084472179412, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.112245536327362, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1126086980700491, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1126668472290038, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1127318770885466, Hidden Layers: [14, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1128060162067412, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.1129486560821533, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1132547348737716, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.1136798218488693, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.113742846608162, Hidden Layers: [14, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.1142170131206512, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1142428741455077, Hidden Layers: [14, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.114990519285202, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.115932379722595, Hidden Layers: [14, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1160058319568633, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1165384948253632, Hidden Layers: [12, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1166182503700255, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1168236628770827, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1169887051582337, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1170781210660934, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1173121399432422, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1180929094552994, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.118099238395691, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.1192982182502746, Hidden Layers: [14, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1195269674062729, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.1196605435609819, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.119926503300667, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.1199304938316346, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1201983499526977, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.1202941477298736, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.1208075528144836, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.1210597709417343, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1211458222866058, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1211650252342225, Hidden Layers: [12, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1215272591114043, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1217362809181215, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.122370755970478, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1229263305664063, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.1230098948478697, Hidden Layers: [14, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1232451692223548, Hidden Layers: [14, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1232563242912292, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1242185267806053, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1246203848421572, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.124660525083542, Hidden Layers: [14, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.1246937453746795, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1251030206680297, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1251817271113396, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.125215107820928, Hidden Layers: [14, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1253704309463501, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1256030082702637, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1256788909435271, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1257029175758362, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.1265652179718018, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1269218326210975, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1272380948066711, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1275532352924347, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.128172285914421, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1282465860843658, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1283307985067368, Hidden Layers: [14, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1283783781528474, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.1291059583425522, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.12932218170166, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1293941140174866, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1294322653859854, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1294667776860297, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.1295561168193817, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.129657448887825, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1297462627887724, Hidden Layers: [14, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1298488974571228, Hidden Layers: [14, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.130066397100687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1304757986068725, Hidden Layers: [12, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.1309785828590393, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1311335456073284, Hidden Layers: [14, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1311353661119938, Hidden Layers: [14, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1314569429159165, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.1320048081874847, Hidden Layers: [14, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.1321519852280617, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.1322445482611656, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.132416479587555, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1324955567717552, Hidden Layers: [14, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1325382965803148, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1326542973518372, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.132675685286522, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.132710320800543, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1328479603528976, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1329798862934113, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1334580842256545, Hidden Layers: [12, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1336679563522338, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1338721074759959, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1341396190822124, Hidden Layers: [16, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.1342642740011215, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1344717059135436, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.134646280169487, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.13478817653656, Hidden Layers: [14, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1350252070128917, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1352657054662703, Hidden Layers: [12, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1354083523750305, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1356325731277466, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.1365522240400314, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1366797506809234, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.13671632707119, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.13683682847023, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1370276898145675, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1372797459959982, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1377322289943694, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1381354246139526, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.1388242813944818, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.139181356191635, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.1392349660396577, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1393481701612473, Hidden Layers: [14, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1395087213516235, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.1396423012018204, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1399101078510285, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1404609561562538, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1405060338974, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1418172389268875, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1424760193824768, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.1427407117486, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1427434656620026, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.142810611784458, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1429515022039414, Hidden Layers: [12, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1432729530334473, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.1436453629136085, Hidden Layers: [14, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.1438857972621919, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.14406378865242, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1440683946609496, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1443023251295088, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1449538472890854, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.144988051056862, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1451707661151886, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1451862204670906, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1453259915709495, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.1457502335309981, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1461452366113662, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1462877541780472, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.1465829479694367, Hidden Layers: [14, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.147533522605896, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1477673414945602, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1478081093430519, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.148675607442856, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.148746195793152, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1491334125995636, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1492148265838622, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1492296457886695, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.149304316997528, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1494616032242775, Hidden Layers: [14, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1499967626295984, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1501411099433898, Hidden Layers: [16, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.150155644118786, Hidden Layers: [14, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1504302397370338, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.151472705602646, Hidden Layers: [14, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.1514975011348725, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1522663474082946, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1529740154743195, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1538565397262572, Hidden Layers: [14, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1539779528975487, Hidden Layers: [14, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.1543290410041809, Hidden Layers: [14, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1547215626239775, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1550965011119843, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1551009283065796, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1553682233393192, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.155660264492035, Hidden Layers: [14, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.1556893781423567, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.155978034734726, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1560142159461975, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1560575425624848, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.1560877054929732, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.156422911643982, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1566076443195343, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.157140380501747, Hidden Layers: [14, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1574367970228194, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.1575050727128982, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.1578937218189238, Hidden Layers: [14, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.1580805070698261, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.158277866721153, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1583648133277893, Hidden Layers: [12, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.158447265625, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1584796118736267, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.158585971593857, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1587497625350953, Hidden Layers: [12, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1589796741008758, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.159177005648613, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1592004747390745, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1593240574598311, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1593245733380317, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.1599270601272582, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.160514140188694, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.161376729786396, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1616141028404237, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1619692549705505, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.1623557872772217, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1627293915748595, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.162863756775856, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.162965503811836, Hidden Layers: [14, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.163649632036686, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1638499915599823, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.163869074344635, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1642675642967224, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1644506767392158, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.1645051602125167, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.1645661570727825, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1646025599837302, Hidden Layers: [16, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1648212660700081, Hidden Layers: [14, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.1649076819419861, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1652860090732573, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1660752207636833, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.1662663221359253, Hidden Layers: [14, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.166352427005768, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.1664682821035384, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.1665527880191804, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.166595023870468, Hidden Layers: [16, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.166648354291916, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.1667070746421815, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1670567111968992, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.1676615328788755, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1680036354064942, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.1686139688491821, Hidden Layers: [16, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.1687471568584442, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.169631724357605, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1698551135063169, Hidden Layers: [12, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.1698786590099335, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.169943438768387, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1700107023715973, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.170336440563202, Hidden Layers: [14, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.170611469745636, Hidden Layers: [14, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1707190768718718, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.1708724796772003, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.1709176969379187, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.1709428073763846, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.1711886260509492, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1714068803787232, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1714589100927113, Hidden Layers: [16, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1715517343878745, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.1716131925582887, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.171757330060005, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.1719075129032135, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.1725343749523163, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.1726222772598267, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.172726434469223, Hidden Layers: [14, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.172731126099825, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1728973822593687, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.1732904494404792, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.1733663275837898, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.1734163999557494, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1734553784132005, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1735279936790466, Hidden Layers: [14, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.173721449136734, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1737823847532272, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.1738640117645265, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.1741005972623824, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.17412093436718, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.174130481481552, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.1745766252279282, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.1747539508342744, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.175797312259674, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.17603859603405, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1763273286819458, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1763556361198426, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.1763800532817839, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1764673442244529, Hidden Layers: [14, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.1768675263971091, Hidden Layers: [14, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1770820021629333, Hidden Layers: [14, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1770922392606735, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1772977681159973, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.1775286853313447, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1780524227619171, Hidden Layers: [14, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1784938354492187, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1785475396215914, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1788064458072185, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.1788590536117554, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1795523599386215, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1796953797340393, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1799266550540923, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1801714555472134, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.1806045177578928, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.180729979634285, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1809096500873566, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.180922313094139, Hidden Layers: [4, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.181095473766327, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.1812008291482925, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.1812626705169678, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.1818133056163789, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1819174618124961, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.1822544205188752, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1823428410887717, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.1823925570249556, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.182465680003166, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.1825273767709732, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1826950311660767, Hidden Layers: [14, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.1826993882656098, Hidden Layers: [14, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.1827657330036163, Hidden Layers: [16, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1827707040309907, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1832415610551834, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.183336302638054, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.1836046726107596, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.1844253718852997, Hidden Layers: [12, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.1847861194908618, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.1856967315673828, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.185770552664995, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.1870422676801682, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.1870985665619371, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.187456034183502, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.1880762338638307, Hidden Layers: [14, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.1885135564804077, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.1887992756366728, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.1889029401540756, Hidden Layers: [14, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.1890507459640502, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.1891784162521362, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.1893329427242278, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.1897786026000976, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.1898424863815307, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.1899617228507995, Hidden Layers: [14, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.1903312265872956, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.1905379891395569, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.1909595952033996, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1912147763371468, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.1914721310138703, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.191513533949852, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.1921170905828475, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1923226314783097, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.1926681563854218, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.193011538684368, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.1930558667182922, Hidden Layers: [14, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.1932858560830355, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.1934251980781554, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.193648087978363, Hidden Layers: [14, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.1937037125825882, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.194228090405464, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.1947636291980743, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1949568316936492, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.1950400904417038, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.1953844026327132, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.1957175029441713, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.1959527790546418, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1967217206954956, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1974178109169007, Hidden Layers: [12, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.1974721908569337, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.197761669874191, Hidden Layers: [14, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.1979898393154145, Hidden Layers: [14, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.1982956261634825, Hidden Layers: [12, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.1986354157924652, Hidden Layers: [14, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.198767086982727, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.1989935801029206, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.1992503435015678, Hidden Layers: [14, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.1992623761892318, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.1993214969635009, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.1995410074144601, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.1995491820573807, Hidden Layers: [8, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.199572672009468, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.1998763474822045, Hidden Layers: [14, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2003934339284896, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.2003999922275543, Hidden Layers: [14, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2006638564169407, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2006974831819535, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2017000504434108, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.2017523035407067, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.201946598768234, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2020080180168151, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2022306070327757, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2023740649223327, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.202992297887802, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2034845188856125, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.203589000105858, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2036739408969879, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2036983489990234, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2037106618285178, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2042333397865295, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.204601080775261, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.204626046180725, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.206292489171028, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.206504605770111, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.2069601752460002, Hidden Layers: [14, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.2074873244762423, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.207822914600372, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2079553816318511, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2081365630626677, Hidden Layers: [14, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2083155289292336, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2086799581050873, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.208918525338173, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.2091000989675522, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2092778968811035, Hidden Layers: [14, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.209413358926773, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2095628324747085, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2096288726329802, Hidden Layers: [16, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2104000524282454, Hidden Layers: [14, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2104397386312484, Hidden Layers: [14, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.2108691544532775, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2113046199083328, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.2113183349370957, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.2113528766334056, Hidden Layers: [14, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2118237602710724, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.2121406303644178, Hidden Layers: [8, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2121646761894227, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.212300381064415, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.213075375556946, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2131316125392915, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.2131961078643798, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2134685341864824, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.2141593639850616, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.2141824513673782, Hidden Layers: [12, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.2147558987140656, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.2147685573101044, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2149228692650795, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2149468020200729, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2150047063827514, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2155731070041658, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.2155862197875975, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2156518012881279, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.215799100011587, Hidden Layers: [14, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2158183955848216, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.215869292974472, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.2161341577768325, Hidden Layers: [14, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2164634570479393, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2169479954242708, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2179839033484459, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2180655002593994, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.2182242006063462, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.2182347044348716, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2183970916867257, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.218765609025955, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2188456342220306, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.2189267501831054, Hidden Layers: [12, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2196875901222228, Hidden Layers: [14, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.219880692720413, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2199360654354094, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.220035719871521, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2209561395645143, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2210055031478404, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.2219280109405517, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.2221442401409148, Hidden Layers: [14, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.222249651312828, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.2228133187294006, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2228325456380844, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2234574933052063, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.2236117005348206, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2241217181086541, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2243560045957564, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.224702876806259, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.225004394352436, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.225172500371933, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2251747727394104, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.2253757685422897, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2259368613362311, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2259837571382524, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2261759088039397, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2264927492141724, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2268468902111054, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2270101189613343, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2271782414913175, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2273240283727644, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.22742484664917, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2277037177085877, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2277079105973243, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2280887336730957, Hidden Layers: [14, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.2282076060771943, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2284138917922973, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2284859031438828, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.228560088634491, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2286129951477052, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2288077477216721, Hidden Layers: [16, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2290545761585236, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.2297819708585738, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.230300000667572, Hidden Layers: [14, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2303008351325988, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.231125675201416, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2313723146915436, Hidden Layers: [14, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.2316720776557921, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.231753465592861, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2321368232965468, Hidden Layers: [14, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.232228826165199, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2323781665414573, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2326258662939071, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.232729040145874, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2327508989572524, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2328656063079833, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2329449695199728, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2330015555620193, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.2334326192736627, Hidden Layers: [14, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2341341882944108, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.2343170046806335, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2347751144170762, Hidden Layers: [12, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.2348447115421295, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2349895792007444, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.235126222848892, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2359618828296661, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.2362071768045424, Hidden Layers: [14, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.2366228699684143, Hidden Layers: [6, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2372017860412599, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.237355664730072, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2374689251780508, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2375131607055665, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.2376206934452056, Hidden Layers: [4, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.2376698523759841, Hidden Layers: [14, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2379881546497344, Hidden Layers: [12, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.2384033278226851, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.2389122724533081, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2393899188041686, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2394693703651427, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.2395631062984467, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2406124026179313, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2406694177389146, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2413958788514137, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2414695698022844, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.241601664185524, Hidden Layers: [14, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2419797756373883, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2421698033809663, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.242634892821312, Hidden Layers: [14, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2426537096500396, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2430524916648864, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.243053564429283, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2431426808834076, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.243456225156784, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.243661993741989, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2442595219612123, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445047547221182, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2445318520665167, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.244551237732172, Hidden Layers: [14, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.2445571527481079, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.2451037096977235, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2453710362911223, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.24555746614933, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.245790148139, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.2461296141147613, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.246322825908661, Hidden Layers: [14, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2464210275411607, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.2464781866073609, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.2465610966682434, Hidden Layers: [14, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.24677541410923, Hidden Layers: [14, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.24697012758255, Hidden Layers: [6, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.247449083685875, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.248150211572647, Hidden Layers: [16, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.248412902712822, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.2486811328679324, Hidden Layers: [16, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.248858909368515, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2489348206520081, Hidden Layers: [14, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.249110186100006, Hidden Layers: [14, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2492913488149644, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2495196838378906, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2496729135513305, Hidden Layers: [16, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.249805443048477, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.2500996903181076, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2506614446640014, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.2507887959480286, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2509438633918761, Hidden Layers: [14, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.2512972742915154, Hidden Layers: [14, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.2514893040657042, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2516102582216262, Hidden Layers: [12, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.2523872871398924, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2524703726768494, Hidden Layers: [4, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.2535302221775055, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.2538080052137375, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.254142478466034, Hidden Layers: [14, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.2543104472756386, Hidden Layers: [14, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.25447074174881, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2545394882559777, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2547107093036174, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2553999902606008, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.255672797679901, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.2559172365665436, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.256157116651535, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2568185716867446, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.2568597660064698, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2572149872630836, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.2572679624557495, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2573097109794618, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.2574507936835289, Hidden Layers: [14, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.257878007173538, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.2579129383563994, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.258162288427353, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.2581990916132928, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2583328559994698, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2586015242934228, Hidden Layers: [14, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.258658321261406, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2588189766407012, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2588403031826019, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2590452094078064, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2594862492084502, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2595300738811492, Hidden Layers: [14, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.2596591730117797, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2597322463989258, Hidden Layers: [12, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.260091652035713, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2605842638015747, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2610995729118586, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2612726211547851, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2618624180555345, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2622084241956473, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2627122163772584, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2629660741090774, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.263277733385563, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2637429974079133, Hidden Layers: [12, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2637933254241944, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.264198021888733, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2642434491962196, Hidden Layers: [14, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.264324443101883, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.2644008711576462, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2646747634410858, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.2649731819629668, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.2649783864617348, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2651285932064056, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.265193262696266, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.265494620859623, Hidden Layers: [4, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2656156569719315, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2657224659919737, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2665656403303145, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.2666680388748646, Hidden Layers: [12, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.2668405151367188, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2668662514686584, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.2669549946784973, Hidden Layers: [12, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.2669831202030182, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2671440348625183, Hidden Layers: [14, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2672824837267398, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.2674663960933685, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2675511837005615, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.2675757185220717, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.2676679823398591, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2679259285926818, Hidden Layers: [14, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.268024039566517, Hidden Layers: [14, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.2680552273988723, Hidden Layers: [14, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.268432930111885, Hidden Layers: [14, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2684665739536285, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2684946018457413, Hidden Layers: [12, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.268565839588642, Hidden Layers: [16, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.2686259225606917, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.2689274773597716, Hidden Layers: [14, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2689354211688042, Hidden Layers: [14, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.2692975685596466, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.269310370385647, Hidden Layers: [14, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.2693283901214598, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.269498236835003, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.269600009918213, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.2699883937835694, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.2702135741710663, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.2706028597354888, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2711218104362487, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2721146658658982, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.2722176745533944, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.272444124519825, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.27256670743227, Hidden Layers: [10, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.2728394241333008, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.2730072708129883, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.2735114455223084, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2735145252794027, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2735622428953648, Hidden Layers: [16, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.273655313551426, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2736858278512955, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.2737457292079923, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2745149836540222, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.2748253226280213, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.274883782863617, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2750106023550032, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.275108258485794, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.2751694118976595, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2755098745822906, Hidden Layers: [14, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.2755898342132568, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.2756651029586792, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.2758692851886153, Hidden Layers: [14, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2759167492389678, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.276469317138195, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.2764834616184235, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.276766179561615, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.2771128609776496, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.2774770901203154, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.2776659578084946, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.2783773452043534, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.278399002611637, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.2785214558839797, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.2790948748588562, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2794184237718582, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.279567049741745, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.2801245115995408, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.2801790002584457, Hidden Layers: [14, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.2802399591207503, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.280376872420311, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2805158779621124, Hidden Layers: [12, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2806914303302765, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.2807814006805418, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.2808357685804368, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.2820487205982207, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2823867545127867, Hidden Layers: [12, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.2824026124477386, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.2824575755596161, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.2831035017967225, Hidden Layers: [14, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2833797991275788, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.283564223408699, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.2836234407424925, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.2836558133363725, Hidden Layers: [14, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2837758395671846, Hidden Layers: [12, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.2850175187587738, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.2850350186824797, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.2851009964942932, Hidden Layers: [12, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.2852699309587479, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.285674626737833, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.2863050699234009, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.286314210653305, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.286460910797119, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.2865045615136623, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2878554665148259, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.28789635181427, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.287969485282898, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.288053663134575, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.288068825006485, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.2882042840719223, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.2882121626138687, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2883574829101563, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.288662077486515, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.2889633562266827, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.2889757871627807, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2892705932855606, Hidden Layers: [14, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.2893567517995834, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.2893610820770263, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.2896505728363992, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.289659138083458, Hidden Layers: [14, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.2901275724172592, Hidden Layers: [14, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.2902149916887282, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.290267742484808, Hidden Layers: [12, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.2903265001177786, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.291357508301735, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.2915854053497313, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.292645646929741, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.2928828254938125, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.2929395660758018, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.292986238002777, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.293042896747589, Hidden Layers: [14, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.2938129652142525, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2940377447605134, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.2940906286239624, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2941042470932007, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.294788048028946, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.294961968421936, Hidden Layers: [16, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.295846273303032, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.2961256757974624, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.29648896753788, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2965001881122589, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.2966798727512359, Hidden Layers: [6, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.2967923645973205, Hidden Layers: [12, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.2968990956544875, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.2979236737489699, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.2980957542657852, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.2983018473386765, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.2983676288127899, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.2986110941171645, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.2987893715500831, Hidden Layers: [12, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.2989471554756165, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.2993536133766175, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.2993562731742858, Hidden Layers: [14, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.2999336421489716, Hidden Layers: [16, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.3003900170326232, Hidden Layers: [6, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.300602905511856, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3014185265302658, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.3014895901083947, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3017965793609618, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.301805184841156, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.301810483932495, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3023189607858658, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.3031688661575316, Hidden Layers: [12, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.303560623884201, Hidden Layers: [14, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.3043898716568947, Hidden Layers: [12, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.3044309780597687, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3044717342853545, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3044827073812484, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.3047610018253326, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3049516544342041, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3054452613592147, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3057035731077193, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3059039340019225, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3059449064731599, Hidden Layers: [12, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3061656594872475, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.306288183093071, Hidden Layers: [6, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3064177635908127, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3064480991363525, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3067478083670139, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.306784102320671, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3068681895732879, Hidden Layers: [12, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.307440264582634, Hidden Layers: [16, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.307906848192215, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3080960268080233, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.308551162481308, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3090039092302324, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3092384294271469, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.3097322063446044, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.310144631922245, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.310320417881012, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.311190249443054, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.311542965888977, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3117063555717468, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3117212817668915, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.3117224589586258, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3118670601844786, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.3119568840265274, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3124546796679497, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.3124562639594077, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.3127180714607238, Hidden Layers: [14, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.3128689140677452, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3129359312355517, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3131315932273864, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3132178382873534, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3132833676338194, Hidden Layers: [14, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3134556994438171, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3139395639896392, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3141018942594527, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.3148029550909996, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.314983524441719, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.315372727870941, Hidden Layers: [12, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3154627685546874, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3157829687595366, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.315994225502014, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.3160212501883506, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.3161579877138139, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3163570433855056, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.3164451763629912, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3164802894592285, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.3170945167541503, Hidden Layers: [14, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.317182038784027, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.3172523515224455, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3174623684883116, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3178813235759734, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.3184804677963258, Hidden Layers: [14, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.318626489162445, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3193671987056732, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3196965992450713, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.3197059497833252, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3198553919792175, Hidden Layers: [14, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.3201689782738686, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.320310755252838, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3209193408489228, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.32132937759161, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3222439572811127, Hidden Layers: [14, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.322603341937065, Hidden Layers: [14, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3228353456258772, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3233416841030121, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3233602770268917, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3235272586941718, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.3241978869438171, Hidden Layers: [12, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.3244619071483612, Hidden Layers: [14, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3245241001844406, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.3248318091630935, Hidden Layers: [16, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.3249909937381745, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3258596748113631, Hidden Layers: [14, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3261946860551834, Hidden Layers: [12, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.32668805873394, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.3267080783843994, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.326729215234518, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3273676634430884, Hidden Layers: [14, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3276256430149078, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3277433071136475, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3277980056256056, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3278208632469177, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3283361272811889, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3287199407815933, Hidden Layers: [14, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.328814271092415, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3288431212902068, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3288901090621947, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.329128805845976, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3291599839925765, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3297507659196852, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.329865675032139, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.329993736743927, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.330053715467453, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3301436387598513, Hidden Layers: [14, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3306114077568054, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3307581782341003, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.3309399664998054, Hidden Layers: [12, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3311425372958183, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.331734648346901, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.3329135417938232, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3329461888074874, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3329702842831612, Hidden Layers: [6, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3331574008464813, Hidden Layers: [14, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.333287979722023, Hidden Layers: [4, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3346209619790315, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3346728983521463, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3352928578853607, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3353062634468078, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.3356382161378861, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.3357007222175596, Hidden Layers: [12, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3358825981616973, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.3359504256248473, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3362213716506957, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3362901675701142, Hidden Layers: [12, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3366749588251114, Hidden Layers: [14, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3372200460433958, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.3372941882014273, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3373357951641083, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3377441930770875, Hidden Layers: [14, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.3379688190221786, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3383282550275326, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3385834038853646, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.3386106692254542, Hidden Layers: [14, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.339330087661743, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.339451030254364, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.3397024245262146, Hidden Layers: [14, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3398525700569153, Hidden Layers: [14, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3399842683821916, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3402878971099852, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.34064542388916, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.341056701540947, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3411517949104308, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3412682354450225, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.3414656937122345, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3416240200996399, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3419297322630883, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3419982314109802, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.3421663615703583, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.3421750948429108, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.3425555679798127, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.3425621151924134, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.3426572501659393, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.342791716814041, Hidden Layers: [16, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.3429890334606172, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3430540845394134, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.3434198067188263, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.3436618953943253, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3438133046627043, Hidden Layers: [10, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.3438747049570083, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3439538061618805, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3443136917352674, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3446952760219575, Hidden Layers: [16, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3454388425350188, Hidden Layers: [14, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3455763921737671, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3457993969917297, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3458165690898896, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.345816738963127, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3459816489219665, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.346075677871704, Hidden Layers: [12, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.3463023979663848, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3466098413467407, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.346781825274229, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3470313728451728, Hidden Layers: [14, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.347072219848633, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3473331645727158, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3473761591911315, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3474469230175017, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.347991520166397, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.3480030301809311, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.348074921965599, Hidden Layers: [12, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3487317115068436, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3489252555370332, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3490514472723008, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3493617281913757, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3495793238878249, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3497422367930412, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.3500553894639016, Hidden Layers: [16, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.3501017365455628, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3503839701414109, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3507744699716568, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.3508429232984782, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.3509022772312165, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.350908747434616, Hidden Layers: [12, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.3509874577820302, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.351419883966446, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.351424762159586, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3515535221099853, Hidden Layers: [12, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.3515627340078353, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3517092064619063, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3520561428070068, Hidden Layers: [6, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3521182894706727, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3526127338409424, Hidden Layers: [14, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3526166605949403, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.3528617352843284, Hidden Layers: [12, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.353035505414009, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3532036989927292, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.353425912618637, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.353647212743759, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3538300142288207, Hidden Layers: [14, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.3540404796600343, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3543722302317618, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.3544619619846343, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3548461299985646, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.3548656195402144, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3551718175411225, Hidden Layers: [14, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.3554134645164013, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.3556158111095429, Hidden Layers: [12, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.355992341786623, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3562421637773514, Hidden Layers: [14, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.356500780582428, Hidden Layers: [14, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3565146418213843, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.356932810306549, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3580610409379006, Hidden Layers: [12, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3581148461103438, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.3582237632274627, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.3583797693252564, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.358584304332733, Hidden Layers: [16, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.3587980136871338, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.3588591716438532, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.3591956872940063, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.3594924323260784, Hidden Layers: [14, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3599221110343933, Hidden Layers: [14, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3604056553840636, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3605182573795318, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3608753430843354, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.360919356405735, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.361185540318489, Hidden Layers: [14, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.36185402572155, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.3618554845452309, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.3618731305599212, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.3621688667535783, Hidden Layers: [14, 6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.362702915430069, Hidden Layers: [14, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3629753009080887, Hidden Layers: [14, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.3631398060023785, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3634249181747435, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.363643764257431, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.364082804441452, Hidden Layers: [14, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3647117540836333, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3647809019908308, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3658879384994507, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3662383365631103, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.3662926003932951, Hidden Layers: [6, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3669246363639833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3669361785054206, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3675332144498824, Hidden Layers: [14, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.3677672371864318, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.3684748814105987, Hidden Layers: [14, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.3687674403190613, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3687836885452271, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.3689477984905243, Hidden Layers: [16, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3690272390842437, Hidden Layers: [14, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.369115690946579, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.3691217392683028, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.369421910047531, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3696078181266784, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3696718173027036, Hidden Layers: [14, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3701489572525023, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.370218774676323, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.3702292048037052, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.370653076827526, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3706976991146802, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3708838138580322, Hidden Layers: [14, 6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.3709621325731276, Hidden Layers: [14, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.370978860616684, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.3712328106164933, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3712963491678238, Hidden Layers: [14, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.371300256729126, Hidden Layers: [14, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3715314090251922, Hidden Layers: [14, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.3716639697551727, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.371949361562729, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.3720141053199768, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3731155395507812, Hidden Layers: [14, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.3731223106384278, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3742104530334474, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.3743419706821443, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3743433923721313, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.374400000333786, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.374490545988083, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.3745349810123444, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.3747590273618697, Hidden Layers: [14, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.3749801129698753, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.3749926613569259, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.3753421798944472, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3754923090934752, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.3759255588054657, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.376452475786209, Hidden Layers: [14, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.376955962240696, Hidden Layers: [16, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3770248398780822, Hidden Layers: [14, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.377598753631115, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3777417466640471, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3777845860123634, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.3778532087802886, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3782864272594453, Hidden Layers: [14, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3786060690879822, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.379000167608261, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3790293709039687, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.3796684101819991, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3798093155622482, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3798220351934432, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.3799200385808945, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.3801362231969834, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3802760004997254, Hidden Layers: [14, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.380561923980713, Hidden Layers: [10, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.3806002330631018, Hidden Layers: [14, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.380611956551671, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.3807407736778259, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3807878807783127, Hidden Layers: [14, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.3811505708694458, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.3814833270311353, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.3817279160022735, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.3818380224704743, Hidden Layers: [16, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.3821219201385975, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3822018563747407, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.3824641168117524, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.382643179655075, Hidden Layers: [8, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.382660992503166, Hidden Layers: [14, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.3829119951128959, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3830936313271522, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.3831788167953492, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3835576341152191, Hidden Layers: [14, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.3837285697460175, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3843189630508423, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.3848715335726738, Hidden Layers: [4, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.38499972820282, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3853567422032356, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.38557870388031, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.385625543117523, Hidden Layers: [12, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.386323773920536, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.3872020456790923, Hidden Layers: [12, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.387208648085594, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.3873851954936982, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.3875371531248093, Hidden Layers: [14, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.3879624485969544, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.3879848376512527, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.3881293289363383, Hidden Layers: [14, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.3882122099995613, Hidden Layers: [4, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.3886387467384338, Hidden Layers: [14, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.3890215158462524, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3894233971834182, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.3895928428173066, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.3898478388786315, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3898489402532577, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.3899388880729675, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.390400286078453, Hidden Layers: [14, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3905784369707106, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3906566561460494, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.3912955420017241, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.3914481106996537, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.3914799213409423, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.391789934158325, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.3919424176216126, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.3920154005289078, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.392097571492195, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.3921920716762544, Hidden Layers: [14, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.3922474757432937, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.392300127506256, Hidden Layers: [4, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.3923653721809388, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.3927490442991257, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.3927817412316799, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3928238101303578, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.3930594787597657, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.393179510831833, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.393390619814396, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.3936654002070425, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3940250068902968, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.3940303496122362, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.3940454349517821, Hidden Layers: [6, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3941033065319062, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.3943568453788757, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.3954484314918516, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.3960285156965255, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.3960764006376265, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.3962278906106949, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.3963168486952782, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.397109228372574, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.397471097111702, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.3975970253944396, Hidden Layers: [14, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.3977055393755435, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.3980314449071884, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.3984536323547363, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.398580132484436, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.3988703126404434, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.3993040726184844, Hidden Layers: [12, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.3993730098605155, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.399439267873764, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.3994881451129912, Hidden Layers: [14, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.3995672065019609, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.3998017713427544, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.3998348641991616, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4000118315219878, Hidden Layers: [14, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4004991441965102, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4007450670003891, Hidden Layers: [14, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.4009284124374388, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.401613317489624, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4020033001899719, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4021509163677692, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.402387039721012, Hidden Layers: [14, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.4027880776524544, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4031451511383057, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.4031879351139067, Hidden Layers: [12, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.4036362636089326, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.404047726392746, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4040622190237044, Hidden Layers: [14, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4041470930576323, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4050356120467185, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.4052648220062256, Hidden Layers: [14, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4054688379764557, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.405615472793579, Hidden Layers: [14, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.406106551170349, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4063033401966094, Hidden Layers: [14, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.4065225884914399, Hidden Layers: [12, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4069226239994168, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.407217264175415, Hidden Layers: [14, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.4074744403362274, Hidden Layers: [4, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4078077630996702, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4082462356090546, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4082952439785004, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4096608672142028, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4103223905563353, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4107495040893554, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4108583152294158, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4111608282327652, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4112306044101715, Hidden Layers: [4, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4112409591674804, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4113329428434374, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4127621088027955, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4129516422748565, Hidden Layers: [14, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4130271777510643, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4137922406196595, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4138897690773011, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4142066687345505, Hidden Layers: [14, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.414388462215662, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4145033602714538, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4145190641880034, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4149462387561798, Hidden Layers: [14, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4149966708049178, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4150501847267152, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.4151182923316956, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4153068100214004, Hidden Layers: [14, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.415557039141655, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4158903524279594, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.415991908311844, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.416033923983574, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4162657856941223, Hidden Layers: [16, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4165477008819578, Hidden Layers: [4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4168289752006529, Hidden Layers: [6, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.416896034836769, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.417103001832962, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.417250825881958, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.417263792514801, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.4173446297645569, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4173992395401, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4174226911664007, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4175143394470215, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4177747431993484, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4178217158317565, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.418121071457863, Hidden Layers: [4, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4184040546417236, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4185050487518311, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4188463464975356, Hidden Layers: [14, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4188990741968155, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4191509306430816, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.419309331536293, Hidden Layers: [14, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4194887631237507, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.4196272314190863, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4199320242404938, Hidden Layers: [14, 4]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.4200205281972884, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.420102985203266, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.420616219997406, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4210114166736603, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4213307254016398, Hidden Layers: [12, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4214343552589415, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4216796696186065, Hidden Layers: [14, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4216918766498565, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4217666134834288, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.422131054162979, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4223053634166718, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.422451855301857, Hidden Layers: [14, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4227982044816017, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.4229118525981903, Hidden Layers: [14, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.4231562033891678, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.423182737827301, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4233819308876992, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4233985096812247, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4238386318683625, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4241429806351662, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.424767118692398, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4248010770082473, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.4253272120952605, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.425509011745453, Hidden Layers: [12, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4257213473320007, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4263512479066847, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4264571014642715, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4270993203520774, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.427158652305603, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.4273456010818482, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4273701775074006, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4273761794567108, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4274224955439567, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4278223842382431, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4280325682163237, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.4284487038850784, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.4287651569247246, Hidden Layers: [4, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4288418308496476, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.4290558960288764, Hidden Layers: [12, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4301183943748472, Hidden Layers: [14, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.430337804555893, Hidden Layers: [4, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.4304524869918822, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4311604604721069, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4315102088451386, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.431624525785446, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.4319932818412782, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4322724536657332, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4324830473065375, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.4325110960006715, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.4326510564088821, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4335243642926216, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.4341230276823045, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4341457191705704, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.4343675493858754, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.4344475463628767, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.4345966086387634, Hidden Layers: [16, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4346961483955383, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4348764226436614, Hidden Layers: [14, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4355213106274605, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.4357823357582091, Hidden Layers: [14, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.436339031457901, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4364774823188782, Hidden Layers: [14, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4367408440113068, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.437243476629257, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4375874012708665, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.4376198530197144, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4377725977897644, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4377964706039055, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4378126459121703, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.43823813354969, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4383385882377624, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.438396360039711, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4384397537708282, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4384685591459274, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4385715961456298, Hidden Layers: [12, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4392974987626075, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.4393303513526916, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.4396920386552812, Hidden Layers: [14, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.439856425732374, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.440154141187668, Hidden Layers: [8, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4402000337839127, Hidden Layers: [14, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4405997693538666, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4406083450317382, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.4411447689533232, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.4412494378089904, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.4418153017759323, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.4421028423309328, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4422174947261808, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.4424711096286775, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.4426380264759064, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.4428123002052307, Hidden Layers: [14, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.4437544797062873, Hidden Layers: [10, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.443949596643448, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.44395463347435, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4440274775028228, Hidden Layers: [12, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.444097840845585, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.444392555952072, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4444691263139249, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4448570900261402, Hidden Layers: [14, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.445134162902832, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4452842209339143, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.445313729405403, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4460951015353203, Hidden Layers: [12, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4463425070047378, Hidden Layers: [6, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4465025444030761, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.446749873638153, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.4470076189041137, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4474419031143189, Hidden Layers: [14, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4475651290267706, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.447571572780609, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4480432436466217, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4481541589498519, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.448527179777622, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.4491006284952164, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.449122373819351, Hidden Layers: [6, 16]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.4491505026817322, Hidden Layers: [14, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.449397428393364, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4494286894798278, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4494871840476988, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.4496923804283142, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.449744176864624, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4501372691243888, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4501505420207976, Hidden Layers: [14, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4504208684563635, Hidden Layers: [14, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4504877673387526, Hidden Layers: [4, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.451099687501788, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.4511441321372984, Hidden Layers: [6, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4513078689575196, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4513372943401337, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.4522238838672639, Hidden Layers: [4, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4527373555898666, Hidden Layers: [14, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.4529275152683259, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4530203363522887, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.4534035222530364, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4536720410585402, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4539482401013373, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.4542656168937682, Hidden Layers: [12, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4546473712921142, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4548569121062755, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.4548871250152586, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.455010360479355, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4555073590278624, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4560959310531616, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4561827063560486, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4566139028072356, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.456911626458168, Hidden Layers: [6, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4570552453398704, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.457326684951782, Hidden Layers: [12, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.457654752135277, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4580973595380784, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4587960109710694, Hidden Layers: [14, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.458910585194826, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4590758994817734, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.4591062173247338, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4601812422275544, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4608954668045044, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4611959837973116, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4612959787845612, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.4613877568244935, Hidden Layers: [14, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4618914723396301, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4621831991374492, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4622851313352583, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.462384913921356, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.4627495381832123, Hidden Layers: [14, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.4629014868736268, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4631351679563522, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4633462250232696, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4636597581207753, Hidden Layers: [14, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.4637993515729903, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.463882452249527, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4642929005622864, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4644216104075312, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4647246258258817, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4651694644093514, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.465279072880745, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4655372874736785, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4659411566257474, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4661257103681564, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4661581881940364, Hidden Layers: [14, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.4663045973181723, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.466325932741165, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.4665672109127044, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.4667618128657343, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4669915588498115, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4671219396591186, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4678195090293884, Hidden Layers: [12, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.4678708218038081, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.4679341015070677, Hidden Layers: [8, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4683241799473763, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4683350431919098, Hidden Layers: [6, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.468501843690872, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.4686041954755784, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.4687716946601868, Hidden Layers: [14, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.469004112482071, Hidden Layers: [14, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.4695570245981215, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4696022897958756, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.469834205508232, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.4701347068548203, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.4706445832252502, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4707231402397156, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.4710390374660491, Hidden Layers: [14, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.4710909113883972, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4715109829902648, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.4720929429531098, Hidden Layers: [14, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4723019901514054, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4725461230278014, Hidden Layers: [4, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.4727415370941164, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4728660807609557, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4734120745658874, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.4740092531442641, Hidden Layers: [8, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4741270051002502, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.474275733947754, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4753249781131743, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.4754662663936613, Hidden Layers: [6, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.475969217777252, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4760962934494017, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.476144519880414, Hidden Layers: [16, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4762025029063224, Hidden Layers: [14, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.4763009814471004, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4767250303030015, Hidden Layers: [14, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4767630041837692, Hidden Layers: [14, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.476808111667633, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.476876473426819, Hidden Layers: [14, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.476892344713211, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.4770312398672103, Hidden Layers: [14, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4772309170961377, Hidden Layers: [14, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.4777283895015718, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.477847488284111, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4779886871576309, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4786576628684998, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.4787994503974915, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.4788737260401248, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4789028928279877, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.4792503386735916, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.4792756605148316, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.4794279308319092, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.4799288318157195, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.4800875812768937, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.4802428305745123, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4805942014455795, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.4807306759655474, Hidden Layers: [14, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.480807308912277, Hidden Layers: [14, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.4808689299821853, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4811575696468353, Hidden Layers: [12, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4812486829161642, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.4812652707099914, Hidden Layers: [12, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4813525319099425, Hidden Layers: [6, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4818754659891127, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.4826995968818664, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.482801127433777, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.482943373978138, Hidden Layers: [6, 10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.4831846640110016, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4835413098931312, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.4842892513275145, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.4845762537717817, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.485069395661354, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.4851923959255218, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.4852456078529357, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.4853772745132445, Hidden Layers: [12, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.485910803079605, Hidden Layers: [14, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.4860647887587546, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.4869631366729734, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.4870971739292145, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4873120877742767, Hidden Layers: [8, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.4879212722778319, Hidden Layers: [8, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.4881995052695274, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.4882584527730942, Hidden Layers: [14, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.488267421722412, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.488311934649944, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.488746618539095, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.488984634041786, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4889871225357054, Hidden Layers: [14, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.4890272111296654, Hidden Layers: [12, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.4895776227712632, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4895888016223906, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4897382185459136, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.4897845589220524, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.4900380358695984, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.4900921599864958, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.4906008895337581, Hidden Layers: [14, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4907044175863267, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4908448525369167, Hidden Layers: [4, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.49088915219903, Hidden Layers: [4, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.4919388756752014, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.4922325882911682, Hidden Layers: [14, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.4922690115869046, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.4923912265002728, Hidden Layers: [12, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.4923984841108322, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4929342374801635, Hidden Layers: [4, 12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.4929517016410827, Hidden Layers: [14, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.4930353016257285, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.493532812654972, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.4935351238250731, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.4935428619384765, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.4937691271305085, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.494155466556549, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.4944718227386473, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.4947805511951446, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4948421076536178, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.495204614162445, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.495291511774063, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.4954968662261963, Hidden Layers: [14, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.4956667230129241, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.4957764327526093, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.4959711283445358, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.4959815547466278, Hidden Layers: [14, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.4960800170898438, Hidden Layers: [14, 10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.4964612604379652, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.4964879512786866, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.4970610224306582, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.4971264348030089, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.4971350864171982, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.4975742094218731, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.4979722678661347, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.4980430529117583, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.4980885628461837, Hidden Layers: [12, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.498643975019455, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.4989364476203917, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.4991245688796042, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.4994183871746063, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.4995138362646103, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.4995971113443374, Hidden Layers: [4, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.4997069239616394, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.499750470727682, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.499851671665907, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.4999164092540742, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.4999502782821654, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.500087587594986, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.500456394314766, Hidden Layers: [6, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5007871970534326, Hidden Layers: [12, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.5011292695999146, Hidden Layers: [14, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5011395947933195, Hidden Layers: [6, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5012647286653518, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.501524379968643, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.5016118527054787, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.502004602909088, Hidden Layers: [14, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5020666748285294, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.50241606426239, Hidden Layers: [14, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.5031532676219939, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5036670804023742, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.503720236301422, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5045835668146608, Hidden Layers: [4, 4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.504787932395935, Hidden Layers: [14, 8]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5049042735099794, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5049324542284013, Hidden Layers: [14, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.5050567955970764, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5051952838897704, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5055404663085938, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.5057408676147461, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.5058841094970703, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5059518699645995, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.5061230376027523, Hidden Layers: [14, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5061524138450622, Hidden Layers: [16, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5064925253987311, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5065143275260926, Hidden Layers: [16, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.506792202591896, Hidden Layers: [16, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5068464622497557, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.507130558222532, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.5072108428925275, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.50731849527359, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5075055212974546, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.5075225130319594, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.5075392980724573, Hidden Layers: [12, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5076407644748688, Hidden Layers: [6, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.508324701398611, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5088348582983016, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5089643285274505, Hidden Layers: [12, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.5096756566166878, Hidden Layers: [14, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.509845276236534, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5100231561660766, Hidden Layers: [4, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5101907598972322, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5103061364889143, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.5110931076705456, Hidden Layers: [16, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.51110337972641, Hidden Layers: [14, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5113538340330124, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5114100337028504, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.511416956782341, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.5115058646202086, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5122471735477447, Hidden Layers: [14, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.512315311282873, Hidden Layers: [14, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.5129951238632202, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5139331356287002, Hidden Layers: [14, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5144484505653382, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.5145435886383054, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5148746818900107, Hidden Layers: [14, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5153647736310958, Hidden Layers: [16, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.5155210123062133, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.5156268239021302, Hidden Layers: [14, 4]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.5160236001014709, Hidden Layers: [14, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5164628878831863, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5165960773825646, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5168158099651337, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5168563008904457, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.5170335814952849, Hidden Layers: [6, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.517641043663025, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.5176684856414795, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5183041379451752, Hidden Layers: [14, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.5186109170913695, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.5189730763435363, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.519034262061119, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.5195272491574285, Hidden Layers: [12, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5200535521507264, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.5201763973236084, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5204613540172578, Hidden Layers: [16, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5206385464668273, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.520719330072403, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5208396956920622, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5215993136167527, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.5217083790004253, Hidden Layers: [12, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.5220387058258056, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.522092010140419, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5222705006599426, Hidden Layers: [14, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.5223910586833953, Hidden Layers: [4, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.522684340238571, Hidden Layers: [14, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.522777806520462, Hidden Layers: [12, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5231809512376784, Hidden Layers: [6, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5233807862997053, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5234745786190032, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5236464619636536, Hidden Layers: [6, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.524057889342308, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5242240205407143, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.5244111554622648, Hidden Layers: [4, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5246812748908998, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.5250527744293212, Hidden Layers: [14, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.525231056213379, Hidden Layers: [12, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.525346432685852, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5253819200992584, Hidden Layers: [14, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5255212411880492, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5256811977028846, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.5262339369058608, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.526802677333355, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5270265519618988, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5273205861449242, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5274603471159935, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.527472234249115, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5279604229927064, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5281553239822387, Hidden Layers: [6, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5284676032066344, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.528754660487175, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5288232135772706, Hidden Layers: [14, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.5289431303739547, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5290359005928038, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5291513056159018, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5297304723262788, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5297442295253276, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.5301416087150574, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5307980851531027, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5308593052625656, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5308994680643082, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5311471388339997, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5312813259661198, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.5313348803520204, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.532194840595126, Hidden Layers: [14, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5322370147928595, Hidden Layers: [4, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5324755446910856, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5332800924777985, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.5333744900226591, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.53347171998024, Hidden Layers: [6, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.5336250097751616, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5340503261089324, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.5342887969017027, Hidden Layers: [4, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.534945899248123, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5356842700242996, Hidden Layers: [12, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.535782729834318, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5359099846929312, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.536663310289383, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.5370842606425286, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.537454183578491, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.5377355099320411, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.538382555603981, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.5384469244480132, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5385719866752623, Hidden Layers: [8, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.5386232321262359, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.5391005964279174, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5392390996217729, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.5399992316961288, Hidden Layers: [16, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5401766837239266, Hidden Layers: [12, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5406735167503356, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.540907790184021, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5412804276943206, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.541425089597702, Hidden Layers: [14, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.5415167098045348, Hidden Layers: [14, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.541915274143219, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5422400817871094, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.5426907973289488, Hidden Layers: [14, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.5429987549781798, Hidden Layers: [14, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.5431840152740477, Hidden Layers: [6, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5434700504541397, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5437105374336242, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.543982310771942, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.544145956993103, Hidden Layers: [4, 10]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5442402992248536, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5446757645010947, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5448535072803498, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.5450934141874313, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.545379231929779, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.5454605922698974, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5456209421157836, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5457930240035058, Hidden Layers: [12, 16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5460962698459624, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5468488916754723, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5470482021570207, Hidden Layers: [12, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.5470664844512938, Hidden Layers: [14, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5472202286720276, Hidden Layers: [8, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.5477503255605698, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5477801249027252, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.549125924706459, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.549153311729431, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5492777690887451, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.5493997485041617, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.5495794266462326, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5497839406728744, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.5498806822299958, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.5500478982925414, Hidden Layers: [16, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5507353949546814, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.550776258587837, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5511295483112335, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5512107179164887, Hidden Layers: [6, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.5512872848510741, Hidden Layers: [14, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.551310858130455, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5516432017087936, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5521598875522613, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5521987783908844, Hidden Layers: [16, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.5523703013658523, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5530194520950318, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5530784014463426, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5532853341102602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.5533569650650023, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5534903764724732, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5535690784454346, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5550355405807494, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.5552442226409913, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5555772542953492, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5556509986519813, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5564271912574767, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5564892768859864, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5566252875328064, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5574787139892579, Hidden Layers: [14, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.5575142384171485, Hidden Layers: [14, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.5576226354241371, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5576801914572715, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.557811529994011, Hidden Layers: [14, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.5584027945995331, Hidden Layers: [14, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.558823463320732, Hidden Layers: [4, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.5588529021143913, Hidden Layers: [12, 14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5592271324843168, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5593310761451722, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5593781995773317, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5595491428375243, Hidden Layers: [8, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.5598769785761832, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5604266286492348, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.561257521867752, Hidden Layers: [12, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.5616415657103062, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.56174245929718, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5618131995797158, Hidden Layers: [16, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.5618546382188796, Hidden Layers: [14, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.5621443689465522, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5622257307767868, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.5623150997459887, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.5624906466007231, Hidden Layers: [14, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.5631063163280488, Hidden Layers: [4, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5632397323846816, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5637934196591377, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.5639455409049987, Hidden Layers: [14, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5652460503578187, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.5655289278030395, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.565563789486885, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5657193840146064, Hidden Layers: [4, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.5660573499202726, Hidden Layers: [16, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.566160239458084, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.5662530720233918, Hidden Layers: [14, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.5673263580799102, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5673860807418822, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.567548280954361, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.5682341412305831, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.5687083512544633, Hidden Layers: [4, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.568933552503586, Hidden Layers: [14, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5697367310523986, Hidden Layers: [4, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.5699867442846298, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.570708061814308, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5707295604646205, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.5708311983048915, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.570857548713684, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.571161476135254, Hidden Layers: [14, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.5712229553461075, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.5720596016049384, Hidden Layers: [4, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.5722575620412826, Hidden Layers: [14, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5722798244953153, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5734360084533692, Hidden Layers: [10, 14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.5734783191680908, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.574022530078888, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.574155135512352, Hidden Layers: [4, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.5741650045514106, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.5741697624921798, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.5742400567177683, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.5742851682007313, Hidden Layers: [14, 14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.5743831634521483, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5744799152612685, Hidden Layers: [16, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.5747139990329742, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5747543740272523, Hidden Layers: [14, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.5749350206851958, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.575216560125351, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5758099720478058, Hidden Layers: [12, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5763756737709045, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.5765310690402985, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.5767676323652267, Hidden Layers: [8, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.5769590125083923, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.5769755735993385, Hidden Layers: [14, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.5771525580883026, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.577446422100067, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5775317288786173, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5777460248470305, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.5777576044797896, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5781004905700684, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.578176667973399, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.5785086210817099, Hidden Layers: [12, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.578631310224533, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.5787812844514846, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.5789630012512206, Hidden Layers: [14, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.579625639438629, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5796981792747975, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.5803554013371468, Hidden Layers: [12, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5804679021835326, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.58053626871109, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.5807987065315245, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5808343980312347, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.5809907112121582, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.581413322687149, Hidden Layers: [8, 12]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5816649533808231, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.581820364356041, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.5824971884489059, Hidden Layers: [14, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.582530400276184, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.5829287246465682, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.5833712086677552, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.5834887226223944, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.584121295928955, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.584499255180359, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.5845229820013045, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.5845437870025634, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.5848249942064285, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.5855218293070792, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5858064950108528, Hidden Layers: [14, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5859119296073914, Hidden Layers: [12, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.5859596894979475, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5861395146697759, Hidden Layers: [14, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.5863343358635902, Hidden Layers: [4, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.586723889708519, Hidden Layers: [14, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.587017528772354, Hidden Layers: [12, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5872633740901947, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.5873322860002517, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.5877507706284522, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.5877726927399636, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.587926486134529, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.5883457335829736, Hidden Layers: [6, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.5883658841848374, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5883739936351777, Hidden Layers: [12, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.5886087127029895, Hidden Layers: [14, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.5888580501079559, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.5888893518447875, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.5890283495783806, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5893586382865905, Hidden Layers: [14, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.5894613341093062, Hidden Layers: [14, 8]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.589477723836899, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5895458803176878, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.5898203552365302, Hidden Layers: [4, 8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.5903962001800536, Hidden Layers: [14, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.5905885577201844, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.5912233397960662, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.5917310684919357, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.5920956704616547, Hidden Layers: [6, 14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.5921920984983444, Hidden Layers: [12, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.5923999116420746, Hidden Layers: [16, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.5929044008255004, Hidden Layers: [14, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.593385265827179, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.59339104449749, Hidden Layers: [14, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.5939129235148428, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.5941739649176596, Hidden Layers: [14, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.594790741920471, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.5949699014425278, Hidden Layers: [8, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.5955701887607574, Hidden Layers: [8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.5957105785608292, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5960649252533912, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.5961232051849366, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.5961959153413772, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.596220617175102, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.5964675101637842, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.5966881394386292, Hidden Layers: [12, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.5966936510652303, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.5967248067855835, Hidden Layers: [14, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.596790479183197, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.5973533154129982, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.5976469163894653, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.5978069657385348, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.5979499683380127, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.597959104537964, Hidden Layers: [14, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.597967255115509, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.5981436939239502, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.5988126251101495, Hidden Layers: [10, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6000946879982947, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.60047317302227, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.601586233139038, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6016839895248414, Hidden Layers: [16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.601874183177948, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6025818049907685, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6027962136268616, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6028615951538085, Hidden Layers: [4, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6028986156582832, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6029678094983102, Hidden Layers: [10, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.603551948070526, Hidden Layers: [14, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.6037446573376655, Hidden Layers: [14, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6039721474647521, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6046424396336079, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.604734609335661, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6049288556575774, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6049754738807678, Hidden Layers: [4, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.6050685750246045, Hidden Layers: [6, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6052088755369187, Hidden Layers: [6, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6054216206073761, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.605578270614147, Hidden Layers: [14, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.6056024137735367, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6060994267463684, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6061894357204438, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.6062880322933197, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6065080538392067, Hidden Layers: [14, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.6066079870462417, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.6068544074892999, Hidden Layers: [4, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.6070415019989013, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.6075833768248557, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.6080554217100143, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.608540658712387, Hidden Layers: [14, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.6085808936357497, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.6088231086730957, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6088911123275758, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.608901499390602, Hidden Layers: [6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.6089219913482666, Hidden Layers: [8, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.609053906917572, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.609287428855896, Hidden Layers: [14, 16]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.6094139039516449, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6099451192319392, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6100181863307952, Hidden Layers: [14, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.610063910484314, Hidden Layers: [14, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.6102398262023925, Hidden Layers: [14, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6106128215789794, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.610857654094696, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6112872838974, Hidden Layers: [12, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6118724138140679, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.6121134419441223, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.612512287557125, Hidden Layers: [4, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.6125524759292602, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.6127665046453477, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6129511848688125, Hidden Layers: [16, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6130150854587555, Hidden Layers: [14, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.6132668242454529, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.613269971370697, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6134663076400755, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.613594752550125, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6138822841644287, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6142002556324004, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6143452756404877, Hidden Layers: [12, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6145376892089842, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.6149540083408354, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.6149865255355835, Hidden Layers: [4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.6155965671539305, Hidden Layers: [14, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.6156838135719298, Hidden Layers: [14, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.615867386817932, Hidden Layers: [14, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.6159905881881713, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.6161996845006943, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.6163668708801269, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.616696138858795, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.6167137876749038, Hidden Layers: [12, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.6169966654777526, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.617002248764038, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.617080687046051, Hidden Layers: [8, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.617394228339195, Hidden Layers: [10, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.6180333063602448, Hidden Layers: [10, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.6180418342351914, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.6180767915248873, Hidden Layers: [4, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.618256782054901, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6183372364044188, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.6183684871196746, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6190730199813843, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6192914947867394, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.6204386487603188, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.620681487083435, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6215388581752777, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6215849995613099, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6220894753932953, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6230900854468344, Hidden Layers: [14, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.6233161152005195, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6233383536338806, Hidden Layers: [14, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.6248542354106903, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6250582695007325, Hidden Layers: [14, 12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6251214444637299, Hidden Layers: [4, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.625308014512062, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6253980503082275, Hidden Layers: [14, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6254666239619255, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6258640397191049, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.625891238451004, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.6260187003612518, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.6261632130146026, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.626171737909317, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.6262701154351233, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6269377813339232, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.6271870419979095, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.6275010930299758, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.6290896342396735, Hidden Layers: [14, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6291972324848174, Hidden Layers: [16, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6296569752693177, Hidden Layers: [4, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6303403396606444, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6303736493587493, Hidden Layers: [14, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6305015790462494, Hidden Layers: [4, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6308828384280205, Hidden Layers: [8, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6309812517166136, Hidden Layers: [12, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.631142036676407, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.6314718604683875, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.632968135356903, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.6330769941806793, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.6331414886415003, Hidden Layers: [14, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6332966375350952, Hidden Layers: [14, 4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6351746678352357, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6359140698909758, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.63598140335083, Hidden Layers: [6, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.6360759840011596, Hidden Layers: [14, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.636107897758484, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6364457309246063, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.636586892604828, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.6368995577096939, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6369876623153687, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6370614529848098, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.6372363731861115, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6373905453681945, Hidden Layers: [12, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.637423395037651, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.637818554162979, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.6378771352767945, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6382166981697082, Hidden Layers: [12, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.638349692583084, Hidden Layers: [4, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6385496586561203, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.6388198778629302, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.639149287700653, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6393402833938597, Hidden Layers: [12, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6394729126095773, Hidden Layers: [16, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6397341072559357, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6397615313529967, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.640686516523361, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.640715942144394, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6417351350784302, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6417883336544037, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.641940794944763, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.64206120967865, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.6421240419149399, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.6422480301856992, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.6434943959712982, Hidden Layers: [16, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6435054976940155, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.6438249543309211, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.6442171589136123, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.6447685286998748, Hidden Layers: [10, 16]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.6450113848447798, Hidden Layers: [6, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6452662916183471, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.6460787181854246, Hidden Layers: [14, 14]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6462226269766689, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.6464651541709898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6465909764766693, Hidden Layers: [14, 4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.6472749561071396, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6478188829421996, Hidden Layers: [12, 14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.6479135484695433, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.6481681988239287, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.648273763179779, Hidden Layers: [14, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6482768373489378, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6488916521072388, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6491548078060148, Hidden Layers: [14, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6492088422775268, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.6494706362485885, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.6495634571313857, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6495755463838577, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.6498304426670074, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.649846633076668, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.649953810930252, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6500540823340415, Hidden Layers: [4, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.6501185879707336, Hidden Layers: [6, 10]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.650158830165863, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6518700302839278, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.652088304042816, Hidden Layers: [10, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.6521053105592727, Hidden Layers: [6, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.6524493576288222, Hidden Layers: [14, 6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.652570258140564, Hidden Layers: [8, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.6526816220283507, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.6526885882019997, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.652726686000824, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.653188872396946, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6533589408397673, Hidden Layers: [8, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6535077021121978, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6540178776383399, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.6540221080780029, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6545829684734343, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.6549458341598509, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.6553491071462632, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.6556576907634735, Hidden Layers: [14, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.655961772918701, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.655973158955574, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.65614213514328, Hidden Layers: [10, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6562079713344573, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6563528583049774, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.6568896032869815, Hidden Layers: [14, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6569371025264263, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.657737931728363, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.658493208885193, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.659054751753807, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6590555161237717, Hidden Layers: [12, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.65910815179348, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.6596220955848693, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.659724180459976, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.66015745139122, Hidden Layers: [14, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6609228372573852, Hidden Layers: [12, 14]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.6610590831041336, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6612754479050635, Hidden Layers: [4, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.662747879385948, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6634241849184037, Hidden Layers: [14, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.6638370203971864, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.6638986155986786, Hidden Layers: [14, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6641271338462829, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.6641634151935576, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.6643911854028701, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.6645798802971838, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.6646652817726135, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6652281806468963, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6652691112756728, Hidden Layers: [14, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6661522328853606, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.666385734260082, Hidden Layers: [12, 16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.6665068343877791, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.6667497382164, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.666830281972885, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.6670170545578002, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.667265977025032, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.6676052272319795, Hidden Layers: [16, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.667952594280243, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.6682733998298644, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6688043848276137, Hidden Layers: [14, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.668950484752655, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.6695407526493071, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.669693878352642, Hidden Layers: [12, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.6699607685804367, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6703035757541655, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6703652497977017, Hidden Layers: [14, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.6704502121210099, Hidden Layers: [6, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6704627559185028, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6707015500068665, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6715821504592896, Hidden Layers: [4, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6718625054359435, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.6726088166236877, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.672736692905426, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6739693284630774, Hidden Layers: [14, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.6741028406322003, Hidden Layers: [14, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.6741280741989613, Hidden Layers: [14, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.6745841012001037, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.67474422454834, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.6747666358947755, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.6753859193325042, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.6757938042879104, Hidden Layers: [14, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.67638665959239, Hidden Layers: [12, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.6766718739569186, Hidden Layers: [8, 4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6771184220910071, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6773063097000123, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.6783748769462108, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.6789251744747162, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.6794592008590699, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.6799230308532713, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6800146684646606, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.6808940515518187, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.681002618432045, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.6818055973052979, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6823516504764555, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6826151423156261, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.6828778789043426, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6831728920936584, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.683435659408569, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.6841323599219322, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.684393870830536, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.6850620613098144, Hidden Layers: [6, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.6850718200206756, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6851101908683777, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.685874329380691, Hidden Layers: [14, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.6859115154147148, Hidden Layers: [14, 16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.68602172421664, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.6861732893288135, Hidden Layers: [10, 10]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.686312511563301, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.6864166741371154, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.6869608566761016, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.6872478783130647, Hidden Layers: [8, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.687251471042633, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.6879114523530006, Hidden Layers: [14, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.688024725317955, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6880490038394929, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.6882636785507201, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.6882670879364015, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.6883925318717956, Hidden Layers: [12, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.688455948293209, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.6888286828994752, Hidden Layers: [12, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.6890758917331694, Hidden Layers: [14, 10]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.6892227978706358, Hidden Layers: [4, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.6893699929714203, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.6893859997987746, Hidden Layers: [8, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.6895153313875197, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.6899841222763061, Hidden Layers: [12, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.6907401442527772, Hidden Layers: [10, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.6908744305968284, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.6909005150794982, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.6910286680459976, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.6913443308323621, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6919383273124695, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.6919715330004692, Hidden Layers: [14, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.692380005121231, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.6929311990737914, Hidden Layers: [12, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6929773002862931, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.69306907636486, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.6930847840309142, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.693127366900444, Hidden Layers: [16, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.6939195215702056, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.694635058939457, Hidden Layers: [14, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.6946387724876402, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.6949315131306648, Hidden Layers: [12, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.6950820374488829, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.6954082061648368, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.6956776916980743, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.6965408549308776, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.6968272387981416, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.698545073032379, Hidden Layers: [14, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.6989871129989624, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.6999855488538742, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7005616680383682, Hidden Layers: [8, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7012091369628906, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7018252894878387, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7022667751312255, Hidden Layers: [6, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.7024972498416902, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7028964655399321, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.7030796751976012, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.703391656398773, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7047621414661407, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.7055030322074891, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7063772532939911, Hidden Layers: [12, 6]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.7068614826202393, Hidden Layers: [4, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.707135702729225, Hidden Layers: [12, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7073437405675649, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.7083117232322693, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7088761613368988, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.709084141254425, Hidden Layers: [12, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7091852992773056, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.7093651401996612, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.709385883808136, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.709457209765911, Hidden Layers: [4, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7095594987869263, Hidden Layers: [14, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.7100847721099854, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7101020709276198, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.710202185988426, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7103703201413154, Hidden Layers: [14, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7104276881217957, Hidden Layers: [10, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7112806544303893, Hidden Layers: [4, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.7114568427801131, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7120026067495346, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7122117028236388, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.7125446498394012, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7126088634729384, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7126224145889282, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7130378901958465, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7133623480796814, Hidden Layers: [6, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.7134972870349885, Hidden Layers: [4, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7135540217757224, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.7136183590888976, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7139221761226655, Hidden Layers: [12, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.7139260132312775, Hidden Layers: [14, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7139797315597534, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.7141844660043717, Hidden Layers: [6, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.7145926792621613, Hidden Layers: [14, 6]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7154089142680167, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7154318228363992, Hidden Layers: [4, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7156692714691162, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.7156890586614608, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.716011992841959, Hidden Layers: [4, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.716227039694786, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.7162760317325592, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.716319939494133, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7163412824869155, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.7176924601793289, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.7177523807287216, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.7179230451583862, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7180974708795547, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.7185775983333584, Hidden Layers: [14, 10]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.7186684252023696, Hidden Layers: [12, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.7187690216898919, Hidden Layers: [4, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7190667424201966, Hidden Layers: [4, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7209585849046707, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7214854776859283, Hidden Layers: [12, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.7218889718055723, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.7219003841876983, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.7219190076589583, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.722057311296463, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7223270909786224, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.7224907875061035, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.7229439437389373, Hidden Layers: [14, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7230394825935362, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7232277603149413, Hidden Layers: [14, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7239278957247735, Hidden Layers: [4, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7244097873568536, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7245009038448333, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.724538342654705, Hidden Layers: [6, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7250207290649413, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7251858174800874, Hidden Layers: [12, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.7252617985457182, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.726160048007965, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7263555154204369, Hidden Layers: [14, 6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.726392878651619, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7268250913619994, Hidden Layers: [12, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.7269628422260284, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.726977269411087, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.7272652745246888, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.7272713334560392, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7287420654594896, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.7293228939771652, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7297257230281828, Hidden Layers: [14, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7298509061336518, Hidden Layers: [8, 8]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.7302283601760862, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7303747057914733, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7307036638259887, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7310086851119995, Hidden Layers: [12, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7313142672777175, Hidden Layers: [16, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.7314121589660645, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.7319075167179108, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.7319412723779677, Hidden Layers: [12, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.732295435667038, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.732524910569191, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7325335249900817, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7325358912944793, Hidden Layers: [4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.7327096436023712, Hidden Layers: [14, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.733296032309532, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.7339372055530546, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.7339461714029312, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.7340780571699141, Hidden Layers: [14, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.7343085520565509, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7349163608551024, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.735089676141739, Hidden Layers: [4, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.735130075365305, Hidden Layers: [4, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.735245285987854, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7356451585143806, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.736058133840561, Hidden Layers: [14, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.7365369663238526, Hidden Layers: [14, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.736712232351303, Hidden Layers: [10, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7377657920718192, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7381709396839142, Hidden Layers: [14, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7384457275867462, Hidden Layers: [14, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7388700738549232, Hidden Layers: [4, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.7392203407287596, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.7397438303232193, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.7400204854011534, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.740133303463459, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.7401804089546205, Hidden Layers: [4, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7402725204825402, Hidden Layers: [12, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7406356678009032, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7407579469680787, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.741133745074272, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.741139496922493, Hidden Layers: [6, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.7423833445310593, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.742418247461319, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.7429313764572143, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7430600957870481, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.743184237241745, Hidden Layers: [12, 8]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.7432760822251439, Hidden Layers: [14, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.7438256413340572, Hidden Layers: [10, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.7441899495124815, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.7450364515781402, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7452405423521995, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.7453706935644149, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.7455829963684082, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.7459279820919036, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.7463804125785827, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.746958520323038, Hidden Layers: [6, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.7471265659332276, Hidden Layers: [14, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.7474043521881104, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.7474734053611756, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7479827032089232, Hidden Layers: [4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7479905771017072, Hidden Layers: [14, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.7484186097979546, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.7485512614250183, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.748627375125885, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.749409262895584, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.7504271820783615, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.7510349155068397, Hidden Layers: [12, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7511304657906295, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7512264298200606, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7515728995800017, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7518246591091156, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.7520624340772628, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7525388585329054, Hidden Layers: [6, 16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.752799540758133, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.7529126749038695, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7535233736038207, Hidden Layers: [6, 14]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.7535314291715622, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7537410244941711, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.7537784278392792, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7538860545158386, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.7539441004991532, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7547780485153197, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.7549011439681053, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7549213156700134, Hidden Layers: [4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7550312072634697, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7550443947315215, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7556672514677047, Hidden Layers: [10, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.756304015636444, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7564259592294693, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.756563608407974, Hidden Layers: [12, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.756698729276657, Hidden Layers: [14, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7568931684494018, Hidden Layers: [12, 16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7569941639900208, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.7570370048880577, Hidden Layers: [14, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7571703345775602, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.7580705286264418, Hidden Layers: [10, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 1.7582494781017304, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.7583915249109268, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.7586350589990616, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.758692416667938, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7594976902008057, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.7595305161476134, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7598211903572083, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7601345896720886, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7628629963696003, Hidden Layers: [10, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.7640695543289184, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.7644579694271088, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7645261989831922, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7649804100990294, Hidden Layers: [4, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.7656977506279943, Hidden Layers: [10, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.7658147633075714, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.7658924241065974, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.7660500019788743, Hidden Layers: [16, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7662122145891188, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7663642048835755, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.7667497992515564, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7673211873769759, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.7684044466018676, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7684059948921202, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7685283899307251, Hidden Layers: [10, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.76896444606781, Hidden Layers: [4, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.768970169186592, Hidden Layers: [8, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7692087815999984, Hidden Layers: [12, 8]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.769347165584564, Hidden Layers: [14, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.7695420131683348, Hidden Layers: [14, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7696022171974182, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.7696832486093044, Hidden Layers: [4, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.7698489472866057, Hidden Layers: [16, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.7698560345172882, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.7698858681917191, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.770346012711525, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.7704019293785094, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.7714637823402881, Hidden Layers: [14, 6]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.7715821774601934, Hidden Layers: [12, 16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.7722574934959412, Hidden Layers: [8, 10]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.7725176095962525, Hidden Layers: [12, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.7734686793088912, Hidden Layers: [12, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.7751446858048439, Hidden Layers: [10, 6]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7754646204411983, Hidden Layers: [4, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.7756221570074557, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.775890165567398, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.776221640586853, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.776850337266922, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7772946999073027, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.7780107603073119, Hidden Layers: [4, 12]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.778512708902359, Hidden Layers: [14, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.7787193522453308, Hidden Layers: [12, 14]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.7787774614989758, Hidden Layers: [10, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7788118124008179, Hidden Layers: [12, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7798802748918532, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.780283318012953, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7803962023258209, Hidden Layers: [6, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.7808013291358946, Hidden Layers: [14, 10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.7810661047697067, Hidden Layers: [4, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.7815556988716126, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.782110451221466, Hidden Layers: [12, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.782600829064846, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.7826528208255765, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.7826811254024506, Hidden Layers: [12, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.7828125361204148, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7832651376724242, Hidden Layers: [10, 12]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.7843420405387878, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.7843876332044601, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7845523595809936, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7853631228804587, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.7855927095413207, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.7857576049864292, Hidden Layers: [14, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.7858603703975677, Hidden Layers: [12, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7867181748747825, Hidden Layers: [12, 16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.7870150417089463, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.7878924131393432, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.7878951699733734, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.7881029949188236, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.7883336112499237, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.7886042892932892, Hidden Layers: [6, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.788817925930023, Hidden Layers: [14, 12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7896199986934662, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.7898313686251641, Hidden Layers: [4, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.7898580418825147, Hidden Layers: [14, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.7901215612888337, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.790847204685211, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.791159351348877, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.7913545773029327, Hidden Layers: [8, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.7923191585242748, Hidden Layers: [10, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.7926916346549988, Hidden Layers: [14, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.7933157370090484, Hidden Layers: [6, 8]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.7934130296707154, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.7934389099478723, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.794656460046768, Hidden Layers: [8, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.7948639497756957, Hidden Layers: [8, 12]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.7950314640998841, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7952616260051726, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.7956661007404329, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.7965043366551399, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.7968890130519868, Hidden Layers: [12, 16]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.7969268172979356, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.7978993713855744, Hidden Layers: [4, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.7979341865181921, Hidden Layers: [4, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.7987716064453125, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.7995828227996824, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.800223227024078, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.8003283069133758, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.8008347842693329, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.8010922849178315, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.8026392117738723, Hidden Layers: [14, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.802810882091522, Hidden Layers: [14, 14]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.803652210712433, Hidden Layers: [6, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.8036522538661957, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8038252727389334, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8049427360296249, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8052691490650177, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8053093898296357, Hidden Layers: [14, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.805625283718109, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8058169708251952, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8060016632080078, Hidden Layers: [8]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8065179065465926, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8065878168940543, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.807133409500122, Hidden Layers: [8, 6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.808211790204048, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8085465685129165, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.809084980249405, Hidden Layers: [10, 6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.8092561933994293, Hidden Layers: [14, 12]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.8100489139556886, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8101681218147276, Hidden Layers: [8, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8103778049945831, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.810582959651947, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.8106041059494018, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8106284245848656, Hidden Layers: [14, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.8114406795501707, Hidden Layers: [14, 6]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.8119950459003449, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.813783778309822, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8143767313957215, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.8157711625695228, Hidden Layers: [4, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.815997906088829, Hidden Layers: [8, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.8167431371212004, Hidden Layers: [12, 16]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.8173689424991608, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.817462757229805, Hidden Layers: [12, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.81791153717041, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.8184639797210693, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8185790256261825, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8189500913619994, Hidden Layers: [10, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.819294129371643, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.8194591376781464, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8198575407266617, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.8202139214277266, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8205865339040757, Hidden Layers: [8, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.8208027110099791, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8220674626529216, Hidden Layers: [14, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.822511725187302, Hidden Layers: [14, 8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.8229052529335021, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.8231517612934112, Hidden Layers: [14, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.823390348434448, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8235276312828064, Hidden Layers: [6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.823876106351614, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8239571676254271, Hidden Layers: [14, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.82455791836977, Hidden Layers: [4, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.824745754957199, Hidden Layers: [16, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.8247808680534363, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8248538494706152, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.825089852809906, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 3
MAE: 1.8261590690612792, Hidden Layers: [14, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8268070788383484, Hidden Layers: [16, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.8277069301605224, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8284483242034912, Hidden Layers: [6]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.8287240147590638, Hidden Layers: [4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.82917581653595, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.830068975687027, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.8302668780088425, Hidden Layers: [14, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.8304269999861718, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8305879549980162, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.8310551524162293, Hidden Layers: [12, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.8312065215706823, Hidden Layers: [8, 6]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.831299501657486, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.831443895459175, Hidden Layers: [12, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8319363639354704, Hidden Layers: [12, 14]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.8322524297237397, Hidden Layers: [14, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.8326948791742326, Hidden Layers: [4, 10]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.8328437447547912, Hidden Layers: [4, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.8328442410230636, Hidden Layers: [6, 4]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8331368060111999, Hidden Layers: [12, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.833171878069639, Hidden Layers: [14, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8343690142631535, Hidden Layers: [12, 6]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.8347806572914123, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.835990902841091, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8365147084593771, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.8366626846790315, Hidden Layers: [14, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8376560673713684, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.8385679125785828, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.8391573116779327, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.8391670510768894, Hidden Layers: [10, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.8395919964313507, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.8397361130714416, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.8399855732917785, Hidden Layers: [14, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.8401006984710695, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8402152673006058, Hidden Layers: [10, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.8406830847859381, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.840716791629791, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.840829442501068, Hidden Layers: [4, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.8408745527267456, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8410793514847754, Hidden Layers: [8, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.8418196067810058, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8419162817299366, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.84203844666481, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.842875154495239, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.8429850846529008, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.8430962954312562, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.8433706612586973, Hidden Layers: [10, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.843495047211647, Hidden Layers: [6, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.843511392980814, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.844065702021122, Hidden Layers: [6, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.8443952932953835, Hidden Layers: [4, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8446020231246947, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.845271998643875, Hidden Layers: [8, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.8454021483659744, Hidden Layers: [10, 12]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.8454953999519348, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.8455752835273742, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8455784142017364, Hidden Layers: [6, 16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.8461190090179442, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.8462807655334472, Hidden Layers: [14, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.8467881398200992, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8474394456148147, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.8474742875099182, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.847792100906372, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.8481660813093186, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.848219861268997, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.8482250349521636, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.848570509314537, Hidden Layers: [14, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.848746150791645, Hidden Layers: [16, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.8490148580074313, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.849183492541313, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.8491930175423623, Hidden Layers: [4, 14]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.8494486767053602, Hidden Layers: [14, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.849710355758667, Hidden Layers: [14, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.8500335142612456, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.85025724619627, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.8517083868980406, Hidden Layers: [16, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.8521542356014251, Hidden Layers: [14, 4]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.853067138969898, Hidden Layers: [12, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 1.8539777965545654, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.854077535867691, Hidden Layers: [14, 12]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.8547063797712326, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8550118267536164, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.8550261214971542, Hidden Layers: [4, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.8555288121700286, Hidden Layers: [4, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8559451431632041, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.8559660755395888, Hidden Layers: [14, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.8565638170242313, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8565674231052398, Hidden Layers: [10, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.856734118670225, Hidden Layers: [10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.8571065683364865, Hidden Layers: [8, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.858044574469328, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8590237263441085, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.8603372291326523, Hidden Layers: [14, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.860503324985504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.8606488258242606, Hidden Layers: [14, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.86068446777761, Hidden Layers: [10, 6]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.8607090876102448, Hidden Layers: [6, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8613657430410384, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.8616373032331466, Hidden Layers: [14, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.8617945508956908, Hidden Layers: [6, 10]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8627278178930282, Hidden Layers: [12, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.8631911352872847, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.8658373714089393, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.8658835619688035, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.8659023777246475, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.86623490190506, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.866550542473793, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8665952370166778, Hidden Layers: [14, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.8668707489967347, Hidden Layers: [14, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.8668766990900039, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8671984914541244, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8677148163318633, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 5
MAE: 1.8677206950187686, Hidden Layers: [14, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8677667833864688, Hidden Layers: [12, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.8682186007499695, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.868643239200115, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.8694670648574827, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.87064488530159, Hidden Layers: [14, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.8707181886434554, Hidden Layers: [14, 12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 1.8712605714797974, Hidden Layers: [10, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.8715872623622416, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.8716534779071807, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.8721141860485075, Hidden Layers: [8, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8724812292158604, Hidden Layers: [14, 4]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.8730671093463898, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.8736142352819443, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8746617496013642, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.8749783651828764, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.875581979751587, Hidden Layers: [14, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.8759938330650328, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.8770955029726024, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.8771304138600826, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.8773270832300184, Hidden Layers: [14, 4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.87760897731781, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8782722890377044, Hidden Layers: [12, 4]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.8790963859558105, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8791436882019041, Hidden Layers: [4]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.8794854626655577, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.879826320707798, Hidden Layers: [4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 1.8798391968607902, Hidden Layers: [8, 4]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.8799741716384886, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.8801732425689697, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.8804706068038939, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8808852375149727, Hidden Layers: [14, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.8811773941516876, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8812625662088394, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.8813213901519774, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.8820032284259796, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.8823429703712464, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.8826792851686478, Hidden Layers: [14, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.8838593558073042, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8841309876441954, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.8841468945741653, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.8843070566654205, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.8844422221183776, Hidden Layers: [4, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.8844440221786498, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 1.8847623512744902, Hidden Layers: [8, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.8847812221050262, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8856355652809142, Hidden Layers: [8, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.8856610432863234, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.8860287280082701, Hidden Layers: [14, 12]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.8864386873245238, Hidden Layers: [14, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.887393186300993, Hidden Layers: [16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.8878778967857361, Hidden Layers: [12]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.8882436275482177, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.888300313234329, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.888327965259552, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.8885407820940017, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.8887332891225814, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.8890158014297485, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.890398328065872, Hidden Layers: [14, 10]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.890647265434265, Hidden Layers: [14, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.890837099134922, Hidden Layers: [14, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.8911680475473402, Hidden Layers: [10, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.8921154890060425, Hidden Layers: [4, 14]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.8929673448204993, Hidden Layers: [10, 10]; Learning Rate: 0.001; Batch Size: 1
MAE: 1.8931716807186603, Hidden Layers: [8, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.893181990146637, Hidden Layers: [12, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.8938237249851226, Hidden Layers: [14, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.893824957370758, Hidden Layers: [12, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.893958365917206, Hidden Layers: [4, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.8963519916534426, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.8964144118726254, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.8971855373382567, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.8974021569490431, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.8984763860702514, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.8985360376536846, Hidden Layers: [6, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.8985876992940907, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 1.898881264090538, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.8993401646614074, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.899719560623169, Hidden Layers: [14, 8]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.9000274062156677, Hidden Layers: [4, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.9002471178770066, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.9006402597427368, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9013921097517013, Hidden Layers: [14, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.9017922565937042, Hidden Layers: [12, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.9028469221591948, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9029434819221493, Hidden Layers: [14, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9032050118446349, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.903415949702263, Hidden Layers: [12, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.9034287571907043, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.903433437824249, Hidden Layers: [12, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.903832612991333, Hidden Layers: [4, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9046104744672774, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 1.9049101696014403, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9049427704811095, Hidden Layers: [6, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9051041648387907, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.905371485710144, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9059335265159607, Hidden Layers: [4, 12]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.905943088293076, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 1.9061113064289092, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.9063168935477735, Hidden Layers: [6, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9075096354484558, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.9081677155494687, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 1.9083795801401138, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9087708072662353, Hidden Layers: [12, 14]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.908993689775467, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.9091907099485397, Hidden Layers: [14, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.9092687207460404, Hidden Layers: [14, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.9093120262622834, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.90933727478981, Hidden Layers: [4, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9104237303733824, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 2
MAE: 1.9105084453374146, Hidden Layers: [4, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.9108876662254333, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9113574192523957, Hidden Layers: [6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9117048387527464, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.9123947501182557, Hidden Layers: [12, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.9124116510152818, Hidden Layers: [10, 12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.912631102323532, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.912921197772026, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.913114196062088, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9145212143659591, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 1.9148906755447388, Hidden Layers: [16, 4]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.9149996566772465, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9154980707168576, Hidden Layers: [8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.915706233739853, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 1.9159319460392, Hidden Layers: [6, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 1.9161082954406736, Hidden Layers: [8, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.9162866861224175, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 1.9169115905761713, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.9172073125839233, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9172749161720275, Hidden Layers: [6, 8]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9180502713322638, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.9188518986701968, Hidden Layers: [14, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9190798655748367, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9191463600695133, Hidden Layers: [6, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9202291474342346, Hidden Layers: [14, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 1.9207148433327674, Hidden Layers: [14, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.9214809358119964, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.9216798859834672, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.922565697193146, Hidden Layers: [8, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 1.9226104006767273, Hidden Layers: [14, 4]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9246784592047335, Hidden Layers: [14, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.9250829823911189, Hidden Layers: [10, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.9250909745693208, Hidden Layers: [4, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9253533780574799, Hidden Layers: [10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.9254102185964583, Hidden Layers: [14, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.9258907408714294, Hidden Layers: [12, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.9262041405439376, Hidden Layers: [12, 14]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.9264496564865112, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.9268941955566405, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.9269641075134278, Hidden Layers: [6]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9276210713386537, Hidden Layers: [14, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9276924939155577, Hidden Layers: [14, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9286438629627227, Hidden Layers: [12, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.928799307346344, Hidden Layers: [8, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.9288315148353576, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9289744840860366, Hidden Layers: [4, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.9300405592918395, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.9301381633281707, Hidden Layers: [12, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9302693367004395, Hidden Layers: [12, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9311276302337645, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.9314128294438124, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.9322919920682906, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.932523000240326, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9326653764247894, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9328050584197043, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9329437346458433, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9331853270530701, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9334777668714522, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9341894731521605, Hidden Layers: [14, 8]; Learning Rate: 0.006; Batch Size: 2
MAE: 1.9342745319604873, Hidden Layers: [6, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.9344578104019168, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9345938473939897, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 2
MAE: 1.9349317388534548, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9350599616765976, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.9352191061973572, Hidden Layers: [14, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.9356156527996062, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 3
MAE: 1.9356876879930496, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 1.9366389416754246, Hidden Layers: [4, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.9367585525512694, Hidden Layers: [12, 6]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9367867797613143, Hidden Layers: [10, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9368676171302794, Hidden Layers: [14, 14]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.937361756324768, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 4
MAE: 1.9376448541879654, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9380147397518157, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.938294498682022, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 1.9383493721485139, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.938847544968128, Hidden Layers: [12, 14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.938849555015564, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9391933490633964, Hidden Layers: [12, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 1.9392089978456497, Hidden Layers: [14, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 1.9395577118396758, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.940157425403595, Hidden Layers: [14, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.940847913980484, Hidden Layers: [14, 10]; Learning Rate: 0.001; Batch Size: 3
MAE: 1.9409704045057297, Hidden Layers: [6, 6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.94138206410408, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9421065837740898, Hidden Layers: [6, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.943249243557453, Hidden Layers: [4, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.944271408081055, Hidden Layers: [14, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 1.9443202018737793, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.9444313392639159, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9449637949466705, Hidden Layers: [12, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.9463834375739097, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 1.9469791264533995, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.9491699311733242, Hidden Layers: [10, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 1.950475431293249, Hidden Layers: [10, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9505077674984932, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.9516332746148108, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 1.9517008786201473, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9523427203893662, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 1.952625010967255, Hidden Layers: [14, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9526316092014315, Hidden Layers: [12, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 1.9534135460853577, Hidden Layers: [12, 14]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9538272678852082, Hidden Layers: [4, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9544293746948243, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.95460830783844, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 1.955149308651686, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.9566843718886375, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 2
MAE: 1.9572237179279326, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.9572651371955871, Hidden Layers: [14, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 1.9573579061031339, Hidden Layers: [6, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.9577749047279358, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9585447118282318, Hidden Layers: [14, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.9586571335792542, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 1.9586886644363404, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9588118568658832, Hidden Layers: [10, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9596466200351714, Hidden Layers: [16]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.961107091665268, Hidden Layers: [14, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9618056178092957, Hidden Layers: [8, 8]; Learning Rate: 0.0015; Batch Size: 2
MAE: 1.9624540791511536, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9631543610841036, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.9634031847715376, Hidden Layers: [8, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9640279711484907, Hidden Layers: [16, 4]; Learning Rate: 0.002; Batch Size: 2
MAE: 1.9653417469859122, Hidden Layers: [8, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9665032938122748, Hidden Layers: [6, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.966683383464813, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.9667405233979225, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.9671439752578734, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 1.9674201624393461, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.9675153195858002, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.967553484916687, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 1.9675712213516239, Hidden Layers: [8, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 1.96797962641716, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9680114315748216, Hidden Layers: [14, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 1.9688195706009863, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 1.9699249312877654, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.9700331091880798, Hidden Layers: [6, 12]; Learning Rate: 0.001; Batch Size: 5
MAE: 1.9701451659202576, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 3
MAE: 1.9702601716518402, Hidden Layers: [6, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 1.9711998686790466, Hidden Layers: [8, 6]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.9712628083229067, Hidden Layers: [12, 12]; Learning Rate: 0.002; Batch Size: 4
MAE: 1.9718848139643668, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.972036017656326, Hidden Layers: [12, 12]; Learning Rate: 0.008; Batch Size: 5
MAE: 1.9722972617149352, Hidden Layers: [14, 14]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9729253516197205, Hidden Layers: [8, 8]; Learning Rate: 0.0075; Batch Size: 5
MAE: 1.9730912506580354, Hidden Layers: [8, 10]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9730967149734497, Hidden Layers: [6, 10]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 1.9733081885278225, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.9736441643238067, Hidden Layers: [4, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 1.9745340392589568, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 1.974611924648285, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.974722777366638, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.9751867965459824, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 2
MAE: 1.975356815934181, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 1.9757091790437697, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 1.976364533662796, Hidden Layers: [12, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.9763814397156239, Hidden Layers: [14, 8]; Learning Rate: 0.0015; Batch Size: 5
MAE: 1.9777335555553435, Hidden Layers: [10, 8]; Learning Rate: 0.002; Batch Size: 5
MAE: 1.9779532909393311, Hidden Layers: [14, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.9786889151334761, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 1.9786947399377823, Hidden Layers: [8, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9798052716255186, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 4
MAE: 1.9798383908271788, Hidden Layers: [12, 16]; Learning Rate: 0.003; Batch Size: 3
MAE: 1.980649572610855, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.9810063333511352, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 3
MAE: 1.9822281531989574, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 1.9829306818395853, Hidden Layers: [14, 10]; Learning Rate: 0.004; Batch Size: 3
MAE: 1.9830652475357056, Hidden Layers: [14, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 1.9831476390361786, Hidden Layers: [8, 8]; Learning Rate: 0.004; Batch Size: 1
MAE: 1.984850284576416, Hidden Layers: [6, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.9854644731283186, Hidden Layers: [14, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 1.9856613577008246, Hidden Layers: [12, 8]; Learning Rate: 0.001; Batch Size: 2
MAE: 1.9875781551599503, Hidden Layers: [4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 1.9876585111618041, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 1.9877824425697326, Hidden Layers: [12, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 1.988246449947357, Hidden Layers: [10, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 1.9884053320884703, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 1.9884292230606078, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 3
MAE: 1.9885560826063156, Hidden Layers: [10, 14]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.9896997374743222, Hidden Layers: [8, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 1.990763525724411, Hidden Layers: [14, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 1.990847741127014, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 1.9910122649744153, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 2
MAE: 1.9914798737764356, Hidden Layers: [12, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 1.9915654287338256, Hidden Layers: [14, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 1.9917332785129545, Hidden Layers: [6, 14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 1.9922024935483933, Hidden Layers: [8, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.9922114973068237, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 3
MAE: 1.9926495358943939, Hidden Layers: [14, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 1.993289938569069, Hidden Layers: [10, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 1.9939743446111677, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9941370654851198, Hidden Layers: [12, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 1.9951442460194229, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 1.9955444917678833, Hidden Layers: [4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.9956910174191003, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 1.995696872472763, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 1.995809498786926, Hidden Layers: [10, 8]; Learning Rate: 0.004; Batch Size: 5
MAE: 1.9960896492004394, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 1.9961109118461606, Hidden Layers: [14, 16]; Learning Rate: 0.002; Batch Size: 1
MAE: 1.9967879698276518, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.997348565235734, Hidden Layers: [16, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 1.9974606842994689, Hidden Layers: [14, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 1.9975146577358245, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 1.9975791783332824, Hidden Layers: [12, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 1.9978902444839477, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 1.998582165375352, Hidden Layers: [6, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 1.9990154728889469, Hidden Layers: [10, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 1.9995101351886988, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 1.9999006360769271, Hidden Layers: [14, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.000362291991711, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0007003605365754, Hidden Layers: [14, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.000810662269592, Hidden Layers: [14, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.0010712698698043, Hidden Layers: [8, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.001096342563629, Hidden Layers: [4, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.001501278758049, Hidden Layers: [14, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.0015033580362798, Hidden Layers: [14, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.001984895825386, Hidden Layers: [8, 12]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.002192910075188, Hidden Layers: [14, 12]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.002246473789215, Hidden Layers: [12, 12]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.002625398397446, Hidden Layers: [14, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.003085993975401, Hidden Layers: [14, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.004952919483185, Hidden Layers: [14, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.0071105022430418, Hidden Layers: [8, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.007160742580891, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.0084685068130494, Hidden Layers: [6, 8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.008544883131981, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.00968359708786, Hidden Layers: [8, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.010382813215256, Hidden Layers: [12, 6]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.0107580602169035, Hidden Layers: [14, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.0128101289868354, Hidden Layers: [4, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.0134480090141293, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.0149026572704316, Hidden Layers: [12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.0171797440052033, Hidden Layers: [6, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.0172990530729296, Hidden Layers: [10, 16]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.017429518699646, Hidden Layers: [12, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.017586702108383, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.018459497451782, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0184739112854, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.0202976350188253, Hidden Layers: [14, 14]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.0204808831214907, Hidden Layers: [14, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.0214748620986938, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.0219015538692475, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.023029864132404, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.0241047174930573, Hidden Layers: [12, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.024413378715515, Hidden Layers: [14, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0246118783950804, Hidden Layers: [14, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.024794682919979, Hidden Layers: [8, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.0250530049800872, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.025753892958164, Hidden Layers: [12, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.0266250342130663, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.0272196531295776, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.029087449789047, Hidden Layers: [10, 6]; Learning Rate: 0.004; Batch Size: 5
MAE: 2.0290900856256484, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.0298323378562926, Hidden Layers: [8, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.0303828083574773, Hidden Layers: [12, 6]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.030778952121735, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.03167760848999, Hidden Layers: [4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.0316823422908783, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.033275057435036, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.034463533818722, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.034504054546356, Hidden Layers: [14, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.0345093579292297, Hidden Layers: [6]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.034518550395966, Hidden Layers: [14, 12]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.0348528653383253, Hidden Layers: [12, 10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.035558174610138, Hidden Layers: [16, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.0364923969507216, Hidden Layers: [12, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.037091014146805, Hidden Layers: [12, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 2.037584570109844, Hidden Layers: [6, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0375961080789566, Hidden Layers: [6, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.0379578442573547, Hidden Layers: [14, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.039259505271912, Hidden Layers: [10, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.039402385234833, Hidden Layers: [14, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.039418058156967, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.0394655644893644, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.0401914227008815, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.0404397830963137, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.0405101127922536, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.0412771478891374, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.041659057199955, Hidden Layers: [14, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.042128403544426, Hidden Layers: [6, 12]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.0435629086494442, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.044292601466179, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.044441722512245, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.0448270533084867, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.044837409734726, Hidden Layers: [8, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.044934856891632, Hidden Layers: [4, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.045678307116032, Hidden Layers: [10, 8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.045956328630447, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.0459713847637175, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.046191961497068, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.046544522047043, Hidden Layers: [4, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.0465540652275083, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.0476628035902977, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.0484800848960876, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.048649752318859, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.0488290712833406, Hidden Layers: [8, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.048884205579758, Hidden Layers: [4, 6]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0499174699783325, Hidden Layers: [6, 12]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.0508079633712772, Hidden Layers: [12, 16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.051028718233108, Hidden Layers: [14, 4]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.051102552622557, Hidden Layers: [14, 4]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.0513546155691147, Hidden Layers: [10, 4]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.0514445700347426, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.0515184462070466, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.0516196534633635, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.051832914352417, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.0520661444664, Hidden Layers: [14, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.052158921957016, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.052586218774319, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.052972470283508, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.053109881401062, Hidden Layers: [14, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.0531227827072143, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.0534109443426134, Hidden Layers: [14, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.0537389397621153, Hidden Layers: [4, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.054859972000122, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.055556089863181, Hidden Layers: [8, 10]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.0556229338645933, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.056040491223335, Hidden Layers: [8, 14]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.0560965716838835, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.0561459751129147, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.056454388976097, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.056578260719776, Hidden Layers: [14, 12]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.057362623691559, Hidden Layers: [12, 16]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.0574438900351524, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.0579430595040322, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.0591199562549596, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.0594616458415986, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.0610601530075074, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.0617831468582155, Hidden Layers: [14, 14]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.0620893602371213, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.0622722253799437, Hidden Layers: [14, 12]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.062719964981079, Hidden Layers: [6, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.063803866863251, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.064094202280045, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.064622406721115, Hidden Layers: [4, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.0647753343582154, Hidden Layers: [8, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.0648088455200195, Hidden Layers: [6]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.0656571135520934, Hidden Layers: [16, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.066851630806923, Hidden Layers: [14, 8]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.0676073328256606, Hidden Layers: [4, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.0677975997924802, Hidden Layers: [4, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.070079334139824, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.070836775749922, Hidden Layers: [4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.071325051784515, Hidden Layers: [6, 8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.071657341718674, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.0718498230576516, Hidden Layers: [6, 16]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.071987761735916, Hidden Layers: [16, 4]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.0722038940191267, Hidden Layers: [8, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.073542498111725, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.0747727692127227, Hidden Layers: [10, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.075014959335327, Hidden Layers: [8]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.075873627513647, Hidden Layers: [16]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.076026823043823, Hidden Layers: [12, 10]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.07639044380188, Hidden Layers: [14, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.076865137428045, Hidden Layers: [8, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.077256418824196, Hidden Layers: [14, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.0773946740329263, Hidden Layers: [14, 16]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.077877454519272, Hidden Layers: [14, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.077954441308975, Hidden Layers: [12]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.078225139141083, Hidden Layers: [6, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.078895276784897, Hidden Layers: [14, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.079251743912697, Hidden Layers: [14, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.079453487753868, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.081443870544433, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.0814577147960662, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.0818224669098853, Hidden Layers: [16, 4]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.083937591314316, Hidden Layers: [14, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.085180877149105, Hidden Layers: [8, 16]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.085791068702936, Hidden Layers: [12, 14]; Learning Rate: 0.0015; Batch Size: 3
MAE: 2.086098995804787, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.087084526181221, Hidden Layers: [4, 8]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.0875950515270234, Hidden Layers: [10, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.088319371700287, Hidden Layers: [12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.0892513052225112, Hidden Layers: [14, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.0894282147884367, Hidden Layers: [10]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.089542101383209, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.0899966076612477, Hidden Layers: [6, 4]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.0902798332870005, Hidden Layers: [14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.090518339782953, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.0909157947301864, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.0911002466380593, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.0912524461746216, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.0915614099502564, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.0919780955314637, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.0923535064458845, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.092441420316696, Hidden Layers: [14, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.0936098918914796, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.094252688169479, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.094554181575775, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.0948588104248045, Hidden Layers: [6, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.0949272871017457, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.0949984744787216, Hidden Layers: [14, 6]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.095119853496551, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.0953568518161774, Hidden Layers: [8, 8]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.0960090861320495, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.0973525404930116, Hidden Layers: [14, 4]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.098026460766792, Hidden Layers: [10, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.0980671377182007, Hidden Layers: [8, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.0984467582702635, Hidden Layers: [8, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.099636361002922, Hidden Layers: [14, 10]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.0999307261705398, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.1028528735637666, Hidden Layers: [12, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.1032484963536264, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.1037427935600284, Hidden Layers: [8, 16]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.103748028039932, Hidden Layers: [14, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.104536937236786, Hidden Layers: [6, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.1060694770812987, Hidden Layers: [12, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1062668279409413, Hidden Layers: [14, 14]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.1071963535547256, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.10782697057724, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.1078823149204253, Hidden Layers: [14, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.108299593687058, Hidden Layers: [16, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.1095364689826965, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.1115400433540343, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.111678131103516, Hidden Layers: [6, 16]; Learning Rate: 0.002; Batch Size: 2
MAE: 2.111763690471649, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.1121305227279663, Hidden Layers: [14, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.1124587461948394, Hidden Layers: [14, 16]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.113142045021057, Hidden Layers: [14]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.113944552898407, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1142090814113614, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.1147344068288803, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.1148816786706446, Hidden Layers: [16, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.11633536529541, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.1165059834718702, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.1168003060519696, Hidden Layers: [12, 16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.1179665670394896, Hidden Layers: [6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.118935555279255, Hidden Layers: [14, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.119750660657883, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.1202010929584505, Hidden Layers: [12, 4]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.1207922563552857, Hidden Layers: [10, 4]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.121137575864792, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.121818995475769, Hidden Layers: [12, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.1224231884479523, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.1228313014507294, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.1229770854115486, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.1231952950954436, Hidden Layers: [16, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.1232413039207456, Hidden Layers: [16, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.1248700964450835, Hidden Layers: [6, 14]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.125870610833168, Hidden Layers: [10, 10]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.126598563969135, Hidden Layers: [10, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.1285406995415683, Hidden Layers: [8, 8]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.128646969795227, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.1289709672927857, Hidden Layers: [14, 4]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.129011590838432, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1299195842742917, Hidden Layers: [8]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.1305911421775816, Hidden Layers: [8, 6]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.1311943118572234, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.131393481850624, Hidden Layers: [8, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1324853856563566, Hidden Layers: [10, 4]; Learning Rate: 0.0015; Batch Size: 3
MAE: 2.132686434745789, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.133263111114502, Hidden Layers: [14, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1337183566093443, Hidden Layers: [14, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.134915567994118, Hidden Layers: [12, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.1350850269794464, Hidden Layers: [6, 4]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.135184167385101, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.136883573293686, Hidden Layers: [8, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.1371863484978677, Hidden Layers: [14, 8]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.138095583438873, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.1388871163725853, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.13968798071146, Hidden Layers: [14, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.139706157207489, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.139981006085873, Hidden Layers: [8, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.1420151562690735, Hidden Layers: [4, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.1430884644985198, Hidden Layers: [16, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1432448194026947, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.1452305309474466, Hidden Layers: [12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1454857543706893, Hidden Layers: [4, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.145997844815254, Hidden Layers: [14, 14]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.1468250691890716, Hidden Layers: [4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.147635163784027, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1481082649230956, Hidden Layers: [10, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1484315128326417, Hidden Layers: [10, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1485152111053467, Hidden Layers: [10, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1494251461029052, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.1497225151062014, Hidden Layers: [4, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.149927827835083, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.1511641428470614, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.1519680306911466, Hidden Layers: [10, 4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.1524018347263336, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.1525599048137662, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.1530689626932142, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.1531429812908174, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.155236092209816, Hidden Layers: [10, 14]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.1553255156874656, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.1574233965873715, Hidden Layers: [14, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1580598936080935, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.158605764865875, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.1591765675544736, Hidden Layers: [10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.159412008523941, Hidden Layers: [14, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.1594497561454773, Hidden Layers: [10, 14]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.1595361099243164, Hidden Layers: [6, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.1617755131721497, Hidden Layers: [10]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.1620195138454434, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1621146903038024, Hidden Layers: [12, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.1624618068933485, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.1629947276115415, Hidden Layers: [6, 12]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.1652822465896606, Hidden Layers: [14, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.1656475142240525, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.165790997505188, Hidden Layers: [4, 6]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.165927071928978, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 1
MAE: 2.1660262048244476, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1661195502281188, Hidden Layers: [4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.166303844809532, Hidden Layers: [10, 6]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.167704227566719, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.1678628311157224, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.1686224967241285, Hidden Layers: [14, 12]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.168736663818359, Hidden Layers: [14, 10]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.1688672080636024, Hidden Layers: [14, 6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1689695842564105, Hidden Layers: [14, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.169298859000206, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.1694029211997985, Hidden Layers: [12, 12]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.16956485080719, Hidden Layers: [14, 8]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.1704022873044013, Hidden Layers: [14, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.1708863973617554, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.172129355430603, Hidden Layers: [14, 4]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.173025022506714, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.1731034190654754, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.1736091212034223, Hidden Layers: [6]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.173639385461807, Hidden Layers: [14, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.1742076174020766, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.174693262577057, Hidden Layers: [14, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.1752003893852234, Hidden Layers: [6, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.1782109575271607, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.178882855653763, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.1792540296912195, Hidden Layers: [4, 8]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.179778540253639, Hidden Layers: [12, 16]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.180105555534363, Hidden Layers: [12]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.180269846320152, Hidden Layers: [6, 12]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.1819722623825073, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.182156965136528, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.18218843793869, Hidden Layers: [12, 8]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.1823269591331482, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.1839795049279926, Hidden Layers: [10, 8]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.1845571444034575, Hidden Layers: [8, 6]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.1845811114311218, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.1849733710289003, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.185506668686867, Hidden Layers: [6, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.1863368556499485, Hidden Layers: [6, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.1881432042121887, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.1887097672224045, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.189119240641594, Hidden Layers: [14, 10]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.190774138331413, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.191343186855316, Hidden Layers: [4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.1936241835951806, Hidden Layers: [14, 8]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.195218495339155, Hidden Layers: [8, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.1957105457782746, Hidden Layers: [4, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.1963380932807923, Hidden Layers: [10, 16]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.1980114564895628, Hidden Layers: [4, 16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.1985860452651975, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.1995634467005734, Hidden Layers: [10]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.2004692912101746, Hidden Layers: [8]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.200614310860634, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.2024274468421936, Hidden Layers: [10, 8]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.206496705174446, Hidden Layers: [12, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.207610981225968, Hidden Layers: [4, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.208293315887451, Hidden Layers: [10, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.21059903216362, Hidden Layers: [8, 12]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.210830051064491, Hidden Layers: [14, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.211073023080826, Hidden Layers: [12, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2126984864473345, Hidden Layers: [14, 6]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.2130393773317336, Hidden Layers: [4, 10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.2133362382650374, Hidden Layers: [4, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.213669481873512, Hidden Layers: [12, 4]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.2141740725040435, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.2142649509012697, Hidden Layers: [14, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.2143728256225588, Hidden Layers: [6, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.214481160402298, Hidden Layers: [6, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.214598279505968, Hidden Layers: [16]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.214814859628677, Hidden Layers: [12, 16]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.2148191576004024, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.214858201146126, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.218115489244461, Hidden Layers: [14, 8]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.2191628173589706, Hidden Layers: [6, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.2194352984428405, Hidden Layers: [10, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.2210044251084327, Hidden Layers: [8, 10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.22216051530838, Hidden Layers: [14, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.2222249255180357, Hidden Layers: [14, 10]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.222566197872162, Hidden Layers: [6, 14]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.2233117491602896, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.223574324011803, Hidden Layers: [6, 14]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.22573318195343, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.2276251718997955, Hidden Layers: [6, 10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.2279289216995237, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.230036625444889, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.231529727935791, Hidden Layers: [6, 8]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.2321721777915955, Hidden Layers: [14, 10]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2325105891227723, Hidden Layers: [14, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.2344828338027, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2347698539495466, Hidden Layers: [8, 10]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.2354313850402834, Hidden Layers: [6, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.2370448083877563, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.237381544709206, Hidden Layers: [14, 16]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.2391082451343536, Hidden Layers: [12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.2394701898097993, Hidden Layers: [6, 6]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.2411082670688627, Hidden Layers: [14, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.2412079275250436, Hidden Layers: [10, 10]; Learning Rate: 0.0015; Batch Size: 3
MAE: 2.241900208771229, Hidden Layers: [10, 8]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.2428644169569014, Hidden Layers: [10, 12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.2441228762865064, Hidden Layers: [14, 6]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.244137595653534, Hidden Layers: [10, 6]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.244569304943085, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.2449592561125753, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.245832419395447, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.247641749739647, Hidden Layers: [12, 6]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.247841094493866, Hidden Layers: [10, 10]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.2494699362516406, Hidden Layers: [4, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.2504344255328177, Hidden Layers: [14, 4]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.25117247402668, Hidden Layers: [8, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.2513430134058, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.2534097151756285, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.2537581592798235, Hidden Layers: [12, 6]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.2544884011745454, Hidden Layers: [10, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.2547781649827963, Hidden Layers: [16, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.2583780333399774, Hidden Layers: [14, 6]; Learning Rate: 0.003; Batch Size: 5
MAE: 2.2585330829620363, Hidden Layers: [14, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.25994597530365, Hidden Layers: [6, 6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.2604554266929626, Hidden Layers: [10, 6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.2620479092597963, Hidden Layers: [12]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.262953279972076, Hidden Layers: [14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.2630436973571775, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.2641238676309583, Hidden Layers: [8]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.26635569190979, Hidden Layers: [12, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.266612653493881, Hidden Layers: [14, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.2667633950710298, Hidden Layers: [14, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.2689075291752814, Hidden Layers: [8, 6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.2698918521404265, Hidden Layers: [10]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.2713723526000975, Hidden Layers: [12, 12]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.2724695103168484, Hidden Layers: [6, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.2730577841997146, Hidden Layers: [4, 6]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.273069883942604, Hidden Layers: [12, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.273168870925903, Hidden Layers: [12, 8]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.273338125705719, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.2782123403549193, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.279309797286987, Hidden Layers: [14, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.279366765975952, Hidden Layers: [14, 14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.2811006367206574, Hidden Layers: [14, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.282795798778534, Hidden Layers: [6, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.2837203428745267, Hidden Layers: [14]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.2841161929666995, Hidden Layers: [10]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.2858661131858824, Hidden Layers: [12, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.2863019459545613, Hidden Layers: [14, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.286444008409977, Hidden Layers: [12, 12]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.2864682302474977, Hidden Layers: [6, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.2885433718562127, Hidden Layers: [4, 8]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.289808635473251, Hidden Layers: [14, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.2902920633554458, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.2917884871959684, Hidden Layers: [6, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.2928055197000505, Hidden Layers: [12, 16]; Learning Rate: 0.003; Batch Size: 1
MAE: 2.2931435994803904, Hidden Layers: [8, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.293800139427185, Hidden Layers: [8]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.2940399603843686, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.2949512348175047, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.2955770359039307, Hidden Layers: [16, 4]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.296251250863075, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.296695460379124, Hidden Layers: [14, 10]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.297421401053667, Hidden Layers: [10, 14]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.298579771995544, Hidden Layers: [16, 4]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.298683853626251, Hidden Layers: [4, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.2987345860004424, Hidden Layers: [8, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.299301622867584, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3011642665863037, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3015500605106354, Hidden Layers: [12, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.301778863430023, Hidden Layers: [6, 10]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.3036632404327393, Hidden Layers: [10, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.3044723675251007, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.30471311211586, Hidden Layers: [10, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.3051772520542144, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.306535981655121, Hidden Layers: [14]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.306690436601639, Hidden Layers: [8, 6]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.3067020059227943, Hidden Layers: [4, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.307020859479904, Hidden Layers: [14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.3073035821914676, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.308794270515442, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.308952045440674, Hidden Layers: [14]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.3093865692615507, Hidden Layers: [14, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.3119770706295966, Hidden Layers: [6]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.3122993767261506, Hidden Layers: [10, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.3130649642944334, Hidden Layers: [12, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.3135028915405274, Hidden Layers: [16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.3135079221725463, Hidden Layers: [14, 6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.313519202232361, Hidden Layers: [14, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.315435642004013, Hidden Layers: [6, 10]; Learning Rate: 0.001; Batch Size: 2
MAE: 2.317508618593216, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.318241516113281, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.318445955395698, Hidden Layers: [6, 16]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.319876595020294, Hidden Layers: [12, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.3199576113224034, Hidden Layers: [12]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.320479943335056, Hidden Layers: [16, 4]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.320818376541138, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.320935190081596, Hidden Layers: [8]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.321748689174652, Hidden Layers: [8, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.322174076795578, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.323934182524681, Hidden Layers: [12, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.324331745624542, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.324379640996456, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.3245733234882353, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.32524663066864, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3259373903274536, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3262550995349884, Hidden Layers: [16, 4]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.328247627675533, Hidden Layers: [14, 4]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.3285417170524596, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.330384300708771, Hidden Layers: [14, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.3304125086069107, Hidden Layers: [14]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.332153889656067, Hidden Layers: [14, 8]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.332355314552784, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.3331160232424737, Hidden Layers: [10, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.3335624427795407, Hidden Layers: [4, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.3348226294517516, Hidden Layers: [8]; Learning Rate: 0.0015; Batch Size: 4
MAE: 2.3375438511371613, Hidden Layers: [10, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.3378108143806458, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.3384107702076435, Hidden Layers: [14, 10]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.3387243807315827, Hidden Layers: [6, 6]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.3400290690362455, Hidden Layers: [8, 8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.340112790584564, Hidden Layers: [12, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3402976632118224, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.3440734834671018, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 4
MAE: 2.3450471656322476, Hidden Layers: [10, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3456249669790266, Hidden Layers: [8, 8]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.347154459714889, Hidden Layers: [14, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.348347647666931, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.3488015089035033, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3506338567733764, Hidden Layers: [12, 8]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.3516180009841916, Hidden Layers: [14, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.351866106748581, Hidden Layers: [14, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.3531298249959947, Hidden Layers: [6, 16]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.353548823297024, Hidden Layers: [16, 4]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.354297457695007, Hidden Layers: [4, 12]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.354473923206329, Hidden Layers: [14, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.355075723737478, Hidden Layers: [12, 16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.355797606706619, Hidden Layers: [14, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3566539422273634, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.357594362705946, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.357841096878052, Hidden Layers: [14, 4]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.3604211545214056, Hidden Layers: [12, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.3608861491680146, Hidden Layers: [14, 16]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.3620734647512434, Hidden Layers: [10, 8]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.3638804137706755, Hidden Layers: [14, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.365408286511898, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.366042521595955, Hidden Layers: [12, 4]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.366333425104618, Hidden Layers: [10, 8]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.3685140312314035, Hidden Layers: [14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.368716421037912, Hidden Layers: [6, 16]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.3702467844486237, Hidden Layers: [10, 12]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.3705247566699983, Hidden Layers: [14]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.3742800340652463, Hidden Layers: [12, 14]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.3762458102703095, Hidden Layers: [6, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.376542870759964, Hidden Layers: [8, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.3772923887372017, Hidden Layers: [10, 16]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.3782636300325395, Hidden Layers: [14]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.378778412938118, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.380768096446991, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.3813441932201385, Hidden Layers: [12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.381423051834106, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.382840000152588, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3828917310237885, Hidden Layers: [10, 14]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.3830521211624145, Hidden Layers: [6, 8]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3836232857704163, Hidden Layers: [14, 10]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.3857659147977825, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.3861864194869993, Hidden Layers: [14, 14]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.3862526239752766, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.3873779133558273, Hidden Layers: [8, 6]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.388888675034046, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3893957302570343, Hidden Layers: [6, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.389688567876816, Hidden Layers: [14, 4]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.3901876912117004, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.391151246547699, Hidden Layers: [8, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.3912450571060178, Hidden Layers: [10, 4]; Learning Rate: 0.001; Batch Size: 4
MAE: 2.392253859400749, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.392287610530853, Hidden Layers: [14, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.3928349199369547, Hidden Layers: [14, 10]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.3941409215927125, Hidden Layers: [12, 12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.394390641212463, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3962662475109098, Hidden Layers: [8, 6]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.3969700083732604, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 3
MAE: 2.3994904100894927, Hidden Layers: [10, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.4003283083438873, Hidden Layers: [10, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.401200239419937, Hidden Layers: [10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.4041891977787015, Hidden Layers: [14, 6]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.406046192407608, Hidden Layers: [10, 10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.4061985299587247, Hidden Layers: [14, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.4071156697273253, Hidden Layers: [14, 16]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.407614386886358, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.409356162071228, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.4102375656962396, Hidden Layers: [4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.410561458826065, Hidden Layers: [10]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.412057755947113, Hidden Layers: [16]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.412959004998207, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.413552816271782, Hidden Layers: [4, 4]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.4162468538284303, Hidden Layers: [12, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.418061542510986, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.4186100766658782, Hidden Layers: [16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.419553357362747, Hidden Layers: [8, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.419939374923706, Hidden Layers: [10, 14]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.4221853942871094, Hidden Layers: [12, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.422223424911499, Hidden Layers: [10, 16]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.4239822015166284, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.4240941166877747, Hidden Layers: [10, 10]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.42441800570488, Hidden Layers: [12]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.4251906888484953, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.4258752822875977, Hidden Layers: [8, 10]; Learning Rate: 0.0085; Batch Size: 2
MAE: 2.4259236590862274, Hidden Layers: [8, 8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.426934880822897, Hidden Layers: [14, 6]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.4274627850055692, Hidden Layers: [12, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.4303963069915766, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.431993655920029, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.4333626568317412, Hidden Layers: [10, 14]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.4338385701179504, Hidden Layers: [16, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.43413844871521, Hidden Layers: [16]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.435729643821716, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.4371638536453246, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.4392266809940337, Hidden Layers: [10, 10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.440468829870224, Hidden Layers: [8, 8]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.440752312541008, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.4438222095966338, Hidden Layers: [8, 6]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.4441592321395875, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.4442741751670836, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 2
MAE: 2.4478122889995575, Hidden Layers: [12, 16]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.4499911413192748, Hidden Layers: [12, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.451582107067108, Hidden Layers: [14, 12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.4517917692661286, Hidden Layers: [16, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.4518509761095046, Hidden Layers: [12, 6]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.4520590603351593, Hidden Layers: [12, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 2.4523137793540952, Hidden Layers: [14, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.452475400328636, Hidden Layers: [6, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.45379753112793, Hidden Layers: [12, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.4553690450191494, Hidden Layers: [14, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.4568203092217447, Hidden Layers: [4, 6]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.45941830432415, Hidden Layers: [6, 10]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.45956379032135, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.4596230570077897, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.4621853940188885, Hidden Layers: [12, 16]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.4635427419692277, Hidden Layers: [6, 8]; Learning Rate: 0.0055; Batch Size: 5
MAE: 2.466722925066948, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.4671855211257934, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.4684245321750637, Hidden Layers: [6, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.469028131723404, Hidden Layers: [10, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4694579558372496, Hidden Layers: [14, 6]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.4697919116020204, Hidden Layers: [8, 10]; Learning Rate: 0.005000000000000001; Batch Size: 5
MAE: 2.4746531563997265, Hidden Layers: [6, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.478027348279953, Hidden Layers: [10, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.4786709368228914, Hidden Layers: [12, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 2.480398269057274, Hidden Layers: [4, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 2.481179675579071, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.4831100583076475, Hidden Layers: [14, 10]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.4841539398431776, Hidden Layers: [8, 12]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.486843165874481, Hidden Layers: [10, 16]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.488544668316841, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4890575573444367, Hidden Layers: [10, 16]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.4900323659181596, Hidden Layers: [12, 8]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.4916726559996603, Hidden Layers: [14]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.4917479679584504, Hidden Layers: [8, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.4919800058603285, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.4921403542757035, Hidden Layers: [10]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.4950780510902404, Hidden Layers: [8, 14]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.4977822482585905, Hidden Layers: [6, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.5009138362407684, Hidden Layers: [14, 16]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.5014610085487368, Hidden Layers: [10, 16]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.501889357402921, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.5022410616874695, Hidden Layers: [4, 4]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.50351269698143, Hidden Layers: [12, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.507000987291336, Hidden Layers: [8, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.507335530281067, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.5079334393143653, Hidden Layers: [10, 6]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.5102748856544492, Hidden Layers: [14, 12]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.5127677664756773, Hidden Layers: [14, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.5139967918396, Hidden Layers: [12, 10]; Learning Rate: 0.0085; Batch Size: 4
MAE: 2.514095245361328, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 4
MAE: 2.514732132911682, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.5148113071918488, Hidden Layers: [10, 10]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.51701871907711, Hidden Layers: [14, 8]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5182691488265987, Hidden Layers: [6, 6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.518946358680725, Hidden Layers: [14, 6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.519612734079361, Hidden Layers: [16]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.5208762288093567, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.52125725197792, Hidden Layers: [14, 4]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.522928927898407, Hidden Layers: [12, 6]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 2.5233595477342603, Hidden Layers: [10, 8]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.5242081701755525, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.524999520540237, Hidden Layers: [8, 16]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.526217043399811, Hidden Layers: [14, 16]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.5297669336795807, Hidden Layers: [12, 10]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.530125877261162, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.530291934490204, Hidden Layers: [10, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.530502221107483, Hidden Layers: [14, 8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.5331138105392457, Hidden Layers: [8, 16]; Learning Rate: 0.0035; Batch Size: 2
MAE: 2.534331890940666, Hidden Layers: [8]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.5354546504020687, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.535784955382347, Hidden Layers: [16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.537845239162445, Hidden Layers: [8, 8]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.5379346877336504, Hidden Layers: [10]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.539952166557312, Hidden Layers: [10, 10]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.5399704918861388, Hidden Layers: [16, 4]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.5402603857815267, Hidden Layers: [10, 14]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.5430226802825926, Hidden Layers: [12, 4]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.5436976120471955, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5438081339597702, Hidden Layers: [12, 16]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.5454398469924926, Hidden Layers: [6]; Learning Rate: 0.0035; Batch Size: 4
MAE: 2.546964113473892, Hidden Layers: [14, 14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 2.54894557762146, Hidden Layers: [4, 10]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.5506374225616453, Hidden Layers: [12]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.5510831434726713, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5517306642532347, Hidden Layers: [14, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.552740550041199, Hidden Layers: [10, 14]; Learning Rate: 0.0015; Batch Size: 1
MAE: 2.55356089925766, Hidden Layers: [8, 14]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.556853540420532, Hidden Layers: [12, 16]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.558982105731964, Hidden Layers: [4, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.5628479421138763, Hidden Layers: [14, 12]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.5631247535943986, Hidden Layers: [8]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.564605771064758, Hidden Layers: [12, 6]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.5654521927833556, Hidden Layers: [6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.566670024394989, Hidden Layers: [16, 4]; Learning Rate: 0.0025; Batch Size: 1
MAE: 2.56702621281147, Hidden Layers: [10]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.570459740161896, Hidden Layers: [12, 4]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.571935909986496, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 4
MAE: 2.575710658788681, Hidden Layers: [12]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 2.5760038599967956, Hidden Layers: [6, 10]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.5764323205947877, Hidden Layers: [8, 14]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.5768654661178587, Hidden Layers: [14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.578273500561714, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.5823566184043885, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.5826634615659714, Hidden Layers: [10, 8]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.583166411876678, Hidden Layers: [10, 4]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.5857137188911437, Hidden Layers: [12, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.587136280536652, Hidden Layers: [8, 14]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.588696889638901, Hidden Layers: [8]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.5891943722963333, Hidden Layers: [6, 14]; Learning Rate: 0.003; Batch Size: 2
MAE: 2.590064583778381, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 5
MAE: 2.5954928741455077, Hidden Layers: [8]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.59977793264389, Hidden Layers: [6, 4]; Learning Rate: 0.0075; Batch Size: 1
MAE: 2.601329207420349, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.601901505947113, Hidden Layers: [4, 4]; Learning Rate: 0.0005; Batch Size: 3
MAE: 2.602644822359085, Hidden Layers: [10]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.602812612056732, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 2
MAE: 2.6034919366836546, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.6128387019634247, Hidden Layers: [10, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.61466598367691, Hidden Layers: [12, 16]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.6147365542054173, Hidden Layers: [4, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6165882892906667, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 4
MAE: 2.616676163673401, Hidden Layers: [14, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 2.6208210263252254, Hidden Layers: [12, 4]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 2.622867947816849, Hidden Layers: [8, 10]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.625325876161456, Hidden Layers: [10, 4]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.6267674342393876, Hidden Layers: [8]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.628404844239354, Hidden Layers: [16]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.628985068321228, Hidden Layers: [12, 6]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.629312935590744, Hidden Layers: [8]; Learning Rate: 0.0035; Batch Size: 5
MAE: 2.630978247523308, Hidden Layers: [8, 10]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.631418771961704, Hidden Layers: [4, 4]; Learning Rate: 0.0015; Batch Size: 5
MAE: 2.6352659787982704, Hidden Layers: [8, 12]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.635581378698349, Hidden Layers: [12, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.6390821740627293, Hidden Layers: [12, 14]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.6395965013504026, Hidden Layers: [8, 8]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6398198561668393, Hidden Layers: [12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.6448491752147674, Hidden Layers: [8, 12]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.6454470694065093, Hidden Layers: [14, 16]; Learning Rate: 0.0015; Batch Size: 2
MAE: 2.6455543756484987, Hidden Layers: [12, 10]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.648490549683571, Hidden Layers: [14, 12]; Learning Rate: 0.001; Batch Size: 1
MAE: 2.6561413288116453, Hidden Layers: [6, 16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.6586707339286804, Hidden Layers: [10, 4]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.662940248966217, Hidden Layers: [14, 12]; Learning Rate: 0.0005; Batch Size: 4
MAE: 2.664280910849571, Hidden Layers: [12]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.667373131215572, Hidden Layers: [12, 16]; Learning Rate: 0.004; Batch Size: 3
MAE: 2.6680451110601426, Hidden Layers: [14]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.6702974177226424, Hidden Layers: [16]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.670423053264618, Hidden Layers: [14, 14]; Learning Rate: 0.009000000000000001; Batch Size: 4
MAE: 2.6706564888954163, Hidden Layers: [16, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.673434201240539, Hidden Layers: [12, 10]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.6738338813781737, Hidden Layers: [10, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.674652694225311, Hidden Layers: [8, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 2.6855965719223023, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 2
MAE: 2.6857311129570007, Hidden Layers: [12, 14]; Learning Rate: 0.0055; Batch Size: 4
MAE: 2.688511425256729, Hidden Layers: [6, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.6912023767828943, Hidden Layers: [10, 12]; Learning Rate: 0.0045000000000000005; Batch Size: 3
MAE: 2.6957205638885497, Hidden Layers: [12, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 2.697273391544819, Hidden Layers: [12, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.6993220925331114, Hidden Layers: [8, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.701877100944519, Hidden Layers: [4, 14]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.7109540820121767, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.7118347570896146, Hidden Layers: [14, 16]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.7139180302619934, Hidden Layers: [12]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.7149265825748445, Hidden Layers: [14, 10]; Learning Rate: 0.006500000000000001; Batch Size: 3
MAE: 2.7152185292243955, Hidden Layers: [6, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.718012340426445, Hidden Layers: [12, 8]; Learning Rate: 0.008; Batch Size: 1
MAE: 2.718341609954834, Hidden Layers: [12, 14]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.7194894165992736, Hidden Layers: [8, 4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 2.722136028289795, Hidden Layers: [8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.723188541889191, Hidden Layers: [4, 8]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.7236596064567564, Hidden Layers: [12, 10]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.7242438077926634, Hidden Layers: [14, 16]; Learning Rate: 0.006; Batch Size: 3
MAE: 2.724489951133728, Hidden Layers: [12, 14]; Learning Rate: 0.002; Batch Size: 5
MAE: 2.724814936637878, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.7256677001714706, Hidden Layers: [10, 8]; Learning Rate: 0.0025; Batch Size: 2
MAE: 2.7327556461691858, Hidden Layers: [12, 4]; Learning Rate: 0.002; Batch Size: 3
MAE: 2.735076573848725, Hidden Layers: [8]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.73578289604187, Hidden Layers: [12, 6]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 2.735939732193947, Hidden Layers: [10, 10]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.7379768388271333, Hidden Layers: [6, 12]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.739984595775604, Hidden Layers: [12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 2.7456139981746674, Hidden Layers: [12, 10]; Learning Rate: 0.008; Batch Size: 5
MAE: 2.749227763772011, Hidden Layers: [4, 12]; Learning Rate: 0.0035; Batch Size: 1
MAE: 2.7533131853342057, Hidden Layers: [12, 6]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.753536377906799, Hidden Layers: [10, 4]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.757665436029434, Hidden Layers: [4, 14]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.761810897350311, Hidden Layers: [8]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.764680408000946, Hidden Layers: [10, 6]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.7654168754816055, Hidden Layers: [8, 12]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.767269615888596, Hidden Layers: [14, 6]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.7685442180633544, Hidden Layers: [12, 10]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.7712779359817503, Hidden Layers: [12]; Learning Rate: 0.0035; Batch Size: 3
MAE: 2.7717042059898374, Hidden Layers: [6, 16]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.774302265167236, Hidden Layers: [10]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 2.7790858850479125, Hidden Layers: [12, 4]; Learning Rate: 0.006; Batch Size: 4
MAE: 2.781913279056549, Hidden Layers: [12, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.786079134106636, Hidden Layers: [14, 12]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.7879556894302366, Hidden Layers: [10, 8]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.788458643913269, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 5
MAE: 2.7929939703941344, Hidden Layers: [14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 2.801421770572662, Hidden Layers: [6]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.8018717379570006, Hidden Layers: [10, 12]; Learning Rate: 0.006500000000000001; Batch Size: 4
MAE: 2.811801800251007, Hidden Layers: [10]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.8146447391510008, Hidden Layers: [12, 4]; Learning Rate: 0.0085; Batch Size: 5
MAE: 2.817098653316498, Hidden Layers: [14, 12]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.8260716676712034, Hidden Layers: [4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 2.8286366925239563, Hidden Layers: [10, 6]; Learning Rate: 0.001; Batch Size: 5
MAE: 2.8289343285560613, Hidden Layers: [16, 4]; Learning Rate: 0.0025; Batch Size: 4
MAE: 2.8297799842357634, Hidden Layers: [8, 14]; Learning Rate: 0.008; Batch Size: 3
MAE: 2.8298318252563477, Hidden Layers: [14, 16]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.8313165426254274, Hidden Layers: [14, 4]; Learning Rate: 0.009000000000000001; Batch Size: 2
MAE: 2.8320538507699964, Hidden Layers: [14]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.833197115421295, Hidden Layers: [12, 10]; Learning Rate: 0.0025; Batch Size: 5
MAE: 2.833484319031238, Hidden Layers: [6, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.834829674720764, Hidden Layers: [14, 14]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.854437692642212, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.8599672094583513, Hidden Layers: [8, 14]; Learning Rate: 0.0055; Batch Size: 2
MAE: 2.8600312576293945, Hidden Layers: [10, 4]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.862335965156555, Hidden Layers: [8, 16]; Learning Rate: 0.009000000000000001; Batch Size: 3
MAE: 2.8644091979265216, Hidden Layers: [16, 4]; Learning Rate: 0.0085; Batch Size: 1
MAE: 2.8649203734397886, Hidden Layers: [8, 12]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.867915225088596, Hidden Layers: [14, 6]; Learning Rate: 0.0075; Batch Size: 4
MAE: 2.874296113848686, Hidden Layers: [8, 14]; Learning Rate: 0.001; Batch Size: 3
MAE: 2.87527836894989, Hidden Layers: [12, 4]; Learning Rate: 0.0005; Batch Size: 5
MAE: 2.8773375306129454, Hidden Layers: [4, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 2.8819887237548825, Hidden Layers: [10, 8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 2.8844206199645996, Hidden Layers: [8, 16]; Learning Rate: 0.0045000000000000005; Batch Size: 2
MAE: 2.888055741786957, Hidden Layers: [10]; Learning Rate: 0.002; Batch Size: 4
MAE: 2.889387345314026, Hidden Layers: [12, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 2.8924584493637084, Hidden Layers: [16]; Learning Rate: 0.01; Batch Size: 1
MAE: 2.8946524188518525, Hidden Layers: [14, 8]; Learning Rate: 0.006500000000000001; Batch Size: 1
MAE: 2.8952078745365144, Hidden Layers: [10]; Learning Rate: 0.0055; Batch Size: 1
MAE: 2.89608642911911, Hidden Layers: [10]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.8963429272174834, Hidden Layers: [10, 12]; Learning Rate: 0.0025; Batch Size: 3
MAE: 2.896396240711212, Hidden Layers: [6, 14]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 2.8971294522285462, Hidden Layers: [4, 14]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 2.897729878127575, Hidden Layers: [12, 12]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.8986426830291747, Hidden Layers: [12, 16]; Learning Rate: 0.0075; Batch Size: 3
MAE: 2.903628206253052, Hidden Layers: [8, 14]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.908469091415405, Hidden Layers: [12, 8]; Learning Rate: 0.01; Batch Size: 2
MAE: 2.9176550731658937, Hidden Layers: [16]; Learning Rate: 0.006; Batch Size: 5
MAE: 2.9264913529753684, Hidden Layers: [12, 10]; Learning Rate: 0.006; Batch Size: 1
MAE: 2.9270001504421237, Hidden Layers: [10, 4]; Learning Rate: 0.0005; Batch Size: 1
MAE: 2.929804211854935, Hidden Layers: [6, 10]; Learning Rate: 0.0055; Batch Size: 3
MAE: 2.9365611748695373, Hidden Layers: [6]; Learning Rate: 0.007000000000000001; Batch Size: 2
MAE: 2.9565970771610735, Hidden Layers: [4]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.9728186190128327, Hidden Layers: [10, 16]; Learning Rate: 0.004; Batch Size: 1
MAE: 2.984579122066498, Hidden Layers: [6]; Learning Rate: 0.005000000000000001; Batch Size: 2
MAE: 2.987040515422821, Hidden Layers: [4, 6]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 2.9883229570388794, Hidden Layers: [14, 14]; Learning Rate: 0.008; Batch Size: 4
MAE: 2.992887207984924, Hidden Layers: [16, 4]; Learning Rate: 0.0035; Batch Size: 4
MAE: 3.001689554810524, Hidden Layers: [14, 12]; Learning Rate: 0.0075; Batch Size: 4
MAE: 3.0025941047668456, Hidden Layers: [14, 12]; Learning Rate: 0.01; Batch Size: 1
MAE: 3.0030121669769287, Hidden Layers: [14, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 3.0039432943463327, Hidden Layers: [4]; Learning Rate: 0.0045000000000000005; Batch Size: 5
MAE: 3.0065708861351013, Hidden Layers: [14]; Learning Rate: 0.0005; Batch Size: 5
MAE: 3.0071094737052917, Hidden Layers: [12, 16]; Learning Rate: 0.0035; Batch Size: 4
MAE: 3.009886054754257, Hidden Layers: [8, 14]; Learning Rate: 0.0045000000000000005; Batch Size: 4
MAE: 3.013174387931824, Hidden Layers: [10, 16]; Learning Rate: 0.01; Batch Size: 3
MAE: 3.0148839492797848, Hidden Layers: [14, 12]; Learning Rate: 0.0085; Batch Size: 3
MAE: 3.018104356586933, Hidden Layers: [8, 12]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 3.0183619604110716, Hidden Layers: [16]; Learning Rate: 0.0025; Batch Size: 1
MAE: 3.018407331466675, Hidden Layers: [4, 6]; Learning Rate: 0.007000000000000001; Batch Size: 4
MAE: 3.0264869556427003, Hidden Layers: [14]; Learning Rate: 0.0015; Batch Size: 4
MAE: 3.02790012216568, Hidden Layers: [14, 4]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 3.035234998345375, Hidden Layers: [14]; Learning Rate: 0.007000000000000001; Batch Size: 5
MAE: 3.0364126608371733, Hidden Layers: [8, 10]; Learning Rate: 0.007000000000000001; Batch Size: 1
MAE: 3.0456604228019715, Hidden Layers: [14, 4]; Learning Rate: 0.0055; Batch Size: 2
MAE: 3.046756519436836, Hidden Layers: [10, 12]; Learning Rate: 0.008; Batch Size: 3
MAE: 3.049593611240387, Hidden Layers: [14, 6]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 3.049882178068161, Hidden Layers: [8]; Learning Rate: 0.0045000000000000005; Batch Size: 1
MAE: 3.050548718929291, Hidden Layers: [12, 6]; Learning Rate: 0.01; Batch Size: 5
MAE: 3.054473400115967, Hidden Layers: [6, 16]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 3.056845028877258, Hidden Layers: [14, 14]; Learning Rate: 0.008; Batch Size: 2
MAE: 3.0653825461864472, Hidden Layers: [14, 12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.071227213859558, Hidden Layers: [10, 14]; Learning Rate: 0.009000000000000001; Batch Size: 1
MAE: 3.0728003606796266, Hidden Layers: [12]; Learning Rate: 0.01; Batch Size: 1
MAE: 3.0774910867214205, Hidden Layers: [6]; Learning Rate: 0.0015; Batch Size: 1
MAE: 3.090915502667427, Hidden Layers: [6]; Learning Rate: 0.0005; Batch Size: 1
MAE: 3.094146846294403, Hidden Layers: [14, 12]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 3.1046783730983734, Hidden Layers: [16]; Learning Rate: 0.001; Batch Size: 1
MAE: 3.105064995646477, Hidden Layers: [8, 4]; Learning Rate: 0.002; Batch Size: 4
MAE: 3.107300700426102, Hidden Layers: [10, 14]; Learning Rate: 0.006; Batch Size: 5
MAE: 3.1101553173065186, Hidden Layers: [12, 16]; Learning Rate: 0.008; Batch Size: 4
MAE: 3.1109962329864502, Hidden Layers: [12, 16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 3.1190274552106856, Hidden Layers: [6, 4]; Learning Rate: 0.007000000000000001; Batch Size: 3
MAE: 3.1285714404582974, Hidden Layers: [4, 14]; Learning Rate: 0.004; Batch Size: 2
MAE: 3.1315883890390395, Hidden Layers: [14]; Learning Rate: 0.0075; Batch Size: 1
MAE: 3.1362825334072113, Hidden Layers: [6, 8]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 3.1394094079732895, Hidden Layers: [6]; Learning Rate: 0.006; Batch Size: 5
MAE: 3.1473915711641314, Hidden Layers: [10, 16]; Learning Rate: 0.009000000000000001; Batch Size: 5
MAE: 3.1639172986745834, Hidden Layers: [8, 8]; Learning Rate: 0.006500000000000001; Batch Size: 2
MAE: 3.1818889126777647, Hidden Layers: [16]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.1884463267326355, Hidden Layers: [10]; Learning Rate: 0.008; Batch Size: 1
MAE: 3.19628550863266, Hidden Layers: [12]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.2311410784721373, Hidden Layers: [12, 12]; Learning Rate: 0.0035; Batch Size: 5
MAE: 3.240051233768463, Hidden Layers: [6]; Learning Rate: 0.0085; Batch Size: 2
MAE: 3.2479322299957274, Hidden Layers: [14, 14]; Learning Rate: 0.01; Batch Size: 3
MAE: 3.2574724512100217, Hidden Layers: [16]; Learning Rate: 0.003; Batch Size: 1
MAE: 3.2770698934793474, Hidden Layers: [8, 14]; Learning Rate: 0.0085; Batch Size: 5
MAE: 3.2774167344570158, Hidden Layers: [6]; Learning Rate: 0.001; Batch Size: 4
MAE: 3.3179026857614518, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 1
MAE: 3.358060486793518, Hidden Layers: [10, 6]; Learning Rate: 0.0085; Batch Size: 4
MAE: 3.3582792000770567, Hidden Layers: [8, 4]; Learning Rate: 0.01; Batch Size: 3
MAE: 3.3849009737968445, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 4
MAE: 3.431247495174408, Hidden Layers: [10, 16]; Learning Rate: 0.009500000000000001; Batch Size: 3
MAE: 3.4833023028373717, Hidden Layers: [16]; Learning Rate: 0.0085; Batch Size: 3
MAE: 3.5067408056259155, Hidden Layers: [12, 14]; Learning Rate: 0.0075; Batch Size: 4
MAE: 3.512376383781433, Hidden Layers: [14, 14]; Learning Rate: 0.0055; Batch Size: 1
MAE: 3.517246386528015, Hidden Layers: [8, 14]; Learning Rate: 0.006500000000000001; Batch Size: 5
MAE: 3.621103637099266, Hidden Layers: [4]; Learning Rate: 0.0055; Batch Size: 5
MAE: 3.6258220076560974, Hidden Layers: [16, 4]; Learning Rate: 0.0075; Batch Size: 2
MAE: 3.6276449546813962, Hidden Layers: [10, 14]; Learning Rate: 0.0085; Batch Size: 1
MAE: 3.634502476453781, Hidden Layers: [12, 14]; Learning Rate: 0.009500000000000001; Batch Size: 1
MAE: 3.66705295753479, Hidden Layers: [8, 12]; Learning Rate: 0.0075; Batch Size: 5
MAE: 3.7561825487613674, Hidden Layers: [14, 8]; Learning Rate: 0.0075; Batch Size: 4
MAE: 3.8142534613609316, Hidden Layers: [14, 10]; Learning Rate: 0.009500000000000001; Batch Size: 5
MAE: 3.8687748544514178, Hidden Layers: [8, 16]; Learning Rate: 0.009500000000000001; Batch Size: 2
MAE: 3.9130908489227294, Hidden Layers: [14, 6]; Learning Rate: 0.005000000000000001; Batch Size: 3
MAE: 4.237235291481018, Hidden Layers: [8, 16]; Learning Rate: 0.005000000000000001; Batch Size: 1
MAE: 4.3152625188827525, Hidden Layers: [14, 8]; Learning Rate: 0.0055; Batch Size: 3
Results saved successfully in dir `results/test2/NN_results_5000_lessData.pkl.pkl`.
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5001/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5002/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5003/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5004/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5005/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5006/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5007/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5008/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5009/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5010/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5011/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5012/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5013/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5014/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5015/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5016/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5017/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5018/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5019/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5020/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5021/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5022/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5023/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5024/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5025/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5026/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5027/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5028/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5029/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5030/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5031/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5032/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5033/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5034/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5035/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5036/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5037/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 5038/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5039/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5040/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5041/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5042/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5043/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5044/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5045/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5046/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5047/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5048/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5049/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5050/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5051/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5052/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5053/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5054/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5055/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5056/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5057/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5058/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5059/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5060/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5061/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5062/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5063/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5064/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5065/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5066/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5067/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5068/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5069/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5070/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5071/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5072/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5073/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5074/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5075/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5076/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5077/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5078/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5079/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5080/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5081/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5082/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5083/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 5084/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5085/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5086/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5087/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5088/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5089/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5090/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5091/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5092/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5093/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5094/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5095/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5096/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5097/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5098/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5099/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5100/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5101/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5102/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5103/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5104/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5105/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5106/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5107/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5108/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5109/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 5110/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5111/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5112/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5113/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5114/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5115/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5116/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5117/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5118/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5119/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5120/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5121/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5122/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5123/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5124/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5125/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5126/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5127/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5128/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5129/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5130/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5131/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5132/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5133/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5134/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5135/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5136/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5137/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 5138/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5139/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5140/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5141/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5142/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5143/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5144/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5145/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5146/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5147/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5148/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5149/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5150/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5151/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5152/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5153/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5154/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5155/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5156/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5157/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5158/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5159/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5160/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5161/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5162/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5163/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5164/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5165/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5166/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5167/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5168/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5169/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5170/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5171/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5172/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5173/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5174/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5175/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5176/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5177/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5178/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5179/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5180/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5181/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5182/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5183/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5184/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5185/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5186/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5187/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5188/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5189/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5190/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5191/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5192/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5193/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5194/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5195/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5196/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5197/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5198/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5199/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5200/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5201/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5202/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5203/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5204/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5205/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5206/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5207/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5208/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5209/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5210/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5211/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5212/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5213/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5214/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5215/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5216/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5217/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5218/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5219/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5220/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5221/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5222/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5223/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5224/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5225/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5226/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5227/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5228/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5229/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5230/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5231/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5232/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5233/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5234/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
Now training the model 5235/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5236/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5237/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5238/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5239/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5240/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 5241/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5242/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 5243/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5244/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5245/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5246/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5247/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5248/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5249/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5250/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5251/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5252/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5253/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5254/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5255/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5256/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5257/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5258/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5259/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5260/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5261/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5262/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5263/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5264/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5265/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5266/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5267/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5268/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5269/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5270/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5271/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5272/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5273/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5274/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 77ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 77ms/step
Now training the model 5275/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 76ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 76ms/step
Now training the model 5276/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 78ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 78ms/step
Now training the model 5277/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 86ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 86ms/step
Now training the model 5278/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 82ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 82ms/step
Now training the model 5279/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 80ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 80ms/step
Now training the model 5280/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 92ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 92ms/step
Now training the model 5281/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step
Now training the model 5282/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 77ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 77ms/step
Now training the model 5283/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 84ms/step
Now training the model 5284/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 5285/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step
Now training the model 5286/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 66ms/step
Now training the model 5287/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 65ms/step
Now training the model 5288/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 5289/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 70ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 71ms/step
Now training the model 5290/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 5291/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 5292/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 5293/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 68ms/step
Now training the model 5294/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5295/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5296/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 5297/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 714ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 715ms/step
Now training the model 5298/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5299/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5300/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 5301/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5302/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5303/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5304/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 5305/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5306/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5307/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5308/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5309/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5310/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5311/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5312/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5313/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5314/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5315/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5316/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5317/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 5318/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5319/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5320/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5321/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5322/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5323/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5324/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5325/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5326/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5327/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5328/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5329/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5330/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 156ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 156ms/step
Now training the model 5331/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5332/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5333/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5334/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5335/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5336/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5337/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5338/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5339/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5340/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5341/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5342/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 5343/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5344/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 5345/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5346/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5347/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5348/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5349/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5350/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 5351/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5352/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5353/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 5354/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5355/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5356/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5357/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 5358/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5359/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5360/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5361/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5362/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5363/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5364/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5365/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 5366/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5367/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5368/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5369/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 5370/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5371/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5372/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5373/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 75ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 76ms/step
Now training the model 5374/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5375/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5376/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5377/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 63ms/step
Now training the model 5378/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5379/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5380/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5381/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5382/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5383/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5384/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5385/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step
Now training the model 5386/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 173ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 173ms/step
Now training the model 5387/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5388/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5389/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 5390/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5391/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5392/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5393/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 64ms/step
Now training the model 5394/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5395/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5396/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5397/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5398/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5399/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5400/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5401/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5402/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5403/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5404/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5405/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 5406/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5407/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5408/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5409/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 60ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 61ms/step
Now training the model 5410/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5411/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5412/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5413/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5414/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5415/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5416/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5417/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 5418/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5419/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5420/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5421/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5422/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5423/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5424/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5425/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 62ms/step
Now training the model 5426/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5427/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5428/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5429/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 5430/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5431/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5432/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 5433/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5434/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5435/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5436/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5437/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5438/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5439/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5440/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5441/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5442/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
Now training the model 5443/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5444/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5445/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5446/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5447/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5448/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5449/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5450/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5451/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5452/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5453/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5454/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5455/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5456/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5457/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5458/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5459/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5460/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5461/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5462/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5463/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5464/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5465/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5466/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5467/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5468/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5469/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5470/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5471/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5472/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5473/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5474/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5475/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5476/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5477/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 5478/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5479/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5480/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5481/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5482/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5483/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5484/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5485/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5486/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5487/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5488/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5489/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5490/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5491/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5492/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5493/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5494/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5495/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5496/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5497/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5498/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5499/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5500/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5501/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5502/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5503/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5504/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5505/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5506/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5507/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5508/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5509/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5510/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5511/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
Now training the model 5512/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5513/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5514/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5515/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5516/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5517/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5518/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5519/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5520/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5521/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5522/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5523/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5524/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5525/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 57ms/step
Now training the model 5526/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step
Now training the model 5527/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5528/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5529/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 73ms/step
Now training the model 5530/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5531/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5532/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5533/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5534/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5535/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5536/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5537/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5538/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5539/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5540/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5541/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5542/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5543/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5544/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5545/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 58ms/step
Now training the model 5546/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5547/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5548/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5549/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 59ms/step
Now training the model 5550/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5551/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5552/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5553/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5554/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5555/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5556/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5557/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 56ms/step
Now training the model 5558/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5559/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5560/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5561/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5562/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5563/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5564/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5565/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5566/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 55ms/step
Now training the model 5567/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5568/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5569/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 54ms/step
Now training the model 5570/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5571/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5572/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step
Now training the model 5573/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5574/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5575/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5576/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
Now training the model 5577/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 53ms/step
Now training the model 5578/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 51ms/step
Now training the model 5579/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5580/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5581/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5582/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5583/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5584/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5585/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5586/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5587/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5588/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
Now training the model 5589/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5590/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
Now training the model 5591/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
Now training the model 5592/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
Now training the model 5593/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
Now training the model 5594/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
Now training the model 5595/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5596/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 48ms/step
Now training the model 5597/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 50ms/step
Now training the model 5598/5600
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
Now training the model 5599/5600
Results saved successfully in dir `results/test2/NN_results_lessdata.pkl.pkl`.
Traceback (most recent call last):
  File "/home1/s4950836/nnproject/NeuralNetwork_project/main.py", line 118, in <module>
    testNetworkConstructor(
  File "/home1/s4950836/nnproject/NeuralNetwork_project/main.py", line 94, in testNetworkConstructor
    results_handler.save_results_readable("NN_results_lessdata_readable", "test2")
  File "/home1/s4950836/nnproject/NeuralNetwork_project/results/result_handler.py", line 81, in save_results_readable
    np.savetxt(filename, self._results)
  File "/home1/s4950836/.local/lib/python3.11/site-packages/numpy/lib/npyio.py", line 1570, in savetxt
    raise ValueError(
ValueError: Expected 1D or 2D array, got 0D array instead
srun: error: node60: task 0: Exited with exit code 1
srun: Terminating StepId=13671129.1

###############################################################################
HÃ¡brÃ³k Cluster
Job 13671129 for user s4950836
Finished at: Sat Nov  2 03:20:33 CET 2024

Job details:
============

Job ID                         : 13671129
Name                           : network_evaluator
User                           : s4950836
Partition                      : regularlong
Nodes                          : node60
Number of Nodes                : 1
Cores                          : 1
Number of Tasks                : 1
State                          : FAILED  
Submit                         : 2024-11-02T00:12:42
Start                          : 2024-11-02T00:12:43
End                            : 2024-11-02T03:20:32
Reserved walltime              : 4-12:00:00
Used walltime                  :   03:07:49
Used CPU time                  :   02:59:13 (Efficiency: 95.42%)
% User (Computation)           : 91.76%
% System (I/O)                 :  8.24%
Total memory reserved          : 40G
Maximum memory used            : 36.88G

Acknowledgements:
=================

Please see this page for information about acknowledging HÃ¡brÃ³k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
